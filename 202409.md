# 9/5(Thu)
LLMをファインチューニングして、データセットを機械語とCコードにする。

# 9/8(Sun)  
[LLM4Decompile:大規模言語モデルによるバイナリコードの逆コンパイル](https://arxiv.org/pdf/2403.05286)  
LLM4Decompileという、プログラムのデコンパイルに特化した取り組みである。事前学習データの構築において、Anghabenchという公開された100万個のコンパイル可能なCファイルを基にしている。  
具体的には、ソースコードをまずバイナリオブジェクトファイルに変換し、次にそれをアセンブリコードに逆アセンブルして、x86 Linuxプラットフォーム上でソースコードとペアリングする。次に、LLM4Decompileのモデル設定では、LDeepSeek-Coderと同じアーキテクチャを使用し、対応するDeepSeek-Coderのチェックポイントでモデルを初期化している。学習目的は以下の２つに分類される。
- Next token prediction(NTP)である。与えられた入力に基づいて次に来るべきトークンを予測するものである。このアプローチは、多くの大規模言語モデルの事前学習において中心的な役割を果たしており、真のトークンに対する負の対数確率を最小化することを目指している。このプロセスは、入力されたシーケンスに基づき、より正確な予測を行うためのモデルのパラメータを洗練させることを意味する。
- Sequence-to-sequense(S2S)である。入力されたシーケンスに対して期待される出力を予測するものである。これは、特にニューラル機械翻訳モデルで採用されているアプローチであり、Cコードのトークンに対する負の対数確率を最小化することに焦点を当てている。この目標では、出力シーケンスに対する損失のみを計算し、より精度高い翻訳を実現している。
これら２つの学習目的の主な違いは、入力シーケンスやアセンブリコードが学習損失の計算にどのように影響するかにある。NTPではすべての入力が考慮されるのに対し、S2Sでは出力シーケンスのみが重視される。  

コード、データセット、モデルはhttps://github.com/albertan017/LLM4Decompile
にある。

# 9/9(Mon)
## LLM4Decompile


### **1. 背景と目的**

- **デコンパイルの課題**：デコンパイラはバイナリコードを高水準のソースコードに変換するツールであり、リバースエンジニアリング、セキュリティ分析、ソフトウェアの保守などで重要である。しかし、従来のデコンパイラは限界があり、特に未知のバイナリコードや複雑なコードには対応しきれないことがある。
- **LLMの可能性**：大規模言語モデル（LLM）は自然言語処理で顕著な成果を上げており、その能力をバイナリコードのデコンパイルに応用できるのではないかという考えに基づいている。

### **2. 提案手法**

- **LLM4Decompile**：提案されたシステム「LLM4Decompile」は、バイナリコードを入力として受け取り、それに対応する高水準ソースコードを生成することを目的としている。LLMは大量のソースコードとバイナリコードのペアで訓練され、コード生成能力を向上させる。
- **データセットと訓練**：さまざまなプラットフォームやコンパイラで生成されたバイナリコードと対応するソースコードを使用して、モデルを訓練します。これにより、LLMが一般化能力を持ち、異なるバイナリコードにも対応できるようになる。

### **3. 実験と評価**

- **性能評価**：提案手法は、生成されたソースコードの正確性、可読性、元のソースコードとの一致度に基づいて評価されます。従来のデコンパイラと比較して、LLM4Decompileがより高い性能を示すことが報告されている。
- **汎用性**：このアプローチは、異なるコンパイラやプラットフォームで生成されたバイナリコードに対しても有効であるとされています。特に、複雑なコード構造や制御フローを持つバイナリコードに対しても、高い精度を実現している。

### **4. 課題と展望**

- **計算資源**：大規模言語モデルは計算資源を大量に消費するため、実用化には高い計算能力が必要である。
- **データの必要性**：モデルの訓練には膨大な量のデータが必要であり、データ収集や準備が大変である。
- **セキュリティと倫理**：デコンパイル技術の悪用を防ぐためのセキュリティと倫理的な配慮が必要である。

### **5. 結論**

- **可能性**：LLM4Decompileは、従来のデコンパイラに比べて高い精度と汎用性を持ち、デコンパイル技術における新たなアプローチを提供します。これにより、リバースエンジニアリングやセキュリティ分析の分野での応用が期待される。

この論文は、大規模言語モデルをデコンパイリングの分野に適用することで、より精度の高いソースコード生成が可能になるという新しいアプローチを提案しており、今後の研究と実践において重要な基盤となると思われる。

# 9/11(Wed)
## ejschwartz/llm4decompile-6.7b-v2を使用してみた  
これはGhidraから得られたデコンパイル結果を精巧なCコードに書き換えてくれるものである。以下が渡したデコンパイル結果である。
```c

void function(undefined4 *param_1,undefined4 *param_2)

{
  undefined4 uVar1;
  
  uVar1 = *param_1;
  *param_1 = *param_2;
  *param_2 = uVar1;
  return;
}
```
上記は元は以下のswap関数である。
```c
void swap(int* a, int* b) {
    int temp = *a;
    *a = *b;
    *b = temp;
}
```
結果は以下である。
```c
void function(int *a, int *b)
{
    int tmp = *a;
    *a = *b;
    *b = tmp;
}
```
関数名は変えてくれなかったが中身は同じになった。これを生成するのに3000sかかった。  
少し長いコードであるマージソートを入力すると、1300s以上かかっても出力されずエラーとなった。ちなみにchatgpt3だとコード自体はあまり読みやすくはならなかったが、マージソートであることは理解していた。

# 9/13(Fri)
## LLM4Binary-llm4decompile-6.7b-v1.5を使用してみた
これはアセンブリコードをCコードに直している際にllmを用いている。  
まずCコードをgccでコンパイルしてバイナリファイルを生成する。次にobjdumpでバイナリファイルを逆アセンブルしてアセンブリコードを生成する。最後にllmを用いて、アセンブリコードをCコードに戻すことを逆コンパイルとしている。しかしながら、アセンブリコードを入力としても同じコードを返すだけである。


シミュレーションを作成した。[シミュレーション](simulation/r2d2.md)

# 9/19(Thu)
## Ghidraを用いたIRコードの並列化の問題点
- 依存関係の解析の困難さ
  > 並列化には、データ依存性の解析が不可欠である。IRコードの段階で変数やメモリの依存関係を正確に把握し、競合を回避する必要があるが、Ghidraの解析ではこれが難しい。
- ループの検出と最適化の限界
  > GhidraのIRは、高レベル言語の構造が低レベルで表現されているため、ループ並列化を行う際にコードの構造を手動で再解釈する必要がある。

# 9/26(Thu)
https://arxiv.org/pdf/2406.06637.pdf  
大規模言語モデル(GPT-4)がデコンパイルにどの程度有効であるかを調査している。バイナリコードから高レベルのソースコードへの変換能力が主な焦点である。  
GPT-4は、特定のバイナリコードのパターンを理解でき、単純な構造やルーチンを高レベルの言語に変換する能力を示している。しかし、複数の関数やロジックの解析には限界がある。
## 結果
  > 関数の引数や変数の推定、分岐やループ構造などの基本的なプログラミングパターンはある程度正確に再現可能であった。
## 問題
  > モデルは単純な関数には対応できるものの、複雑なロジックを持つ関数や最適化されたバイナリコードの解析には限界がある。例えば、暗号化アルゴリズムや複雑なメモリ管理を行うコードは正しく再現できない。
## 課題
  > バイナリ解析専用のファインチューニングを施したモデルの開発が重要だと指摘されている。特に、特定のアーキテクチャ（x86,ARMなど）やプラットフォームに特化したデータセットを使った訓練が有効だと考えられている。
> データ型やポインタの解析精度を高めるため、より多くの実行コンテキスト情報やメモリレイアウト情報を組み込む必要がある。
> 暗号化や最適化されたコードの解析に対しては、LLMが抱えている課題を克服するための新しいアプローチが必要である。
