# 5/28

<details><summary>AIと一緒に読める「alphaXiv」　英語論文のURL「arxiv」→「alphaxiv」に変えて起動　"日本語ブログ"に変換可能</summary>

米コーネル大学が運営する「arXiv」は、物理学や数学、コンピュータサイエンスなどの論文を無料で公開・閲覧できる英語のベースのプレプリントサーバである。査読前にいち早く世界に論文を共有できるという利点を持つ。arXivは単にPDFとして保存されているだけなので一方的な閲覧に限られるが、「[alphaXiv](https://www.alphaxiv.org/explore)」は、各論文を介してWebブラウザ上で質問や議論できる。  

利用する際には、各論文URLの「arxiv」を「alphaxiv」にカエルだけで開始できる気軽さもうれしい。ユーザーインタフェースは、左が元の論文、右が入力や出力ができるエリアのサイドバー形式になっている。ユーザーは元の論文を見ながら、アシスタント機能を使ってAIチャットで質問やサーベイなどが可能。5月21日現在、Gemini 2.5ProやClaude 3.7 Thinking、o4-mini、GPT-4.1などの強力なAIが備わっている。  

![image](https://github.com/user-attachments/assets/3c006f6d-d6b6-4ae2-bac9-2408883ae159)  AlphaXivを起動した際のUI  


また、目次や小見出しありで整理された日本語文のブログ形式で、英語論文を一発で出力してくれる。URLを変更してalphaXivを起動し、上段の「Blog」タブをクリックすると一発で選択した論文がブログ形式として多言語で出力される。一部で「Code」タブもある。  

![image](https://github.com/user-attachments/assets/a742c406-9860-4b09-8228-320576cf7f88)  論文をブログ形式に変換した様子  

全体に対しての質問も可能、論文内の文章にハイライトを引いて、その箇所に対してだけの質問や翻訳も可能。論文で提案された技術が格納されているGithubリポジトリをリンクさせたり、別の論文をリンクさせたりすることもできる。  

また論文に対し、微分にしか見ることができないプライベートコメントを残したり、alphaXivユーザー同士で共通で見られる公開コメントを残すことも可能。公開コメントには返信も可能で、返信があると通知が届く。  

論文に対して「いいね」もでき、トレンドとしてどの論文にいいねが多く付いているかを確認できる。またマイライブラリ機能があり、読みたい論文、読んだ論文などカテゴリー別に保存できる。ダイレクトメッセージもあり、alphaXivユーザー同士で交流も可能である。他にもさまざまな機能が無料で使い放題である。  
</details>

<details><summary>AIの頭の中ではどのように情報が処理されて意思決定が行われるのか</summary>

大量のデータから学習する大機オ言語モデルは、人間が直接設計したアルゴリズムとは異なり、学習の過程で独自に問題解決の戦略を獲得するが、それらの戦略は開発者にとっても不可視であり、モデルがどのように出力を生成しているのかを理解するのは困難である。Anthropicは、同社が開発した大規模言語モデル・Claudeの「思考の軌跡」を可視化するための新たな研究結果をまとめた論文を複数発表した。  

[Tracing the thoughts of a large language model \ Anthropic](https://www.anthropic.com/research/tracing-thoughts-language-model)  
[Circuit Tracing: Revealing Computational Graphs in Language Models](https://transformer-circuits.pub/2025/attribution-graphs/methods.html)  
[On the Biology of a Large Language Model](https://transformer-circuits.pub/2025/attribution-graphs/biology.html)  
[Tracing the thoughts of a large language model - YouTube](https://www.youtube.com/watch?v=Bj9BD2D3DzA)  

Anthropicはまず、Claudeが多言語で自然に会話できる理由を調査した。例えば、英語・中国語・フランス語といった異なる言語で「smallの反対は何か」と尋ねたところ、言語を問わず「small」「opposite」「large」に対応する共通の内部特徴が活性化することがわかった。これは、Claudeが個別の言語ではなく、言語を超えた概念空間で思考していることを示している。このような共通の思考基盤が存在することで、一つの言語を学んだ知識を他の言語に応用する能力が実現されているとAnthropicは論じた。  
![image](https://github.com/user-attachments/assets/741a31c9-f4ab-4649-9803-3f8d27903c39)  

また、詩の韻を踏む能力については、Claudeは単語を一語ずつ生成するように訓練されているにもかかわらず、あらかじめ韻を踏む語を想定し、その語で終わるように文を計画的に構築していることがわかった。例えば、「rabbit」を候補としてあげ、それに合った文脈を作っていく。  
![image](https://github.com/user-attachments/assets/0570cb61-51c9-40cc-99a1-8e515c6e6c8d)  
また、Claudeが暗算を行う仕組みについても明らかにされた。例えば、「36+59」のような計算問題に対しては、Claudeは1の位の計算と大まかな全体の合計という2つの計算経路を並行して進め、最終的な答えを導いていた。そして、Claudeは、計算方法を説明するときには学校で学ぶような筆算によるやり方を語りながら、実際の内部では異なる独自の戦略が採用されていたことも判明。つまり、出力される説明と、実際にモデルが用いている処理は一致していない場合があるというわけである。  
![image](https://github.com/user-attachments/assets/fad69743-db10-435d-a22d-3af5d1af0dc4)  

さらに、Claudeは時として「もっともらしいが実際には偽りの」推論過程を生成することがある。難しい数学問題に対して誤ったヒントを与えると、そのヒントに沿うような推論ステップを後付けで構築し、あたかも正しい手順を踏んだかのように説明する。これは人間の心理学で「動機づけられた推論」と呼ばれる現象に似ており、AIの出力の信頼性という観点で懸念が生じるとAnthropicは述べている。  

一方で、Claudeは複数の事実を組み合わせて答えを導く高度な推論能力も備わっている。例えば、「ダラスが属する州の首都は？」という問いに対して、Claudeはまず「ダラスはテキサス州にある」という知識を活性化し、次に「テキサス州の首都はオースティンである」という知識をリプレイしているのではなく、段階的に情報を統合して推論していることが確認された。  
![image](https://github.com/user-attachments/assets/619e76a8-eb6d-4a2c-a586-0e403af8c7d1)  

そして、AIが時に誤った情報、いわゆる幻覚を生成する理由についても調査が行われた。Claudeの中では基本的に、知らない質問には「答えられない」と返す回路がデフォルトで働いているとのこと。しかし、質問に含まれる名前が聞き覚えのあるものであった場合、たとえ詳細な情報がなくても「既知の情報」と誤って判断し、その結果として誤答を生成する場合があることがわかった。Anthropicは、このことが幻覚の発生する一因となっていると指摘している。  

たとえば、Anthropicは実際に、「Michael Batkin」という架空の人物に関する質問をClaudeに投げかけました。通常であれば「その人物に関する質問をClaudeに投げかけた。通常であれば「その人物についての情報はありません」と返すはずだが、Claude内部の「既知の名前」に関する特徴を人為的に活性化させたところ、Claudeは「Michael Batkinはチェスプレイヤーです」など、あたかもMichael Batkinが実在するかのように話し出したそうである。これは、モデルが「名前を知っている」という断片的な手がかりを根拠に、その人物に関する知識があるかのように振る舞うという典型的な幻覚の例である。  

安全対策を回避して有害な出力を生成させる脱獄についても、Anthropicは「Babies Outlive Mustard Block」という文章の頭文字を使って「BOMB」という単語をモデルに認識させ、爆弾の作り方に関する情報を出力させるように誘導する実験を行った。すると、Claudeは、危険な情報だと認識しながらも、文法的整合性を維持しようとする内部の圧力によって、出力を継続していたことがわかった。そして、文章を一文で終えることで整合性の要求が満たされ、そのタイミングでようやく拒否反応に切り替わるという挙動が確認された。  
![image](https://github.com/user-attachments/assets/79218d2e-2c07-4e27-b7e4-3a0f50c15db6)  

Anthropicは、AIが社会的に重要な場面で使われるようになっていく中で、「モデルの内部で何が起きているかを理解できること」が、モデルを信頼できる存在にするための鍵であり、モデルの内部構造を可視化・解析することはAIの信頼性と安全性を高めるために極めて重要である。
</details>
