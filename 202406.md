# 2024/6/1(Sat)

## 幸せのパンケーキが人に与える幸せの度合いについて

先日、友だちと幸せのパンケーキに行ったのだが、このネーミングについて少し疑問に感じた。幸せの度合いについては個人様々であることは想像に難くない。それにも関わらず、幸せのパンケーキというようにこのパンケーキを食べることによってあたかも幸せになれるといった印象を与える商品を提供することに不安を感じた。  
幸せのパンケーキのホームページでは、「「おいしいものは人を笑顔にできる。」この思いをカタチにしたのが『幸せのパンケーキ』です。」と語っている。「おいしいものは人を笑顔にできる」に関しては、大いに賛成できるがおいしいものをどういった環境・気持ちで食べるかによって笑顔になるかどうかが変化してくると思う。また、「思いをカタチにしたのが幸せのパンケーキです」に関しては、思いという味も形もないものを物体化したことを明言している。しかし、形をカタカナ表記にすることで物体感というものを和らげているようにも感じる。それを考慮しても、不思議な文章である。

![ダウンロード](https://github.com/PEARLabo/diary/assets/166197812/17115afe-50eb-4cdb-9352-1453fee233d4)

これらの疑念から、幸せのパンケーキにおける幸せについて定量的に測りたいと考えた。そこで、pythonを用いた幸せのパンケーキに関する質問を通して、幸せを定量的に測っていきたいと考えた。以下がpythonのコードである。
```python
# 幸せの度合いを測るスクリプト

def ask_question(question):
    """
    ユーザーに質問し、1から10の範囲で評価を入力させる関数
    """
    while True:
        try:
            rating = int(input(f"{question} (1-10): "))
            if 1 <= rating <= 10:
                return rating
            else:
                print("1から10の間で入力してください。")
        except ValueError:
            print("数字を入力してください。")

def measure_happiness():
    """
    幸せのパンケーキに関する幸せ度合いを測る関数
    """
    print("幸せの度合いを測るためにいくつか質問します。各質問に対して1から10の範囲で評価してください。")

    questions = [
        "幸せのパンケーキについての印象はどの程度でしょうか？",
        "実際に幸せのパンケーキを食べて、どの程度満足していますか？",
        "幸せのパンケーキの量にどの程度満足していますか？",
        "幸せのパンケーキの見た目はどの程度満足していますか？",
    ]

    total_score = 0
    for question in questions:
        total_score += ask_question(question)

    average_score = total_score / len(questions)
    print(f"\nあなたの幸せの度合いは {average_score} / 10 です。")

# スクリプトを実行
if __name__ == "__main__":
    measure_happiness()
```
一応、このpythonコードでの私自身における実行結果を以下に示す。

<img width="502" alt="スクリーンショット 2024-06-01 031531" src="https://github.com/PEARLabo/diary/assets/166197812/69f27b23-8ac5-4e49-98dd-5d9ba552bad4">

以上より、このコードでは充分ではない点が多く存在する。質問の量と質である。また、多くの対象者を募らなけらばならないことである。そこを深く研究し改善することが出来れば、幸せのパンケーキが人に与える幸せについて、性差、年齢差、体質などのような観点からなにか関係性が見つかるかもしれない。

これらの文章は酔っ払って作成したものであるため、深い意味は全くありません。私は幸せのパンケーキが大好きです。

# 2024/6/2(Sun)
## pythonでの静的解析
pythonを使った静的解析ツールを作成する場合、まずパーサーを実装してソースコードを解析する。その後、特定のパターンやルールに基づいてコードをスキャンし、問題や潜在的な改善点を検出する。pythonでは、ASTモジュールを使って静的解析を行うことが比較的容易である。また、ライブラリやフレームワーク（例えば、'ast'、'flake8'、'pylint'など）を活用することも出来る。
>astモジュールは、pythonアプリケーションでpythonの抽象構文木を処理しやすくするものである。

# 2024/6/3(Mon)
## アンケートを因子分析する
必要なモジュールは以下の通りである。
```python
# 基本モジュール
import numpy as np
import pandas as pd

# 可視化のためのモジュール
import matplotlib.pyplot as plt
import seaborn as sns

# 画像を表示するためのモジュール
from IPython.display import Image
```
さらに、因子分析に必要なパッケージとモジュールを用意する。
```python
!pip install factor-analyzer

#因子分析のためのモジュール
from factor_analyzer import FactorAnalyzer
```
続いて、データを紹介する。
```csv
データ表,質問内容
Sex,性別
Age,年代
Q1,あなたは、当社をどのくらい好きですか
Q2,あなたは、今後どのくらいの期間当社の社員でありたいですか
Q3,あなたは、現在の業務にどのくらい満足していますか
Q4,あなたの担当している仕事は、自分に適していると思いますか
Q5,あなたは、社内の人に個人的な悩みを相談することができますか
Q6,あなたは、上司から正当に評価されていると思いますか
Q7,あなたは、当社の業績向上に貢献したいと思いますか
Q8,あなたは、当社で定年まで勤務したいですか
Q9,あなたが当社に勤めているのはキャリアアップのためですか
Q10,あなたが当社に勤務しているのは、やりがいがあるからですか
Q11,あなたは、転職したいと考えていますか
Q12,当社は働きやすい職場環境であると思いますか
Q13,あなたは、会社から必要とされていると感じていますか
Q14,あなたは、できるだけ良いサービスをお客さまに提供したいと思いますか
Q15,あなたは、自分の仕事場を綺麗にするように心がけていますか
Q16,あなたは、業務で勘を働かせて行っていますか

```
```csv
Sex,Age,Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q8,Q9,Q10,Q11,Q12,Q13,Q14,Q15,Q16
0,50,4,5,0,0,0,5,5,5,0,3,0,3,2,5,3,3
1,40,5,0,5,5,0,5,0,0,0,0,0,5,5,5,5,5
0,40,4,4,4,3,4,3,3,4,3,3,3,3,3,3,3,3
1,30,1,1,2,2,0,1,2,0,4,2,4,1,1,4,3,4
1,20,2,3,3,3,3,5,1,1,3,2,3,3,2,4,4,3
1,20,0,0,1,1,1,5,1,0,3,0,5,1,5,5,4,4
1,50,4,5,3,3,3,3,5,5,0,3,0,2,2,4,5,3
0,20,4,2,4,2,4,2,4,0,2,3,4,4,1,4,3,4
1,50,5,5,5,5,4,5,5,5,3,5,2,3,4,5,5,3
0,40,3,5,3,3,0,3,4,4,2,3,3,3,3,4,4,3
1,30,1,3,3,2,3,4,3,3,1,3,3,3,5,3,4,4
1,30,3,3,0,0,5,3,3,3,3,3,3,2,0,3,4,3
1,40,3,5,0,4,5,0,4,4,0,0,4,0,0,5,5,5
1,30,1,3,1,1,0,1,1,0,3,1,5,0,3,3,5,4
0,30,4,5,3,3,3,3,4,3,2,3,0,5,3,5,4,3
1,20,3,5,1,1,5,4,5,5,2,3,2,0,0,5,5,5
1,40,0,0,0,0,0,2,3,0,0,0,5,0,0,5,5,2
1,20,4,0,3,4,4,4,5,4,5,3,4,3,3,5,5,5
1,20,3,4,4,5,4,4,5,4,3,3,3,3,3,4,4,3
1,30,3,1,1,2,0,3,3,1,2,2,4,3,2,3,3,3
1,50,3,4,3,3,3,3,3,4,1,2,2,4,3,4,4,3
0,20,4,2,3,3,4,4,3,1,3,3,3,2,2,4,4,3
1,40,2,2,2,2,0,0,3,4,4,4,4,2,1,3,4,4
1,30,4,5,3,4,4,4,4,4,0,3,1,4,3,4,4,3
0,10,4,3,4,4,3,3,4,3,3,4,2,4,4,5,5,4
0,20,2,2,2,2,2,2,2,0,3,3,2,3,3,3,3,2
0,40,3,5,4,4,4,3,3,4,3,3,0,3,3,5,4,4
0,20,3,3,3,3,5,3,5,3,3,3,3,3,3,5,5,3
1,20,1,3,3,4,4,4,5,3,3,4,3,1,3,5,5,4
0,40,5,5,4,1,4,4,4,4,2,3,0,3,4,4,5,4
1,20,2,1,2,2,2,2,2,1,3,3,2,1,1,1,1,2
0,10,3,3,3,1,1,0,3,1,3,1,4,2,0,4,4,1
1,30,0,0,0,0,2,3,0,0,0,0,4,0,1,4,4,3
1,30,3,5,3,3,2,3,3,4,2,2,0,4,4,3,4,4
1,40,3,4,3,3,3,1,3,3,3,3,4,4,2,3,4,3
0,40,2,4,4,4,4,1,5,5,3,2,3,3,1,5,5,5
1,30,3,4,3,3,3,3,3,3,3,3,2,2,3,4,4,3
1,30,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3
1,10,1,3,0,2,0,4,2,4,2,2,0,2,2,4,3,2
1,20,3,3,2,2,3,3,3,3,3,2,2,2,2,2,3,3
1,30,3,3,3,3,3,3,4,1,1,3,3,3,3,4,4,4
1,30,0,0,3,0,0,3,0,0,0,3,5,0,0,3,3,3
0,20,2,2,3,3,1,3,1,2,3,2,4,2,4,5,3,3
0,20,1,5,3,2,3,2,3,2,0,0,3,2,2,4,4,2
1,30,4,5,3,3,0,3,5,5,5,4,0,3,2,5,5,5
1,30,3,3,3,4,4,3,3,3,2,3,3,3,3,3,3,3
1,30,3,1,1,1,1,1,1,0,3,1,5,1,2,2,2,2
1,40,3,3,3,3,4,5,3,2,1,2,3,3,3,5,3,3
1,40,2,3,3,3,1,3,3,3,2,2,3,2,3,3,4,3
1,20,4,5,2,1,4,4,5,5,5,2,1,1,3,4,4,4
1,50,4,3,3,2,4,3,4,4,2,4,2,3,3,4,4,4
1,40,2,3,2,2,1,1,2,4,3,2,4,1,2,3,3,3
1,30,3,5,2,1,0,0,3,3,3,1,1,0,0,3,4,4
0,30,3,3,3,3,3,1,3,3,3,3,3,1,2,5,3,3
0,40,4,5,4,4,2,4,5,5,3,5,0,4,4,5,4,4
1,30,3,3,3,3,2,3,4,2,4,4,4,2,4,5,5,4
1,20,0,1,0,0,0,0,0,0,0,0,5,4,0,2,5,5
0,30,4,4,2,4,4,3,4,4,3,5,2,4,3,5,5,4
1,30,3,4,3,3,2,2,3,3,3,3,4,4,3,3,3,2
0,20,3,2,3,3,2,3,3,2,2,3,2,3,3,2,3,3
1,30,3,3,3,3,3,3,3,3,3,3,3,0,3,3,3,3
1,30,4,5,4,4,4,3,5,5,4,4,2,3,4,4,5,4
1,20,3,3,3,3,1,1,3,2,1,3,2,2,2,3,4,3
0,30,0,0,0,2,1,0,0,0,0,0,5,0,0,0,1,4
1,30,4,5,4,4,5,0,5,4,4,4,3,3,0,5,5,4
1,50,5,5,5,5,4,4,5,5,3,4,0,4,3,5,4,3
1,20,5,5,3,3,1,5,5,5,3,4,0,4,4,4,4,4
0,40,3,5,3,3,0,3,4,3,0,3,3,3,0,5,3,4
0,50,1,3,1,0,0,2,3,3,1,1,3,1,0,4,5,4
1,30,2,2,2,3,2,3,3,1,3,2,3,2,2,3,4,2
1,30,3,1,3,3,2,3,3,0,4,3,4,2,3,4,3,4
1,20,2,3,4,4,4,4,2,3,3,4,2,3,3,3,4,3
0,50,3,5,4,4,3,3,3,4,3,3,2,3,3,3,3,2
1,40,3,4,3,3,3,3,1,4,1,1,2,4,3,1,3,3
1,20,1,3,0,2,3,2,3,2,3,1,5,0,2,4,4,4
1,20,1,2,2,1,2,2,2,2,2,2,2,2,2,2,2,2
0,40,2,5,3,2,2,2,5,4,0,0,0,1,0,5,5,4
1,20,1,5,1,3,3,4,4,4,4,4,3,0,3,5,4,4
1,30,3,3,3,3,1,3,3,3,3,3,3,3,2,3,3,3
1,30,3,4,4,3,0,4,4,3,3,2,0,2,4,5,3,5
1,40,2,3,3,3,2,4,3,3,3,3,2,3,3,3,4,3
0,20,3,3,4,4,1,3,3,1,0,3,2,3,1,4,4,3
0,50,3,5,3,4,2,3,4,5,3,3,3,3,3,4,3,3
1,40,5,5,3,3,3,3,5,5,3,3,5,3,3,5,5,3
0,40,3,5,3,3,4,4,4,4,3,3,0,2,3,4,4,4
0,20,5,5,4,5,3,2,5,5,4,4,0,4,3,4,5,5
1,20,3,3,3,3,1,3,3,3,3,3,3,2,2,4,3,4
0,40,4,5,3,3,3,1,4,4,3,3,2,1,3,5,4,3
1,40,1,0,1,0,0,3,4,0,0,0,5,2,0,4,4,3
0,40,4,5,5,3,2,4,3,4,1,4,0,4,3,3,3,3
1,30,4,5,5,5,3,3,5,5,4,4,0,3,3,5,5,4
1,50,3,5,4,4,3,1,4,4,3,3,3,2,3,5,5,4
0,40,5,5,4,5,4,5,5,5,4,5,0,4,4,5,4,5
1,20,3,3,3,4,3,3,3,2,3,3,3,3,3,3,3,4
1,30,4,4,3,2,2,3,2,2,0,0,2,0,0,2,4,2
0,20,3,3,3,3,2,4,3,2,3,3,3,3,3,4,4,3
1,30,5,5,5,5,4,3,5,5,0,5,0,3,3,5,5,4
1,20,0,1,3,3,4,4,3,0,3,3,4,0,0,5,5,5
1,40,1,1,3,1,1,2,1,1,1,1,4,2,1,5,3,4
1,20,2,1,1,2,2,1,2,2,2,2,2,2,2,1,2,2
```
今回扱うデータは以下のカラムが含まれている。  
・性別：0:女性,1:男性  
・年代：20,30,40,50,60  
・質問1～質問16：0~5までの6段階評価  
```python
# カラムごとの情報（欠測(null)がないかどうかやデータ型について）を確認
df.info()
```
```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 100 entries, 0 to 99
Data columns (total 18 columns):
 #   Column  Non-Null Count  Dtype
---  ------  --------------  -----
 0   Sex     100 non-null    int64
 1   Age     100 non-null    int64
 2   Q1      100 non-null    int64
 3   Q2      100 non-null    int64
 4   Q3      100 non-null    int64
 5   Q4      100 non-null    int64
 6   Q5      100 non-null    int64
 7   Q6      100 non-null    int64
 8   Q7      100 non-null    int64
 9   Q8      100 non-null    int64
 10  Q9      100 non-null    int64
 11  Q10     100 non-null    int64
 12  Q11     100 non-null    int64
 13  Q12     100 non-null    int64
 14  Q13     100 non-null    int64
 15  Q14     100 non-null    int64
 16  Q15     100 non-null    int64
 17  Q16     100 non-null    int64
dtypes: int64(18)
memory usage: 14.2 KB
```
```python
# 要約統計量を出力します
df.describe()
```
|index|Sex|Age|Q1|Q2|Q3|Q4|Q5|Q6|Q7|Q8|Q9|Q10|Q11|Q12|Q13|Q14|Q15|Q16|
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
|count|100\.0|100\.0|100\.0|100\.0|100\.0|100\.0|100\.0|100\.0|100\.0|100\.0|100\.0|100\.0|100\.0|100\.0|100\.0|100\.0|100\.0|100\.0|
|mean|0\.68|30\.9|2\.8|3\.29|2\.73|2\.73|2\.38|2\.81|3\.25|2\.83|2\.33|2\.59|2\.48|2\.36|2\.33|3\.85|3\.86|3\.43|
|std|0\.4688261722621507|10\.35676717236736|1\.3333333333333333|1\.6036259419254109|1\.278058818456468|1\.3169830843425607|1\.51610878850624|1\.300310763167052|1\.3586609569571049|1\.6578859606697496|1\.3488116730266422|1\.2956414892580697|1\.566569951882588|1\.2989506254175822|1\.3261549188110977|1\.122542208605543|0\.9213516640723501|0\.8791065253018446|
|min|0\.0|10\.0|0\.0|0\.0|0\.0|0\.0|0\.0|0\.0|0\.0|0\.0|0\.0|0\.0|0\.0|0\.0|0\.0|0\.0|1\.0|1\.0|
|25%|0\.0|20\.0|2\.0|2\.75|2\.0|2\.0|1\.0|2\.0|3\.0|2\.0|1\.0|2\.0|2\.0|2\.0|2\.0|3\.0|3\.0|3\.0|
|50%|1\.0|30\.0|3\.0|3\.0|3\.0|3\.0|3\.0|3\.0|3\.0|3\.0|3\.0|3\.0|3\.0|3\.0|3\.0|4\.0|4\.0|3\.0|
|75%|1\.0|40\.0|4\.0|5\.0|3\.0|4\.0|4\.0|4\.0|4\.0|4\.0|3\.0|3\.0|4\.0|3\.0|3\.0|5\.0|5\.0|4\.0|
|max|1\.0|50\.0|5\.0|5\.0|5\.0|5\.0|5\.0|5\.0|5\.0|5\.0|5\.0|5\.0|5\.0|5\.0|5\.0|5\.0|5\.0|5\.0|

因子分析の前段階で相関分析が行われる。相関分析を使った場合も、傾向が似た質問項目をまとめてグルーピングすることができるが、因子分析の準備としては、質問間の関係性を理解するために行われる。相関分析では質問項目のペアごとに相関係数と言われる量を算出して、算出された相関係数の値から、そのペアの関連性が強いか弱いかを判断する。

相関係数のカラースケール表示を以下に示す。  

![ダウンロード](https://github.com/PEARLabo/diary/assets/166197812/fb5c93a4-ede1-431e-90dd-9d54e3b41670)

因子数の目安となる値を求めるために、以下のスクリプトによってデータの固有値・固有ベクトルを出力する。
```python
fa = FactorAnalyzer()
fa.fit(df_fa)

# 固有値(ev)・固有ベクトル(v)をチェック
ev, v = fa.get_eigenvalues()
```
```python
# 因子数の目安を出力
print("因子数の目安：",len(ev[ev > 1]))
```
```
因子数の目安： 4
```
固有値の値を高い順にプロットした図をスクリープロットと呼ぶ。スクリープロットからも値が1以上の固有値の数を即座に確認出来る。またスクリープロットの「カーブ」の変化から因子数を定める方法もあるため、一般に因子数を定めるにあたってスクリープロットは出力される。
```python
# スクリープロットを描く
plt.scatter(range(1,len(ev)+1),ev)
plt.plot(range(1,len(ev)+1),ev)
plt.title('Scree Plot')
plt.xlabel('Factors')
plt.ylabel('Eigenvalue')
plt.grid()
plt.show()
```
![ダウンロード (1)](https://github.com/PEARLabo/diary/assets/166197812/6da6f956-4dd0-4d95-89af-1d2bd4edbf58)
因子分析実行後の出力については因子負荷量を確認する。因子負荷量は、各因子がそれぞれの質問に対してどの程度影響を与えているかを表している。従って、書く印紙について、因子負荷量の値が高い質問項目を見ることで、この因子がどのような内容なのかを推定することができる。
```python
# 因子負荷量を出力
fa.loadings_
```
```
array([[ 0.43700673,  0.45629721, -0.03918171,  0.01807779],
       [ 1.01000498, -0.10740845, -0.00628458, -0.09881217],
       [-0.02796968,  0.80863334,  0.04805419,  0.01173773],
       [ 0.02506138,  0.63996293,  0.05561122,  0.19483609],
       [ 0.20353067,  0.07589132,  0.11158761,  0.2745287 ],
       [-0.09077328,  0.50823578,  0.14815699, -0.07236554],
       [ 0.58412756, -0.12317894,  0.33589921,  0.21653845],
       [ 0.97584386, -0.15849091, -0.04311949,  0.10869657],
       [-0.11747168, -0.05431097, -0.07796542,  0.82225278],
       [ 0.16354187,  0.31516428, -0.08407165,  0.53886385],
       [-0.66581532, -0.34403243,  0.09871279,  0.3018856 ],
       [ 0.04447535,  0.78563136, -0.11050244, -0.13400899],
       [-0.10981618,  0.66461915, -0.0787136 ,  0.15297189],
       [-0.04140432,  0.0843115 ,  0.83779359, -0.05337359],
       [ 0.0918267 , -0.04702079,  0.79793802, -0.15412959],
       [-0.07312818,  0.00756505,  0.53528061,  0.03719336]])
```
```python
# 因子負荷量を代入
qlist_fa.loc[:,'f1']= fa.loadings_[:,0]
qlist_fa.loc[:,'f2']= fa.loadings_[:,1]
qlist_fa.loc[:,'f3']= fa.loadings_[:,2]
qlist_fa.loc[:,'f4']= fa.loadings_[:,3]
qlist_fa.head(5)
```
|index|データ表|質問内容|f1|f2|f3|f4|
|---|---|---|---|---|---|---|
|2|Q1|あなたは、当社をどのくらい好きですか|0\.4370066144294808|0\.456297220719006|-0\.03918164351798052|0\.018077862566076557|
|3|Q2|あなたは、今後どのくらいの期間当社の社員でありたいですか|1\.0100052295633384|-0\.10740843885251951|-0\.006284580136376506|-0\.0988123139791396|
|4|Q3|あなたは、現在の業務にどのくらい満足していますか|-0\.02796969437234646|0\.8086336260787723|0\.04805420386078123|0\.011737475240966886|
|5|Q4|あなたの担当している仕事は、自分に適していると思いますか|0\.025061350889809396|0\.6399630690102933|0\.055611205323650055|0\.19483596037406467|
|6|Q5|あなたは、社内の人に個人的な悩みを相談することができますか|0\.2035305660936983|0\.07589133344381162|0\.11158758203924457|0\.2745287951926574|

各因子は各質問項目についての因子負荷量の大きさから解釈を行う。因子負荷量の絶対値が大きい質問項目がその因子と関連の強い質問項目である。因子負荷量の値としては一般に0.4が目安とされる。実運用上は、各因子について因子負荷量が0.4以上のものだけを抽出して因子を解釈していく。
```python
# 因子負荷量（絶対値）0.4を基準として質問を抽出する
qlist_fa[abs(qlist_fa['f1']) > 0.4]
```
|index|データ表|質問内容|f1|f2|f3|f4|
|---|---|---|---|---|---|---|
|2|Q1|あなたは、当社をどのくらい好きですか|0\.4370066144294808|0\.456297220719006|-0\.03918164351798052|0\.018077862566076557|
|3|Q2|あなたは、今後どのくらいの期間当社の社員でありたいですか|1\.0100052295633384|-0\.10740843885251951|-0\.006284580136376506|-0\.0988123139791396|
|8|Q7|あなたは、当社の業績向上に貢献したいと思いますか|0\.5841272887287392|-0\.1231789708321217|0\.3358993331860718|0\.21653869178207866|
|9|Q8|あなたは、当社で定年まで勤務したいですか|0\.9758436883441387|-0\.1584908762323164|-0\.04311946473497964|0\.1086967585888379|
|12|Q11|あなたは、転職したいと考えていますか|-0\.6658152820584464|-0\.3440324026416215|0\.09871273588783851|0\.30188548555472167|
```python
# 複数の因子にまたがって因子負荷量の高い質問項目を除外する
qlist_fa[(abs(qlist_fa['f1']) > 0.4) & (abs(qlist_fa['f2']) < 0.4)& (abs(qlist_fa['f3']) < 0.4)& (abs(qlist_fa['f3']) < 0.4)]
```
|index|データ表|質問内容|f1|f2|f3|f4|
|---|---|---|---|---|---|---|
|3|Q2|あなたは、今後どのくらいの期間当社の社員でありたいですか|1\.0100052295633384|-0\.10740843885251951|-0\.006284580136376506|-0\.0988123139791396|
|8|Q7|あなたは、当社の業績向上に貢献したいと思いますか|0\.5841272887287392|-0\.1231789708321217|0\.3358993331860718|0\.21653869178207866|
|9|Q8|あなたは、当社で定年まで勤務したいですか|0\.9758436883441387|-0\.1584908762323164|-0\.04311946473497964|0\.1086967585888379|
|12|Q11|あなたは、転職したいと考えていますか|-0\.6658152820584464|-0\.3440324026416215|0\.09871273588783851|0\.30188548555472167|
```python
# 因子負荷量（絶対値）0.4を基準として質問を抽出する
qlist_fa[abs(qlist_fa['f2']) > 0.4]
```
|index|データ表|質問内容|f1|f2|f3|f4|
|---|---|---|---|---|---|---|
|2|Q1|あなたは、当社をどのくらい好きですか|0\.4370066144294808|0\.456297220719006|-0\.03918164351798052|0\.018077862566076557|
|4|Q3|あなたは、現在の業務にどのくらい満足していますか|-0\.02796969437234646|0\.8086336260787723|0\.04805420386078123|0\.011737475240966886|
|5|Q4|あなたの担当している仕事は、自分に適していると思いますか|0\.025061350889809396|0\.6399630690102933|0\.055611205323650055|0\.19483596037406467|
|7|Q6|あなたは、上司から正当に評価されていると思いますか|-0\.09077330082005641|0\.5082354854151148|0\.14815703658528434|-0\.07236531541038362|
|13|Q12|当社は働きやすい職場環境であると思いますか|0\.044475366561889766|0\.785631307756783|-0\.11050247014212733|-0\.13400892761822095|
|14|Q13|あなたは、会社から必要とされていると感じていますか|-0\.10981601612030101|0\.6646189804106863|-0\.07871364630141019|0\.15297180085148496|
```python
# 因子負荷量（絶対値）0.4を基準として質問を抽出する
qlist_fa[abs(qlist_fa['f3']) > 0.4]
```
|index|データ表|質問内容|f1|f2|f3|f4|
|---|---|---|---|---|---|---|
|15|Q14|あなたは、できるだけ良いサービスをお客さまに提供したいと思いますか|-0\.041404326551682594|0\.0843114205864016|0\.8377936759969387|-0\.0533736582302159|
|16|Q15|あなたは、自分の仕事場を綺麗にするように心がけていますか|0\.09182674569815329|-0\.04702078592585131|0\.7979378009797045|-0\.15412957457777796|
|17|Q16|あなたは、業務で勘を働かせて行っていますか|-0\.07312822913287523|0\.007565060562605179|0\.5352804884591725|0\.03719335864416982|
```python
# 因子負荷量（絶対値）0.4を基準として質問を抽出する
qlist_fa[abs(qlist_fa['f4']) > 0.4]
```
|index|データ表|質問内容|f1|f2|f3|f4|
|---|---|---|---|---|---|---|
|10|Q9|あなたが当社に勤めているのはキャリアアップのためですか|-0\.11747172061112338|-0\.054310900618316144|-0\.0779654373069115|0\.8222525271553397|
|11|Q10|あなたが当社に勤務しているのは、やりがいがあるからですか|0\.1635416439742483|0\.31516425826874256|-0\.08407164342964105|0\.5388640633109031|

# 2024/6/6(Thu)
## Pythonを使って並列化可能な部分を特定するための具体的なツールを作る場合、以下の手順が考えられる。
1. **ソースコードの解析**:PythonのAST(抽象構文木)モジュールを使用して、ソースコードを解析する。これにより、コードの構造を把握し、処理を進める。
2. **並列化のポテンシャルを検出するルールの定義**:どのようなパターンが並列化に適しているかを定義する。これには、ループの中で独立したイテレーションがあるかどうか、複数の処理が互いに依存していないかなどが含まれる。
3. **コードのスキャンとルールの適用**:パーサーを使ってソースコードをスキャンし、並列化のポテンシャルがあるかどうかをルールに基づいて検査する。
4. **並列化可能な箇所の報告**:ルールに合致する箇所を特定し、それらを報告する。これには、コンソールに出力するだけではなく、報告書やグラフィカルなインターフェースを通じてユーザーに提供することも考えられる。
5. **実用性の検証**:特定された箇所が実際に並列化可能かどうかを検証する。これには、並列化を適用してパフォーマンスを評価したり、潜在的な競合状態やデータ依存性を分析することが含まれる。
6. **ユーザーのフェえードバックと改善**:ユーザーからのフィードバックを受けて、ツールの改善や追加機能の検討を行う。

これらの手順を組み合わせて、Pythonを使った並列化可能な部分を特定するツールを開発することが可能になると考えられる。

# 2024/6/7
## Pythonを用いたPythonコードのエラーメッセージの出力
以下のPythonコードにPythonプログラムを読み込むとエラーメッセージを出力する。
```python
import traceback

def get_error_message(file_path):
    try:
        with open(file_path, 'r') as file:
            code = file.read()
        exec(code)
    except Exception as e:
        return traceback.format_exc()

# Pythonコードファイルのパス
file_path = "test.py"

# エラーメッセージの取得
error_message = get_error_message(file_path)
if error_message:
    print("エラーメッセージ:")
    print(error_message)
else:
    print("エラーは見つかりませんでした。")
```
今回は形式的にtest.pyファイルを読み込ませた。test.pyの中身は以下の通りである。
```python
print("Hello,World!"
```
出力結果は以下の通りとなった。

![Screenshot from 2024-06-07 16-17-59](https://github.com/PEARLabo/diary/assets/166197812/c10e61b2-cf63-4903-972d-c17df125db78)

希望通り、出力結果はエラーメッセージと間違っている行番号まで出力してくれた。

# 2024/6/10(Mon)
## 機械語コードからC言語を生成する
機械語コードの命令セットや形式に応じて、適切なC言語の表現を生成する必要がある。以下は、単純な機械語コードをC言語に変換する例である。この例では、機械語の命令が16進数のリストとして提供されていると仮定している。このPythonコードは、機械語コードの16進数リストを受取、それをC言語の配列として表現する。生成されたC言語のコードは、配列に格納された機械語コードを実行する簡単なプログラムである。
```pyton
def machine_code_to_c(machine_code):
    c_code="unsiggned char code[]={\n}"
    for byte in machine_code:
        c_code+=f"       0x{byte:02x},\n"
    c_code+="};\n"
    c_code+="int main() {\n"
    c_code+="    void (*function)()=(void(*)())code;\n"
    c_code+="    function();\n"
    c_code+="    return 0;\n"
    c_code+="}\n"
    return c_code

# 機械語コードの例(16進数のリストとして仮定)
machine_code=[0xB8,0x01,0x00,0x00,0x00,0xC3] #例: mov eax, 1; ret

# C言語のコードに変換
c_code=machine_code_to_c(machine_code)
print(c_code)
```
実行結果は以下のようになった。

![Screenshot from 2024-06-10 17-02-33](https://github.com/PEARLabo/diary/assets/166197812/380081fb-716e-424f-9f2f-3f73cd4c9dd7)

このソースコードを詳しく見ていく
1.  machine_code_to_c(machine_code)関数:
    >- 引数として、機械語コードを16進数のリストとしって受け取る。
    >- 機械語コードをC言語の配列に変換し、それを含む完全なC言語のプログラムを生成する。
2. 変換されるC言語のプログラムの構造:
    >- unsigned char code[]配列:機械語コードを格納する配列である。16進数のリストからそれぞれのバイトを取り出し、16進数の形式で表現されたC言語のバイト列に変換される。
    >- main()関数:変換された機械語コードを実行するためのC言語のメイン関数である。関数ポインタfunctionを使って機械語コードが格納された配列を呼び出す。
3. print(c_code):
    >- 変換されたC言語のコードを出力する。

このコードは、機械語プログラムをC言語に変換し、それをCコンパイラでコンパイルすることで、機械語プログラムを実行可能な形式に変換する。

これを発展したプログラムを作成するためにAIを用いた方法を模索しようと思う。

# 2024/6/12(Wed)
実際のバイナリ解析には専用のツールを使用することが現実的であると思う。今回はNSAが開発したGhidraを用いようと思う。これは、オープンソースの逆コンパイルツールで、バイナリ解析やリバースエンジニアリングのために使用される。Ghidraを用いるにはjavaが必要なのだが、どのopenjdkがインストール可能か管理者しか確認できないため、苦戦中

# 2024/6/13(Thu)
Ghidraをインストール中に試行していたものとして、AIを用いた逆コンパイルである。  
1. データセットの拡張と強化
    >大量の機械語とC言語のペアを収集し、自動ラベル付けを行う。例えば、Githubなどのオープンソースリポジトリをクローリングしてデータセットを生成する。しかし、Githubにオープンソースが見つからなかった。
```python
import requests

def fetch_code_from_github(repo_url):
    # Github APIを使ってリポジトリからコードを取得する
    response = requests.get(repo_url)
    if response.status_code == 200:
        return response.text
    else:
        return None
```
2. モデルの改良
    >大規模なとrンスフォーマーモデルを使用し、精度を向上させる。Hugging FaceのTransformersライブラリを利用する
```python
from transformers import T5Tokenizer, T5ForConditionalGeneration

tokenizer = T5Tkenizer.from_pretrained('t5-large')
model = T5ForConditionalGeneration.from_pretrained('t5-large')
```
3. トレーニングプロセスの最適化
    >ハイパーパラメータの移動チューニングにはOptunaなどのライブラリを使用する
```python
import optuna
from transformers import Trainer, TrainingArguments

def objective(trial):
    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)
    batch_size = trial.suggest_int('batch_size', 4, 32)
    
    training_args = TrainingArguments(
        output_dir='./results',
        num_train_epochs=3,
        per_device_train_batch_size=batch_size,
        per_device_eval_batch_size=batch_size,
        learning_rate=learning_rate,
        warmup_steps=500,
        weight_decay=0.01,
        logging_dir='./logs',
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
    )
    
    trainer.train()
    eval_results = trainer.evaluate()
    return eval_results["eval_loss"]

study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=20)
```
4. 後処理と最適化
    >生成されたCコードを整形し、可読性を向上させる。PylintやClang-Formatなどのツールを利用する。
```python
import subprocess

def format_code(code):
    formatted_code = subprocess.run(['clang-format'], input=code, text=True, capture_output=True)
    return formatted_code.stdout
```
5. ユーザーインタラクションの改善
    >GUIを使用してユーザーが簡単に操作できるようにする。Streamlitなどのライブラリを使用する。
```python
import streamlit as st

st.title('AI-Based Decompiler')

uploaded_file = st.file_uploader("Choose a binary file")

if uploaded_file is not None:
    machine_code = uploaded_file.read()
    c_code = machine_code_to_c(machine_code)
    st.code(c_code, language='c')
```
これらのようにAIを使った逆コンパイラには、データセットの拡張、モデルの改良、トレーニングプロセスの最適化、生成コードの後処理、ユーザーインターフェースの改善をすることでより発展させることができる。これらを実装することで、より高制度で使いやすい逆コンパイラを実現できる。  
また、Ghidraがうまく活かせられない場合はRadare2を使用してみようと思う。

Ghidraを使用してみた。以下のCソースのバイナリファイルを作成する。
```c
#include <stdio.h>

int sum(int *array, int size) {
    int total = 0;
    for (int i = 0; i < size; i++) {
        total += array[i];
    }
    return total;
}

int main() {
    int numbers[] = {1, 2, 3, 4, 5};
    int result = sum(numbers, 5);
    printf("Sum: %d\n", result);
    return 0;
}
```
そのバイナリファイルを解析して、関数の逆コンパイルをして、C言語のソースを取得する。以下が逆コンパイルした結果である。  
```c
int sum(long param_1,int param_2)

{
  int local_10;
  int local_c;
  
  local_10 = 0;
  for (local_c = 0; local_c < param_2; local_c = local_c + 1) {
    local_10 = local_10 + *(int *)(param_1 + (long)local_c * 4);
  }
  return local_10;
}
```
これがsum関数である。
```c
undefined8 main(void)

{
  uint uVar1;
  long in_FS_OFFSET;
  undefined4 local_28;
  undefined4 local_24;
  undefined4 local_20;
  undefined4 local_1c;
  undefined4 local_18;
  long local_10;
  
  local_10 = *(long *)(in_FS_OFFSET + 0x28);
  local_28 = 1;
  local_24 = 2;
  local_20 = 3;
  local_1c = 4;
  local_18 = 5;
  uVar1 = sum(&local_28,5);
  printf("Sum: %d\n",(ulong)uVar1);
  if (local_10 != *(long *)(in_FS_OFFSET + 0x28)) {
                    /* WARNING: Subroutine does not return */
    __stack_chk_fail();
  }
  return 0;
}
```
これがmain関数である。  
２つとも変数名に変化があり、見づらくなってしまっている。

# 2024/6/14(Fri)
**シンボル名推論について**  
シンボル名推論をAIを用いて行うプロセスは、機械学習や自然言語処理技術を活用して逆コンパイルされたコードの可読性を向上させる方法である。  
シンボル名推論の必要性について、逆コンパイルされたコードでは、元の変数名や関数名が失われることが多いため、自動生成された名前が割り当てられている。これを人間にとって理解しやすい名前にとって理解しやすい名前に変換するためにAIを活用する。  
今回、シンボル推論を試してみた。以下がコードとそれぞれの説明である。
```python
import re
from transformers import GPT2LMHeadModel, GPT2Tokenizer
```
1. **'re'モジュール**
    >`re`モジュールはPythonの標準ライブラリで、正規表現操作を提供する。正規表現は、文字列内のパターンを検索、マッチ、置換するためのツールである。
2. **'transformers'ライブラリ**
    >`transformers`ライブラリはHugging Faceによって提供されるライブラリで、自然言語処理(NLP)のための事前訓練済みモデルを簡単に使用することができる。`GPT2LMHeadModel`はGPT-2モデルの一部であり、テキスト生成を行うために使用される。`GPT2Tokenizer`はトークナイザで、テキストをトークンに変換したり、その逆を行ったりする。
```python
# モデルとトークナイザーのロード
model_name = 'gpt2'
model = GPT2LMHeadModel.from_pretrained(model_name)
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
```
このコードは、PythonでHugging FaceのTransformersライブラリを使用して、GPT-2モデルとその対応するトークナイザーをロードするものである。
```python
# 逆コンパイルされたコードのサンプル
decompiled_code = """
int func_1(int arg1, int arg2) {
    int var1 = arg1 + arg2;
    return var1;
}
"""
```
逆コンパイルされたC言語の例で単純な加算を行う関数である。
```python
# シンボル名推論のためのプレースホルダを定義
def replace_symbols_with_placeholders(code):
    # 変数名と関数名をプレースホルダに置き換える
    code = re.sub(r'\bfunc_1\b', 'FUNCTION_NAME', code)
    code = re.sub(r'\barg1\b', 'ARG_1', code)
    code = re.sub(r'\barg2\b', 'ARG_2', code)
    code = re.sub(r'\bvar1\b', 'VAR_1', code)
    return code
```
この関数は、与えられたコード内の特定のシンボル（変数名と関数名）をプレースホルダーに置き換えるものである。
```python
# プレースホルダを元のコードに適用
code_with_placeholders = replace_symbols_with_placeholders(decompiled_code)
```
`replace_symbols_with_placeholders(decompiled_code)`を実行することで、与えられた逆コンパイルされたコード`decompiled_code`内のシンボル名がプレースホルダーに置き換えられた新しいコード文字列`code_with_placeholders`を得ることができる。
```python
# 推論用のプロンプトを作成
prompt = f"Replace placeholders with meaningful names in the following C code:\n{code_with_placeholders}\n\nModified code:"
```
プレースホルダーに置き換えられたコード'code_with_placeholders'を含む推論用のテキストを生成する。
```python
# トークン化とモデルによる推論
inputs = tokenizer.encode(prompt, return_tensors='pt')
outputs = model.generate(inputs, max_length=300, num_return_sequences=1)
```
与えられたプロンプトをトークン化し、モデルによって生成されたテキストを取得するために使用される。
1. **トークン化**

   - `inputs = tokenizer.encode(prompt, return_tensors='pt')`:
     - `tokenizer.encode(prompt, return_tensors='pt')` は、与えられた `prompt` をトークン化するために使用されます。ここで、`prompt` は推論タスクのために作成したテキストである。
     - `return_tensors='pt'` は、トークン化されたテキストをPyTorchテンソルとして返すことを示しています。これにより、モデルへの入力データがPyTorchのテンソル形式で得られる。

2. **モデルによる推論**

   - `outputs = model.generate(inputs, max_length=300, num_return_sequences=1)`:
     - `model.generate(inputs, max_length=300, num_return_sequences=1)` は、与えられた入力 `inputs` に対してモデルを使用して生成を行うメソッドである。
     - `max_length=300` は、生成されるテキストの最大長を指定します。この場合、最大で300トークンまでのテキストが生成される。
     - `num_return_sequences=1` は、返されるテキストのシーケンス数を指定します。ここでは1つのシーケンスが返される。

3. **結果**

   - `outputs` には、モデルによって生成されたテキストのトークンIDのリストが含まれます。これにより、モデルが与えられたプロンプトに基づいて生成したテキストを取得することができる。

このようにして、事前学習済みの言語モデルを使用して、特定のタスクや問題に対する自動生成の解を取得することができる。
```python
# 推論結果のデコード
generated_code = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(generated_code)
```
モデルによって生成されたテキストのトークンIDから元のテキストを復元し、それを表示するために使用される。
1. **デコード**

   - `generated_code = tokenizer.decode(outputs[0], skip_special_tokens=True)`:
     - `outputs[0]` は、モデルによって生成されたテキストのトークンIDのリストである。ここでは、1つのシーケンスが生成されたため、`outputs` の最初の要素を選択している。
     - `tokenizer.decode()` メソッドは、トークンIDのリストを元のテキストにデコードします。
     - `skip_special_tokens=True` は、特別なトークン（例えば、`[CLS]`、`[SEP]`）をスキップしてデコードすることを示している。これにより、生成されたテキストが自然な文章で表示される。

2. **結果の表示**

   - `print(generated_code)`:
     - `generated_code` 変数には、モデルによって生成された元のコードのテキストが格納されている。
     - `print()` 関数を使って、この生成されたコードをコンソールに表示する。

このコードを実行することで、モデルが生成したテキストを人間が理解しやすい形式で確認することができます。これにより、言語モデルが与えられたプロンプトに基づいてどのようにコードを生成したのかを把握することができる。  
そして、以下が実行結果である。  
![Screenshot from 2024-06-14 20-04-53](https://github.com/PEARLabo/diary/assets/166197812/684bfd0d-012d-43d6-be1a-1177b4a3b728)  
**予想された結果ではなかった。どうしてなのか疑問である。**

# 2024/6/18(Tue)
Ghidra上のPythonインターフェースを用いることで、前回までのGhidraでバイナリファイルを取得してそれをグーグルコラボに移送させる手間が省けることになった。だから、Ghidra上で完結するように思われる。よって、以上の方向性で進めていこうと思う。

# 2024/6/24(Mon)
使用するC言語コード
```c
#include <stdio.h>

int my_sum(int* ,int);

int main(){
	int ary[5] = {1,2,3,4,5};
	int sum = 0;
	int i;

	sum = my_sum(ary,sizeof(ary) / sizeof(int));

	for(i=0;i<5;i++){
		printf("%d ",ary[i]);
	}

	printf("\n");

	printf("sum = %d\n",sum);	

	return 0;
}

int my_sum(int* ary,int size){
	int sum = 0;
	int i;
	
	for(i=0;i<size;i++){
		sum += *(ary + i);
	}

	return sum;
}
```
このC言語コードから機械語を生成して、またC言語に逆アセンブリすると以下のコードが得られる。  
以下はsum関数である。
```c
int my_sum(long param_1,int param_2)

{
  int local_10;
  int local_c;
  
  local_10 = 0;
  for (local_c = 0; local_c < param_2; local_c = local_c + 1) {
    local_10 = local_10 + *(int *)(param_1 + (long)local_c * 4);
  }
  return local_10;
}
```
以下はmain関数である。
```c
undefined8 main(void)

{
  uint uVar1;
  long in_FS_OFFSET;
  int local_30;
  uint local_28 [4];
  undefined4 local_18;
  long local_10;
  
  local_10 = *(long *)(in_FS_OFFSET + 0x28);
  local_28[0] = 1;
  local_28[1] = 2;
  local_28[2] = 3;
  local_28[3] = 4;
  local_18 = 5;
  uVar1 = my_sum(local_28,5);
  for (local_30 = 0; local_30 < 5; local_30 = local_30 + 1) {
    printf("%d ",(ulong)local_28[local_30]);
  }
  putchar(10);
  printf("sum = %d\n",(ulong)uVar1);
  if (local_10 != *(long *)(in_FS_OFFSET + 0x28)) {
                    /* WARNING: Subroutine does not return */
    __stack_chk_fail();
  }
  return 0;
}
```
明らかにシンボル名が見づらいことがよくわかる。ここからシンボル名を我々人間がわかりやすいものに変えることを考える。
