## 論文読み  

<details><summary>enPiTにおける教育効果測定の実践と評価</summary>

- [参考](https://www.jstage.jst.go.jp/article/jssst/32/1/32_1_213/_pdf)

    >論文はenPiT（エンタープライズIT人材育成プログラム）における教育効果の測定と評価に焦点を当てている。具体的には、プログラムへの参加者や教育機関での教育の効果を測定し、評価する方法が提案され、その実践結果が報告されている。

</details>

<details><summary>ファイル検索におけるアクセスログから抽出した関連度の利用</summary>

- [参考](https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_action_common_download&item_id=18831&item_no=1&attribute_id=1&file_no=1)

    >アクセスログから得られた情報を利用してファイル検索の関連度を向上させる方法について述べている。具体的には、ユーザーがファイルをアクセスした履歴などのアクセスログから関連度を抽出し、それを検索のランキングやフィルタリングに利用することが議論されている。この手法は、検索結果の質を向上させ、ユーザーの検索体験を向上させることが期待される。

</details>

<details><summary>キーワード非含有ファイルを検索可能とするファイル間関連度を用いた検索手法の評価</summary>

- [参考](https://www.ieice.org/iss/de/DEWS/DEWS2008/proceedings/files/e10/e10-6.pdf)

    >この手法では、キーワードが含まれていないファイル同士の関連性を評価し、検索結果の精度向上を図っている。  

</details>

<details><summary>On the Job Learning:産学連携による新しいソフトウェア工学教育手法</summary>

- [参考](https://www.sa.cs.titech.ac.jp/~tkobaya/paper/sigss200908tkobaya.pdf)

    >この論文では、情報セキュリティに関する研究に焦点をおいている。情報セキュリティの重要性とその背後にある概念について議論している。コンピュータシステムやネットワークにおけるセキュリティ問題を中心に議論している。現代の情報セキュリティにおける課題や将来の展望についても議論している。

</details>

<details><summary>飛行船制御を題材としたプロジェクト型ソフトウェア開発実習</summary>

- [参考](https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_action_common_download&item_id=67448&item_no=1&attribute_id=1&file_no=1)

    >学生が飛行船の制御システムを開発するプロジェクトである。具体的には、飛行船の飛行パスを制御するアルゴリズムやシステムの開発、制御信号の処理、センサーデータの収集と解析などが含まれる。このプロジェクトを通じて、学生はソフトウェア開発スキルを向上させると同時に、現実世界の問題に対する解決策を提供する能力を養うことができる。

</details>

<details><summary>データマイニング技術を応用したソフトウェア構築・保守支援の研究動向</summary>
             
- [参考](https://www.jstage.jst.go.jp/article/jssst/27/3/27_3_3_13/_pdf)

    >データマイニング技術を利用してソフトウェアの構築や保守を支援する研究の最新動向について述べた論文である。データマイニング技術がソフトウェア開発や保守にどのように応用されているかを述べた論文である。

</details>

<details><summary>CX-Checker:柔軟にカスタマイズ可能なC言語プログラムのコーディングチェッカ</summary>

- [参考](https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_action_common_download&item_id=80670&item_no=1&attribute_id=1&file_no=1)

    >このツールは、C言語プログラムの品質向上を目的として開発され、コーディングスタンダードに準拠しているかを確認している。CX-Checkerの機能、カスタマイズ性、および効果についての内容が議論されている。

</details>

<details><summary>ソフトウェア開発におけるトレーサビリティ確保のための開発環境の検討</summary>

- [参考](https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_action_common_download&item_id=82088&item_no=1&attribute_id=1&file_no=1)

    >ソフトウェア開発におけるトレーサビリティ確保のための開発環境に関する検討に焦点を当てている。具体的には、開発プロセス、ツールの選定、プロジェクト管理手法、要件管理システム、ソースコード管理システムなどが議論されている。要件から設計、実装、テスト、保守までの各段階での変更や影響を追跡し、文書化することが重要であり、適切な開発環境を構築することはプロジェクトの成功に必要である。

</details>

<details><summary>デザインパターンのオブジェクト指向モデル化と支援ツールへの応用</summary>

- [参考](https://www.jstage.jst.go.jp/article/jssst/21/1/21_1_60/_pdf)
    >デザインパターンはソフトウェア設計の再利用可能なテンプレートであり、文書ではそれをオブジェクト指向モデル化する方法や、支援ツールを用いた応用方法について論じられている。このアプローチにより、ソフトウェア開発者は効果的な設計を行い、再利用可能なソリューションを提供することができる。

</details>

<details><summary>制御ソフトウェアの固定小数点演算化ツールの設計と実装</summary>

- [参考](https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_action_common_download&item_id=68338&item_no=1&attribute_id=1&file_no=1)

    >制御ソフトウェアの固定小数点演算化ツールの設計と実装は、言語の選択（車載ソフトウェアは主にC言語）、ビット幅や小数点位置の決定、演算の実装、適切なテストを含む。演算子のオーバーロードや性能と精度のバランスも重要である。

</details>

<details><summary>デザインパターンへのソフトウェア工学的な取り組み</summary>

- [参考](https://www.jstage.jst.go.jp/article/jssst/29/1/29_1_1_130/_pdf)

    >デザインパターンを理解し、適用することでソフトウェアの品質や保守性を向上させることを目指す。

</details>

<details><summary>システムのモデル化　オブジェクト指向モデリング</summary>

- [参考](https://www.jstage.jst.go.jp/article/sicejl1962/46/4/46_4_261/_pdf
)
    >システムの設計や開発において非常に重要な役割を果たす。この手法はシステムをオブジェクトとして抽象化し、それらの間の関係や相互作用を明確にする。具体的には、クラス、オブジェクト、継承、ポリモーフィズム、カプセル化などの概念を活用して、システムの構造や振る舞いをモデル化する。このモデリング手法は、開発者やステークホルダー間でのコミュニケーションを促進し、品質の高いソフトウェアの開発に役立つ。
</details>

<details><summary>進化型計算に基づくシステムの最適化</summary>

- [参考](https://www.jstage.jst.go.jp/article/sicejl1962/35/7/35_7_508/_pdf)

    >進化型計算に基づくシステム最適化は、進化アルゴリズムを使用して、複雑なシステムの最適な設計やパラメータの調整を行う手法であり、解候補を適応度関数に基づいて評価し、適応度の高い個体を選択・変異・交叉させることで、解の探索を進める。
</details>

<details><summary>生物的適応システム　～進化・学習のアルゴリズムと創発システム論～</summary>

- [参考](https://www.jstage.jst.go.jp/article/sicejl1962/40/10/40_10_752/_pdf)

    >進化や学習の原理を基にしたアルゴリズムを通じて、生物的な適応性や創発するシステムを探求している。自然界の生物が環境にどのように適応し、進化しているかを理解し、それをコンピュータ上で模倣する手法が焦点である。
</details>

<details><summary>遺伝的アルゴリズムにおける世代交代モデルの提案と評価</summary>

- [参考](https://www.jstage.jst.go.jp/article/jjsai/12/5/12_734/_pdf/-char/ja)
    >遺伝的アルゴリズムにおける世代交代モデルは、適応度の向上、収束速度、多様性の維持などに大きな影響を与えるため、問題の特性や目的に応じて適切なモデルを選択することが重要である。混合戦略や適切的モデルの導入は、それぞれのモデルの利点を組み合わせることで、より効果的な最適化を実現する可能性がある。
</details>

<details><summary>Wikiを導入したソフトウェア開発コミュニケーションの分析</summary>

- [参考](https://www.jstage.jst.go.jp/article/jsaisigtwo/2009/KSN-006/2009_02/_pdf)
    >Wikiを導入したソフトウェア開発コミュニケーションの分析では、情報共有、コラボレーション、ナレッジマネジメント、コミュニケーションパターンの観点から評価が行われる。Wikiは情報の共有や編集を容易にし、プロジェクトのナレッジを管理しやすくする。分析では、これらの要素がプロジェクトの成功にどの程度貢献しているかが評価される。
</details>

<details><summary>モデル変換とコード生成機能を有する組み込み制御ソフトウェア開発支援ツール</summary>

- [参考](https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_action_common_download&item_id=109512&item_no=1&attribute_id=1&file_no=1)
    >組み込み制御ソフトウェア開発支援ツールには、モデル変換とコード生成機能が組み込まれている。これにより、モデルベースの開発アプローチを採用し、モデルから自動的にコードを生成することが可能である。これにより、開発プロセスの効率化やエラーの削減が図られる。
</details>

<details><summary>ソフトウェア開発における知識の共有と再利用</summary>

- [参考](https://www.jstage.jst.go.jp/article/jjsai/9/1/9_34/_pdf)
    >ソフトウェア開発における知識の共有と再利用は、効率的な開発プロセスのために重要である。これを実現する方法はいくつかある。例えば、コーディング制約やドキュメント化された設計ガイドラインを作成し、チーム内で共有することが挙げられる。また、コードリポジトリやドキュメント管理システムを活用して、コードやドキュメントを共有し、再利用可能なコンポーネントやパターンを継続的に蓄積していくことも重要である。さらに、チーム内での定期的なコードレビューやペアプログラミングを通じて、知識の共有と品質の向上えお図ることも効果的である。
</details>

<details><summary>プログラムの自動作成</summary>

- [参考](https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_action_common_download&item_id=7042&item_no=1&attribute_id=1&file_no=1)
    >プログラムの自動生成に関数する研究は、AIの進化と共に拡大しているが、現時点では複雑なタスクや特定の文脈においては限界がある。特に、人間の創造性や抽象的な問題解決能力を模倣することは難しく、現実世界の複雑な状況に適応する能力にも限界がある。ソフトウェア工学は、ソフトウェアの開発、保守、および管理に関する原則や手法を研究する。プログラムの自動生成は、これらの原則や手法を活用して、効率的かつ信頼性の高いソフトウェアを生成することを目指している。特に、形式手法やモデル駆動型開発などのアプローチが、自動生成技術との統合において重要な役割を果たしている。
</details>

<details><summary>ALRIGHT:ソフトウェア開発PBLでの設計文書インスペクションの振り返りを支援する可視化アプリケーションの開発</summary>

- [参考](https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://www.jstage.jst.go.jp/article/repit/2024/0/2024_9/_article/-char/ja&ved=2ahUKEwjDs-nrkMGGAxU6hlYBHUtyB4sQFnoECBcQAQ&usg=AOvVaw2UUS8T35c9LGri3DPlXcKF)
    >このアプリケーションは、チームメンバーがせえっ京文書を共有し、レビューする際に視覚的な手法を使用して効率的なコラボレーションを促進する。論文では、アプリケーションの設計、実装、および評価に関する詳細が提供され、実際の効果や可能性について議論されている。
</details>

<details><summary>Fine-tuning can distort pretrauned features and underperform out-of-distribution</summary>

- [参考](https://arxiv.org/pdf/2202.10054)
    >### 背景  
    >**事前学習とファインチューニング**:最近のディープラーニングでは、一般的な大規模データセットで事前学習されたモデルを利用し、そのモデルを特定のタスクやデータセットに適合させるためにファインチューニングする手法が一般的である。  
    **分布外データにおけるパフォーマンス**:一般的に、ファインチューニングされたモデルは分布内データには良好に対応しますが、分布外データに対するパフォーマンスが懸念されている。  
    >### 研究の動機
    >モデルが分布外データに対してなぜパフォーマンスが低下するのかを理解し、ファインチューニングの手法を改善することが、この研究の中心的なテーマである。
    >### 主要な発見  
    >1.**特徴の歪み**:
    >- ファインチューニングは、事前学習されたモデルの学習済み特徴を歪め、操作を加えてしまうことがある。これは新しいデータセットに適応する際に、オリジナルの特徴が変化するためである。
    >- 特徴が歪むことで、モデルの一般化能力が損なわれ、特に分布外データに対して対応できなくなるリスクがある。  
    >2.**実験と解析**:
    >- 複数の実験を通じて、ファインチューニングがどのように特徴を変え、分布外データに対してどの程度の影響を与えるかを検証している。
    >- 結果として、ファインチューニングは分布内のパフォーマンスを向上させる一方で、分布外データでのパフォーマンスに悪影響を及ぼすことが確認された。
    >### 解決策の提案
    >- **レギュラリゼーションとレイヤーの凍結**:モデルの安定した特性を維持しつつ、新しいタスクに柔軟に適応させるために、特定のレイヤーを凍結することが有用であると提案されている。
    >- **構造的なアプローチ**:特徴の操作を最小限に抑え、むしろ事前学習された特徴の利点を維持するための戦略についても考察されている。
    >### 結論
    >この研究は、ファインチューニングが提供するメリットと同時に、それが持つ潜在的なデメリットに光を当てている。特に分布外データへの一般化能力の低下について、注意深く検討する必要があると警告している。これにより、研究者や実務者は、モデルを新しいデータセットやタスクに適応させる際の手法について再考し、調整する必要があるとしている。
</details>

<details><summary>SpotTune: Transfer Learning Through Adaptive Fine-Tuning</summary>

- [参考](https://openaccess.thecvf.com/content_CVPR_2019/papers/Guo_SpotTune_Transfer_Learning_Through_Adaptive_Fine-Tuning_CVPR_2019_paper.pdf)
    >### 問題設定
    >転移学習では、大規模なデータセットで訓練されたモデルを小規模データセットの異なるタスクに適用することがしばしばある。この際、どの層を固定し、どの層を微調整するかを選択することが重要となる。
    >### 提案手法(SpotTune)
    >提案されたSpotTuneは、各サンプルに対して異なる層の微調整を動的に選択することを可能にする手法である。特に、従来の方法とは異なり、すべてのサンプルに対して同じ層構成を固定または微調整するのではなく、サンプルごとに微調整が必要な層を自動的に決定する。
    >### 技術的詳細
    >SpotTuneは、適応的なハイパーネットワークを利用して各サンプルに対する最適な微調整パスを選択する。これにより、パフォーマンスを最大化するための動的かつ効率的なモデルチューニングを実現する。
    >### 実験と結果
    >提案手法は複数のデータセットを用いた実験で評価され、従来の微調整方法よりも優れた性能を示した。特に、異なるタスクにおける適応的な層選択により、モデルの柔軟性と精度が向上することが確認された。
</details>

<details><summary>Using a Decompiler for Real-World Source Recovery</summary>

- [参考](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=18e857c36b5627c9f19f0da978e709ab0617a0a7)
    >### 目的
    >この研究の主な目的は、逆コンパイルを使用して実世界のソフトウェアバイナリから有用なソースコードを復元する方法と、その実用性について評価することである。
    >### 背景
    >古いソフトウェアにおいてソースコードが行方不明になっている場合、逆コンパイルによって得られたコードを基にして保守やアップデートを行うことができる。マルウェアなどのセキュリティ脅威に対し、その動作を分析するために逆コンパイラが使われる。逆コンパイルにより、バイナリの振る舞いを理解し、脆弱性や不正行為を特定することが可能である。異なるプラットフォーム間でソフトウェアを移植する際、オリジナルのソースコードがない場合には逆コンパイルによるソースコードの再現が役に立つ。このような様々な場面で逆コンパイルが用いられる。
    >### 手法
    >ここでは、特定の逆コンパイラを用いて、どのように実際のソフトウェアバイナリからソースコードを再現できるかを示している。また、その手法の限界や課題についても考察されている。例えば、コンパイルされたコードの最適化が逆コンパイルプロセスに与える影響などを分析する。
    >### 結果
    >実際のソフトウェアを対象としたケーススタディを通して、提案手法がどの程度の効果を発揮するかを示しています。これにより、逆コンパイルが実際のソフトウェアプロジェクトにおけるソースコードの理解に役立つことが実証された。
    >### 結論
    >逆コンパイルは完全なソースコード復元を保証するものではないが、バイナリからの知識抽出やセキュリティ対策の評価など、多くの実用的な場面で有用であることを示している。また、研究者は逆コンパイル技術のさらなる改善の必要性を強調している。  
</details>

<details><summary>Towards Neural Decompilation</summary>

- [参考](https://arxiv.org/pdf/1905.08325)
    >### 背景と動機
    >逆コンパイルは、セキュリティ分析、ソフトウェア保守、互換性のための解析で必要となることがありますが、従来の逆コンパイラは限界がある。特に、コードの複雑さやコンパイラの最適化により、逆コンパイルされコードの可読性が損なわれることがある。
    >ニューラルネットワークの進展を背景に、機械学習技術を応用した逆コンパイルの可能性を探ることで、より高精度な復元が期待される。
    >### 提案手法
    >本研究では、ニューラルネットワークを活用した新しいアプローチを提案している。具体的にはエンコーダ・デコーダアーキテクチャを使用し、バイナリコードを入力として取り込み、それを高水準なソースコードに変換する。
    >モデルは、Seq2Seqと呼ばれる手法に基づき、バイナリコードの命令列を直接、対応する高水準プログラム構造にマッピングする。  
    >### 実験と評価
    >提案モデルの性能を評価するため、様々な種類の入力バイナリに対して実験を行った。この評価には、既存の逆コンパイラと比較し、可読性や構造の再現性、正確性などの指標を用いて性能を分析した。
    >結果として、ニューラルネットワークによる逆コンパイルは一部のケースで従来手法を上回る結果を示し、特にオブジェクト指向プログラムや制御フローの複雑なコードに対して効果的であることが確認された。
    >### 課題と今後の研究
    >新しいアプローチにはなお解決すべき課題が存在し、特に学習データセットの充実と、様々なプログラミング言語やコンパイラ設定への適応が必要である。
    >今後の研究では、より多くのデータを用いてモデルの精度を向上させることや、異なるプログラミング言語に対する一般化能力を高めることが目指されている。  
</details>

<details><summary>Fine-tuning gpt-2 to patch programs, is it worth it?.</summary>

- [参考](https://real.mtak.hu/150350/1/Lajko-ISSQ2022.pdf)
    > GPT-2が、コードやプログラムにも適用可能かを調査している。そのために、著者たちはコードの「パッチ」をあてる、すなわちプログラムのバグ修正や機能改善のためにモデルを利用する方法を考えた。  
    > この研究では、プログラムに関連するデータセットを使って、GPT-2をファインチューニングし、コードの修正に活用できるかを試行した。  
    > 実験のプロセスでは、一般的なプログラムエラーやバグを含むデータセットを集め、それを元にGPT-2にファインチューニングを行った。次いで、ファインチューニングされたモデルがコードのパッチを生成できるか、あるいはどの程度効果的にバグを修正できるかをテストした。  
    > 結果として、ファインチューニングされたGPT-2は、ある程度のプログラム修正を自動で生成できることが確認されたが、すべてのケースで最適な解決策を提案するわけではないことも明らかになった。つまり、GPT-2は特定のシンプルな問題に対するアプローチとしては有用であるものの、より複雑なバグ修正には限界があることが示唆される。さらに、研究はGPT-2のサイズやファインチューニングに使ったデータセットの影響についても考察している。より大きなモデルや多様で質の高いデータセットを使用した場合、パフォーマンス向上の可能性がある。  
    > 結論として、GPT-2をファインチューニングしてプログラム修正に利用することは一定の価値があるものの、現状では補助的なツールとしての活用が妥当であり、この技術のさらなる進化が必要とされている。  
</details>

<details><summary>深層学習を用いた時系列データの要約と分類</summary>

- [参考](https://db-event.jpn.org/deim2018/data/papers/241.pdf)
    > 時系列データを扱うための深層学習技術を用いた手法について研究している。
    > 1. **時系列データの重要性**: 時系列データは金融市場や気象データ、センサーデータなどさまざまな領域で重要な役割を果たしている。これらのデータを効果的に分析することは、様々な意思決定や予測に役立つ。

    > 2. **深層学習の利点**: 深層学習は、大量のデータから特徴を自動で抽出し、人間が設計するよりも効率的にパターンを捉える能力がある。特に、時系列データの複雑な依存関係やパターンを学ぶのに適している。

    > 3. **要約と分類の手法**: 論文では、深層学習を用いて時系列データを要約し、それを基に分類を行う手法が紹介されている。まず、データの要約を通じて重要な特徴を抽出し、その特徴を用いて分類を行う。

    > 4. **モデルの設計と評価**: 山室氏らは、時系列データに特化した深層学習モデル（例えば、リカレントニューラルネットワーク（RNN）やその派生モデル）を設計し、それを用いて実験を行った。評価では、モデルがどれほど効果的にデータを要約し、分類が行えるかを検証し、他の手法と比較している。

    > 5. **実験結果と応用可能性**: 研究の結果、提案された深層学習モデルが従来の手法に対して優れた性能を示すことが確認された。また、この手法はさまざまな時系列データの分類問題に応用可能であることが示されている。

    > この研究は、時系列データの分析における深層学習の有効性を示し、今後の応用範囲を広げるための基盤を提供するもの。
</details>

<details><summary>深層学習による自動要約</summary>

- [参考](https://www.jstage.jst.go.jp/article/jjsai/34/4/34_446/_pdf)
> 1. **自動要約の重要性**
> 膨大な情報が日々生成される現代では、重要な情報を効率的に抽出するための自動要約技術が非常に重要である。この技術は特に長文のテキストを迅速に把握するのに使える。
> 2. **深層学習の活用**
> 西川氏の論文では、深層学習を利用した自動要約のアプローチが紹介されている。従来の手法に比べ、深層学習はより自然で人間に近い要約を生成する能力をもっている。
> 3. **概要と抽出型要約**
> 自動要約には主に「抽出型要約」と「要約生成」という2つのタイプがある。抽出型要約は、元の文章から重要な部分をそのまま抜き出す手法である。一方で、要約生成は文章全体を理解し、新たな文章を生成する。この論文では、特に抽出型要約に焦点を当て、深層学習モデルをどのように適用するかを説明している。
> 4. **モデルの訓練と評価**
> 論文では、実際に深層学習を用いて要約モデルを訓練し、その性能評価を行った結果が示されている。具体的には、教師あり学習を通したモデルの改善や、評価指標を用いた要約品質の検証が行われている。
> 5. **結果と今後の展望**
> 論文の結果として、深層学習を用いた自動要約は、従来の手法に比べて優れた結果を示していることが明らかになった。また、今後の展望として、日本語の特性を考慮したさらなるモデルの改善や、異なる分野への適用可能性が提案されている。
> この論文は、自動要約技術の発展における深層学習の重要性を示し、今後の研究の方向性を示す重要な研究である。
</details>

<details><summary>日本語機能表現辞書の編纂</summary>

- [参考](https://www.jstage.jst.go.jp/article/jnlp1994/14/5/14_5_123/_pdf)
> 1. **研究の背景と目的**:
> 日本語の機能表現は、文法的機能を持つ表現、意味を補助したり修飾したりする表現などが含まれているが、それらは多様で複雑であるため、体系的な整理が難しいという問題がある。  
> 著者らはこれらの表現を体系的に整理し、辞書形式で提供することで、自然言語処理や言語研究の基盤的なリソースを構築することを目的としている。  
> 2. **データ収集と分類**:
> 著者らは、言語資料や既存の文献をもとに、日本語の代表的な機能表現を収集した。  
> 収集した表現は、形式、意味、用法などの観点から詳細に分類された。分類基準としては、分類基準としては、文法的機能（例：テンス、ムード）、意味的役割（例：因果関係、目的）などがある。  
> 3. **辞書の編纂**:
> 各機能表現について、表現そのものの形式、使用される文脈、関連する例文、意味や機能の解説などの情報を整理した。  
> 辞書は電子的な形式でも提供され、自然言語処理システムにも容易に統合できるように設計されている。  
> 4. **自然言語処理への応用**:
> 機械翻訳や自動要約、文法チェック、情報抽出などの自然言語処理タスクでの利用を想定している。特に、日本語の表現の多様性とニュアンスを適切に処理するために、この辞書が有用となることが強調されている。  
> 5. **言語教育への貢献**:
> 辞書は、日本語学習者や教師にとっても有益なリソースであり、表現の使い方を学ぶための教材としても活用可能である。  
>
> この研究は、日本語の機能表現を体系的に捉え、それを利用しやすい形で提供することで、言語研究と技術応用の両面から、日本語理解の深化に貢献している。この辞書を通して、より正確で深い日本語の解析や生成が可能になることが期待されている。  
</details>

<details><summary>大規模言語モデルを用いた分の言い換えによる文脈の自然言語表現</summary>

- [参考](https://www.jstage.jst.go.jp/article/pjsai/JSAI2024/0/JSAI2024_3T1OS6a01/_pdf)
> 1. **研究背景**:
> 自然言語処理において、文の意味を保持しつつ文を言い換えることは重要な課題である。言い換え技術は、機械翻訳、要約生成、対話システムなど多くの応用に寄与する。  
> 大規模言語モデル（例えばBERTやGPTなど）の進化により、より自然で文脈に応じた言い換えが可能になっている。  
> 2. **研究の目的**:
> この研究は、大規模言語モデルを活用して、文の文脈を考慮した自然な言い換えを生成する手法を開発することを目指している。  
> 特に、文脈を保ちながら、多様で適切な言い換えを自動的に生成できるアルゴリズムの構築に着目している。  
> 3. **手法**:
> 提案された手法では、大規模言語モデルを利用して、与えられた文の文脈を理解し、その文脈を理解し、その文脈に応じた言い換え表現を生成する。  
> モデルはまず入力文の意味を解析し、その後、意味を維持しながら異なる表現を生成するプロセスを経る。
> 4. **実験と評価**:
> 著者らは提案手法の有効性を検証するために、いくつかの実験を行っている。これには、人間の評価者による主観的な評価や、自動評価指標を用いた定量的な評価が含まれる。
> 評価結果は、提案手法が従来の手法よりも自然で一貫した文脈を維持した言い換えを生成できることを示している。
> 5. **応用と今後の展望**:
> この技術は、対話システムにおけるユーザーインタフェースの改善、教育分野での教材開発、およびコンテンツ制作における自動化ツールとして応用が期待されている。
> 今後の課題としては、より多様な言い換え生成のためのモデルの改善や、特定の文脈に対する適応力の向上が挙げられる。

> この研究は、言い換え技術の精度を向上させるだけでなく、幅広い自然言語処理タスクへの応用可能性を示しており、言語モデルの実用化に向けた重要な一歩となっている。
</details>

<details><summary>大規模言語モデルを用いたIoTファームウェア脆弱性検出のための逆コンパイル手法の提案</summary>

- [参考](https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_uri&item_id=240772&file_id=1&file_no=1)  
> 1. **背景と動機**:
> IoTデバイスは生活の多くの場面で利用されているが、そのファームウェアはしばしばセキュリティが脆弱である。これにより、攻撃者がデバイスを悪用する危険性が高くなる。  
>  ファームウェアの解析、特に逆コンパイルはセキュリティ評価の重要なプロセスであるが、そのプロセスには高度な専門知識と多大な時間を要する。  
> 2. **研究の目的**:
> 大規模言語モデルを活用して、ファームウェアのバイナリコードをより効率的に解析し、潜在的な潜在的な脆弱性を自動的に検出する手法を開発することを目指している。  
> 3. **手法**:
> 提案手法では、まずIoTデバイスのバイナリコードを抽出し、大規模言語モデルにより解析する。言語モデルは自然言語処理技術を基盤としており、コードの構造と動作を理解し、潜在的な脆弱性を指摘する。  
> モデルは、逆コンパイル過程で生成される中間表現を分析し、脆弱性パターンを検出するために訓練されている。  
> 4. **実験と評価**:
> 提案された手法はいくつかの既存のIoTデバイスファームウェアに適用され、従来の逆コンパイル手法と比較されている。  
> 実験結果によれば、提案手法はより高い精度で脆弱性を検出できることが確認されており、解析に要する時間も短縮されている。  
> 5. **応用と今後の課題**:
> この手法は、IoTデバイスのセキュリティ向上に寄与し、ファームウェア開発やデブロイメントの際のセキュリティ評価ツールとして利用されることが期待される。    
> 次のステップとして、さらなる精度向上のためのモデルの改良や、異なる種類のバイナリフォーマットへの対応、実用的なツールの開発が挙げられる。
  
> この研究は、IoTセキュリティの強化に向けた重要な貢献をしている。大規模言語モデルを活用することで、手間がかかるプロセスを自動化し、かつ成果を向上させることで、IoTデバイスの安全性を高めることを狙っている。
</details>

<details><summary>自然言語処理を用いた悪性URLクエリ検知に対する埋め込み層変更バックドア攻撃の攻撃耐性評価</summary>

- [参考](https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_action_common_download&item_id=240993&item_no=1&attribute_id=1&file_no=1)
> 1. **研究の背景と目的**:
> 悪性URLの検知は、インターネットセキュリティにおいて重要な課題である。これを高精度で実現するために、NLP技術や機械学習モデルが広く利用されている。  
> 一方で、これらのモデルは「バックドア攻撃」に対して脆弱であり、攻撃者がモデル内に意図的な脆弱性を組み込むことで、誤検知を誘発する可能性がある。
> この研究の目的は、特に「埋め込み層変更」と呼ばれる方法を用いたバックドア攻撃に対するモデルの耐性を評価することである。
> 2. **攻撃手法**:
> 「埋め込み層変更バックドア攻撃」とは、モデルの埋め込み層を標的とし、意図的に改変することで、特定のトリガによって予測を操れるようにする攻撃手法である。
> この方法を用いることで、普段の検出精度を維持しつつ、特定の不正クエリが意図的に逃れるように操作できてしまう。
> 3. **実験と評価**:
> 著者らは、実際に悪性URL検知モデルにこの攻撃を適用し、どの程度の精度で攻撃が成功するかを評価した。
> また、攻撃に対するモデルの耐性を強化するために、いくつかの防御策も検討されている。
> これには、モデルのトレーニングデータを改良するアプローチや、ロバスト性を高めるための新たなトレーニング手法の導入が含まれる。
> 4. **結果と考察**:
> 結果として、このタイプのバックドア攻撃が成功する条件や、その影響の範囲が明らかにされた。
> 攻撃に対する防御策について、提案された手法はある程度の攻撃耐性を持つことが確認されたものの、完全な防御にはさらなる研究が必要であることが示された。
> 5. **今後の展望**:
> 今後はさらに効果的な防御策の開発や、他の種類の攻撃手法に対する耐性評価が必要である。
> 特に、実世界での適用を考慮したモデルの改良、およびセキュリティ評価フレームワークの構築が重要とされている。

> この研究は、NLPを用いたシステムの安全性確保において、潜在的な脅威を理解し、それに対する防御策を講じるために重要なインサイトを提供している。
</details>

<details><summary>LLM はユーザーに適したテキストの難易度を暗黙的に考慮しているのか？</summary>

- [参考](https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/A3-6.pdf)
> 1. **研究の背景**:
> 大規模言語モデルは、テキスト生成や質問応答などのタスクにおいて、ユーザーに対する親和性が重要である。
> 特に、教育やカスタマーサポートの分野では、ユーザーの理解度に適した情報を提供することが求められている。
> 2. **研究の目的**:
> この研究の主な目的は、LLMが生成するテキストがユーザーの知識レベルや情報処理能力に適応できているかどうかを探ることである。
> 具体的には、モデルの出力が無意識のうちに難易度を調整しているかを評価する。
> 3. **方法論**:
> 実験では、異なる理解レベルを持つと想定されるユーザーグループごとに、同一の質問をLLMに投げかける。
> 生成されたテキストの難易度を、その複雑さや専門性を評価する指標を用いて分析する。
> 4. **評価と結果**:
> 結果として、LLMはある程度までユーザーの理解度に応じたテキストを生成できることが確認されたが、これは明示的にデザインされたわけではなく、むしろモデルが持つ膨大なデータによる副次的なものと考えれる。
> いくつかのケースでは、複雑な専門用語の使用によって不適切なレベルの情報を提供してしまうことも観察された。
> 5. **考察と結論**:
> 研究は、LLMの強みである幅広いデータによる多様な表現の生成能力を強化する一方で、ユーザーのプロファイルを明示的に考慮した生成モデルの必要性に言及している。
> 将来的に、ユーザーの理解度にリアルタイムで適応できるようなアルゴリズムの開発が求められる。

> この研究は、自然言語処理システムにおけるユーザー経験向上の観点から、LLMの利用方法を再考するアプローチを提供している。
</details>

<details><summary>生成モデルに関するセキュリティとプライバシの現状</summary>

- [参考](https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_action_common_download&item_id=240785&item_no=1&attribute_id=1&file_no=1)
> 1. **背景**:
> 生成モデルは、テキスト、画像、音声などの多様な形式のデータを自動生成するために用いられ、様々な分野で革新的な応用がされている。
> しかし、生成モデルの普及に伴い、セキュリティとプライバシに関する新たな問題が浮上してきている。
> 2. **セキュリティの課題**:
> 生成モデルはフェイクコンテンツを生成する能力を持つため、偽情報の拡散に悪用される可能性がある。
> また、生成モデル自体が攻撃を受けることもある。例えば、バックドア攻撃やモデルの投毒(poisoning)などにより、意図的に誤った出力を導き出すことができる。
> 3. **プライバシーの問題**:
> モデルがプライベートなデータを学習に使用する場合、そのデータが生成した出力に含まれる可能性があるため、プライバシーの侵害が懸念される。
> 特に、訓練データから学習した情報が意図せず漏洩する「メモリリーク」が問題とされている。
> 4. **現状の技術的対応**:
> フェイクコンテンツ対策として、生成物の真偽を判別する技術の開発が進められている。
> プライバシー保護のために、差分プライバシーやフェデレーテッドラーニングなどの手法が提案されているが、完全な解決には至っていない。
> 5. **結論と今後の展望**:
> 生成モデルに利点を最大化するためには、同時に考慮すべきセキュリティとプライバシーの課題が多く存在し、これらのバランスを取ることが研究者にとっての大きな挑戦である。
> 未来の展望としては、技術的進展に加えて、倫理、法律的な対応も含めた多面的なアプローチが必要であると指摘している。

> この論文は、生成モデルの後半な利用が進む中で、セキュリティとプライバシーに関する重要な課題を明らかにし、これらの課題に対処するための枠組みやアプローチを検討している。
</details>

<details><summary>大規模言語モデルを用いた自律型詐欺サイト分析システム</summary>

- [参考](https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_action_common_download&item_id=240888&item_no=1&attribute_id=1&file_no=1)
> 1. **研究の背景**:
> インターネット上の詐欺サイトは、個人情報の盗難や金融詐欺を目的としており、ますます巧妙化している。
> こうしたサイトを迅速かつ正確に検出することは、ネットセキュリティにおける重大な課題である。
> 2. **研究の目的**:
> 本研究の目的は、大規模言語モデルを用いて詐欺サイトを自律的に分析し、高い精度で迅速に識別するシステムを開発することである。
> 3. **システムの概要**:
> システムは、大規模言語モデルを利用して、サイトのテキストコンテンツやメタデータを解析し、詐欺の兆候を自動で検出する。
> モデルは言語パターンやスタイル、典型的な詐欺手法に基づくキーワードの出現頻度などを分析し、サイトの危険度を評価する。
> 4. **実験と評価**:
> システムの精度を評価するために、既知の詐欺サイトと合法サイトを含むデータセットを用いて実験を行った。
> 結果として、自律型詐欺サイト分析システムは、高井正解率と低いご認識率で詐欺サイトを検出できることが示された。
> 5. **応用と利点**:
> このシステムは、企業のセキュリティチームが日常的なURL検査プロセスに統合することで、セキュリティリスクを低減し、迅速な対応を可能にする。
> 自律型であるため、人的リソースを節約し、スケーラビリティも兼ね備えている。
> 6. **今後の課題と展望**:
> システムの適用範囲拡大として、より多様な言語や市場向けに対応する必要がある。
> 絶えず進化する詐欺手法に対して、モデルの更新と検出能力の向上が求められる。

> この研究は、セキュリティ分野におけるAIの利用の可能性を拓くものであり、詐欺サイトの迅速な検知と対策を支援する有効なアプローチを提供している。
</details>

<details><summary>大規模言語モデルによるシミュレーション自動生成</summary>

> [参考](https://www.jstage.jst.go.jp/article/pjsai/JSAI2024/0/JSAI2024_1K4OS15a02/_pdf)
> 1. **研究の背景**:
> シミュレーションは科学、工学、経済学などの多くの分野で重要な役割を果たす。しかし、複雑なシミュレーションを構築することは専門的なスキルと多大な時間を要する。
> 最近のAI技術、特に大規模言語モデルは自然言語を通じて複雑なタスクを理解し、遂行する能力が高く評価されている。
> 2. **研究の目的**:
> 本研究の目的は、シミュレーションの設計と構築を自動化するために、大規模言語モデルの能力を活用することである。
> 特に、ユーザーがシミュレーションの要件を自然言語で記述し、その記述を基に言語モデルが自動的にシミュレーションを生成するシステムを開発することを目指している。
> 3. **手法**:
> 提案された手法では、シミュレーションの要件を自然言語で記述し、そのテキストを大規模言語モデルが解析する。
> モデルは解析結果を基に、シミュレーションに必要な要素やその関係を自動的に構築する。
> 生成されたシミュレーションは、ユーザーによる微調整が可能で、さらなる細部調整を通じて目的に合ったシミュレーションが実現される。
> 4. **実験と評価**:
> いくつかのケーススタディを通じて、このアプローチの有効性が検証されている。これには具体的なシミュレーションシナリオの生成とその正確性、効率性の評価が含まれる。
> 結果は提案手法が従来の手動によるシミュレーション構築と比較して大幅に時間を節約できることを示した。
> 5. **利点と応用**:
> このシステムは、シミュレーション構築の時間とコストを削減し、専門家以外のユーザーにも複雑なシミュレーションを利用する機会を提供する。
> 教育、研究開発、産業応用など、幅広い分野での応用が期待される。
> 6. **今後の展望**:
> 言語モデルをより専門的なシミュレーション分野に適用するためのさらなるトレーニングや、モデルの精度向上が進められる予定である。
> システムの拡張性を考慮した継続的な開発が見込まれる。

> この研究は、AI技術によるプロセス自動化の可能性を示し、シミュレーション生成の新しいパラダイムを提供している。
</details>

<details><summary>AMR 複文構文パターン辞書作成および意味的曖昧性解消実験</summary>

- [参考](https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_action_common_download&item_id=208162&item_no=1&attribute_id=1&file_no=1)
> 抽象意味表現(AMR)と複雑な文構造の解析におけるその応用に関するものである。AMR PropBankとの関係や複雑な文パターン辞書の開発など、AMRの複雑さを掘り下げている。また、意味論的な曖昧さの解決と、解析におけるリレーショナルAMRの使用についても検討する。
> 1. 自然言語処理における抽象意味表現(AMR)の重要性は何か。  
> 抽象意味表現(AMR)は、文章の構造化された意味表現を提供することで、自然言語処理(NLP)で重要な役割を果たす。その重要性を強調するポイントをいくつか示す。  
> 1.1. 意味理解:  AMRは、使用される特定の単語に依存しない方法で文章の意味を捉える。これにより、基礎となる意味をより深く理解出来る。これは、機械翻訳、質問応答、情報検索などのタスクにとって重要である。  
> 1.2. 標準化: AMRは、文章の意味を表現するための標準化されたフレームワークとして機能し、様々なNLPシステムの比較と評価を容易にする。この標準化は、モデルのトレーニングとテストのためのベンチマークとデータセットの作成に役立つ。  
> 1.3. 曖昧さの処理: AMRは、文章内の概念間の関係を明確に表現することで、意味の曖昧さに対処するように設計されている。これは、多様性と構文のバリエーションから生じる曖昧さを解決するのに役立つ。  
> 1.4. 他のフレームワークとの統合: AMRは、Universal Dependencies(UD)などの他の言語フレームワークと統合できるため様々なNLPアプリケーションでの有用性が向上する。この統合により、構文情報と意味情報を組み合わせることで、より包括的な言語分析が可能になる。  
> 1.5. 複雑な文の解析の促進: AMRを使用すると、複雑な文の構造を解析できる。これは、微妙な言語を理解するために不可欠であり、対話システムや高度なAIなどの高度な理解を必要とするアプリケーションにも不可欠である。   
>
> 全体として、AMRはNLPの強力なツールであり、人間の言語を意味レベルで処理および理解する能力を強化し、、人工知能や計算言語学の様々なアプリケーションに非常に役立つ。  
>
> 2. この論文では、AMR解析における意味上の曖昧さの解決にどのように取り組んでいるか。  
> 2.1. リレーショナル AMR: この論文では、文中の様々なエンティティとアクションの関係を捉えることに重点を置いたリレーショナル AMRの概念について説明する。このアプローチは、文の様々な構成要素が互いにどのように相互作用するするかを強調する構造化された表現を提供することで、曖昧さを明確にするのに役立つ。  
> 2.2. 複雑な文のパターン辞書: 複雑な文の解析を支援するツールとして、複雑な文のパターン辞書の開発が言及されている。この辞書は、複雑な文の構造から生じる曖昧さを識別して解決するのに役立ち、それによってAMR 解析の精度が向上する。  
> 2.3. BERTによる微調整: この論文では、AMR 解析モデルの微調整にBERTを使用することを強調している。BERTの言語の文脈的理解を活用することで、モデルは意味の曖昧さをより適切に処理し、全体的な解析パフォーマンスを向上させることができる。  
> 2.4. 評価指標: 論文では、AMR解析システムのパフォーマンスを評価するための評価指標として、精度、再現度、Fスコアの使用について概説している。これらの指標は、システムが曖昧さをどの程度解決し、文の意味を正確に表現しているかを定量化することに役立つ。
> 2.5. 多様なデータセットでのトレーニング: 論文では、ウィキペディアやAMR PropBankから派生したデータセットなど、多様なデータセットでAMR解析モデルをトレーニングすることの重要性を強調している。様々な言語構造やコンテキストに触れることで、モデルが意味の曖昧さをより効果的に処理できるようになる。
> 
> これらの戦略を採用することで、論文では、意味の曖昧さをより適切に解決して言語をより正確で意味のある表現につながるために、AMR解析を強化する方法を示している。  
> 
> 3. この文書で説明されているAMRとユニバーサル依存関係(UD)の関係について説明する。  
> 3.1. 補完的なフレームワーク: AMRとUDは、言語の分析において異なるものの補完的な目的を果たす。AMRは文の意味的意味を捉えることを重点に置いているが、UDは文中の単語間の文法関係を記述する構文フレームワークを提供する。これらを組み合わせることで、意味情報と構文情報の両方を統合し、言語をより包括的に理解出来る。  
> 3.2. 依存関係構造: この文書では、AMRをUDが提供する依存関係構造に合わせることができることを強調する。このあわせにより、意味的役割と関係が構文的依存関係にどのように対応するかをより微妙に表現できる。AMR表現をUD構造にマッピングすることで、文法形式から意味がどのように構築されるかを分析できるようになった。  
> 3.3. 構文解析手法: この論文では、AMRとUDの両方を活用できる構文解析手法の使用について説明する。例えば、構文解析モデルは、まずUDを使用して文の構文構造を分析し、次にそれに対応するAMR表現を導出するように設計できる。この2段階のアプローチにより、構文と意味の両方の側面が考慮されるようになり、構文解析プロセスが強化される。  
> 3.4. 曖昧さの解決: AMRとUDの統合は、曖昧さの解決に役立つ。UDを通じて構文の依存関係を理解することで、パーサーはAMRの意味の役割と関係についてより情報に基づいた決定を下すことができ、曖昧な文をより適切に処理できるようになる。  
> 3.5. 標準化とベンチマーク: AMRとUDはどちらも標準化されたフレームワークであり、さまざまなNLPシステムの比較と評価を容易にする。この論文では、これらのフレームワークを一緒に使用すると、モデルのトレーニングとテストのベンチマークを作成し、最終的に意味解析タスクのパフォーマンスを向上させることができると強調している。  
>
> 要約すると、AMRとUDの関係は、言語分析における補完的な役割を特徴としており、AMRは意味的洞察を提供し、UDは統語的構造を提供する。これらの統合により、自然言語の理解と処理におけるNLPシステムの機能が強化される。  
>
> 1. AMRの概要
> - 定義: AMRは、文の意味を構造化された形式で捉える意味表現フレームワークとして紹介されている。使用されている特定の単語を抽象化し、代わりに基礎となる概念とその関係に焦点を当てている。  
> - 重要性: この論文では、機械翻訳、質問応答、情報検索などの自然言語処理(NLP)タスクにおけるAMRの重要性を強調している。  
> 2. AMRと意味的曖昧さ  
> - 曖昧さの課題: この論文では、1つの文がコンテキストに基づいて複数の解釈を持つ可能性がある言語の意味的曖昧さによって生じる課題について説明する。  
> - 解決戦略: 正確な意味解析に不可欠な、これらの曖昧さを解決するための効果的ま戦略の必要性を強調している。  
> 3. リレーショナルAMR  
> - 概念: この論文では、文中の様々なエンティティとアクションの関係に焦点を当てたリレーショナルAMRという考え方を紹介している。このアプローチは、これらの関係の構造化された表現を提供することで、曖昧さを明確にすることを目的としている。  
> - 例: この論文では、リレーショナルAMRが従来の方法よりも効果的に複雑な文を表現できる方法を示す例を示す。  
> 4. 複雑な文のパターンの辞書  
> - 開発: 著者は、複雑な文のパターンを処理するために特別に設計された辞書の作成について説明する。この辞書は、曖昧さにつながることが多い複雑な文の構造を識別してっかいせきすることに役立つ。  
> - 用途: この辞書は、意味表現の精度を向上させるためにAMR解析と組み合わせて使用される。  
> 5. BERTの微調整  
> - 方法論: この論文では、BERTを使用してAMR構文解析モデルを微調整する方法について説明する。BERTの言語のコンテキスト理解は、曖昧さをより適切に処理し、構文解析のパフォーマンスを向上させるのに役立つ。  
> - トレーニングの詳細: 使用されるデータセットやBERTモデルに設定されたパラメータなど、トレーニングプロセスの詳細が含まれる場合がある。  
> 6. 評価指標  
> - パフォーマンス評価: この論文では、精度、再現率、Fスコアなど、AMR構文解析システムのパフォーマンスを評価するために使用される評価指標の概要を示す。これらの指標は、システムが曖昧さをどの程度解決し、セマンティクスを正確に表現するかを定量化するのに役立つ。  
> - 結果: 著者は、AMR構文解析の改善におけるアプローチの有効性を示す実験の結果を提示する可能性がある。  
> 7. ユニバーサル　ディペンデンシー(UD)との統合  
> - 補完的フレームワーク: AMRとUDの関係について検討し、これらのフレームワークを統合して言語分析を強化する方法を強調する。AMRは意味的洞察を提供し、UDは構文構造を提供する。  
> - 構文解析手法: この論文では、AMRとUDの両方を活用し、より包括的な言語分析を可能にする構文解析手法について説明する。  
> 8. 結論と今後の取り組み  
> - この論文では、複合文パターン　レキシコンの開発における貢献と、それがAMR構文解析に与える影響についてまとめている。  
> - 今後の方向性: レキシコンのさらなる改良、追加の構文解析手法の検討、または他のNLPタスクでのAMRの適用の拡大など、今後の研究分野を提案する場合がある。  
</details>

<details><summary>IRCoder: Intermediate Representations Make Language Models Robust Multilingual Code Generators</summary>

- [参考](https://aclanthology.org/2024.acl-long.802.pdf)
> - 概要: この論文ではコンパイラ中間表現(IR)を使用してコード生成モデル(コードLM)の多言語機能を強化する方法について説明する。この論文では、約400万のソースコードとそれに対応するIRのペアで構成されるSLTransデータセットを紹介している。著者らは、コード補完、理解、および指示の追跡など、様々なタスクのパフォーマンスが向上する、IRでのコードLMのグラウンディングの利点を実証するための実験を実施している。この論文の目的は、中間表現を活用して多言語コード生成の理解と機能を向上させ、最終的にソフトウェア開発者の生産性を向上させることである。  
> 1. IRCoderの主な貢献は？
> 1.1. SLTransデータセットの作成: 著者らは、約400万組の自己完結型ソースコードファイルとそれに対応する中間表現(IR)で構成される並列データセットであるSLTransを開発した。  
> 1.2. グラウンディングの利点の調査: この論文では、IRでCode-LMをグラウンディングすることの利点を体系的に調査し、様々なタスクとプログラミング言語にわたって有意かつ一貫した経験的利益を実証している。  
> 1.3. IRCoderモデルの開発: 著者らは、11億から73億のパラメータのサイズに及ぶ、IRCoderと呼ばれる一連の基本および命令調整済みCode-LMを作成し、公開した。これらのモデルは、SLTransからの並列データと単一言語データの混合に対する継続的な事前トレーニングの結果である。  
> 1.4. 扱われる研究課題: この論文では、並列ソースコード-IRコーパスによる明示的なグラウンディングによるトレーニングの有効性、プロンプトの変動＠に対する堅牢性、多言語パフォーマンスの向上、事前トレーニングが指示に従うことに与える影響など、いくつかの研究課題に取り組んでいる。  
>
> これらの貢献は、コード生成モデルの堅牢性と多言語機能を強化し、様々なプログラミング言語でのコードの理解と生成を向上させることを目的としている。  
> 
> 2. 中間表現により多言語コード生成がどのように改善されるか？  
> 2.1. 共有セマンティックフレームワーク: IRは、様々なプログラミング言語の構成要素を整合できる共通のセマンティックフレームワークとして機能する。この共有表現は、様々な言語の構造を統一された形式で固定することで言語間の転送を容易にし、モデルが言語間でより効果的にコードを理解および生成するのに役立つ。  
> 2.2.   言語固有の干渉の削減: 共有IRを利用することで、モデルは言語固有のパラメータから生じる可能性のある否定的な干渉を最小限に抑えることが出来る。このアプローチにより、コード構成要素をより一般化して理解できるようになり、事前トレーニングデータの一部ではなかった言語にモデルを一般化する能力を高めることができる。  
> 2.3. 堅牢性とパフォーマンスの向上: IRでのコードLMの基盤化は、迅速な堅牢性、多言語コード補完、コード理解、および指示の追跡など、様々なタスクで大幅なパフォーマンス向上につながることが示されている。これは、従来のCode-LM事前トレーニングコーパス、よりも桁違いに小さいデータセットでトレーニングしながら実現される。  
> 2.4. 知識移転の促進: IRを使用すると、リソースの多いプログラミング言語からリソースの少ないプログラミング言語への知識の移転を効果的に行うことができる。これは、急速に進化するプログラミング言語や、コードコーパスにおける言語の偏った分布という状況では特に重要である。  
> 2.5. 言語構成の強化された学習: IRのトレーニングにより、Code-LMはIR言語の構文とセマンティクスを学習するようになり、様々なプログラミング言語のIR構成とそれぞれの構成の整合性が向上する。この整合性により、正確でコンテキストに適したコードを生成するモデルの能力が向上する。  
>
> 全体として、言語コード生成モデルのトレーニングに中間表現を統合すると、モデルの理解と生成能力が向上し、様々なプログラミング言語にわたってモデルがより堅牢で効果的になる。  
>  
> 3. この研究で使用されているデータセットとその内容は？  
> データセットはSLTransと呼ばれる。これは、自己完結型のソースコードファイルとそれに対応する中間表現(IR)のペア約400万個で構成されている。  
> SLTransデータセットの主な機能は次のとおりである。  
> 3.1. 並列ソースコードIRペア: データセット内の各エントリは、ソースコードファイルと、具体的にはLLVM IR(低レベル仮想マシン中間表現)を使用した中間形式の同等の表現をペアにする。  
> 3.2. プログラミング言語の多様性: データセットには、低、中、高リソースのプログラミング言語が混在しており、多言語コード生成機能を包括的に評価できる。  
> 3.3. 大規模: 合計262億トークンのSLTransは、コードLMの継続的な事前トレーニングに不可欠な大量のトレーニングデータを提供する。  
>
> SLTransデータセットは、中間表現にコードLMを基盤づけることの利点の調査を容易にし、最終的には複数のプログラミング言語にわたるコード理解および生成タスクのパフォーマンスを向上させることを目的として設計されている。
</details>

<details><summary>Can docstring reformulation with an LLM improve code generation?</summary>

[参考](https://aclanthology.org/2024.eacl-srw.24.pdf)

関数の説明文（docstring）を大規模言語モデルで再構成することで、コード生成の性能向上を試みた研究である。  

### 背景と目的
関数の説明文（docstring）は、関数の目的や使用方法を記述するもので、コード生成モデルにとって重要な入力情報である。本研究では、LLMを用いてdocstringを再構成することで、コード生成の精度向上を目指す。  


### 手法
以下は2つのベースライン手法を提案した：
1. **LLMによるdocstringの再構成**：既存のdocstringをLLMで再構成し、より明確で有用な説明文に変換する
2. **再構成されたdocstringを用いたコード生成**：再構成されたdocstringを入力として、コード生成モデルに関数の実装を生成させる
これらの手法を、HumanEvalベンチマークおよび難易度を高めたバリエーションで評価した。

### 実験と結果
- 再構成されたdocstringを用いても、コード生成モデルの性能に大きな変化はみられなかった
- これは、現在のオープンソースのコード生成モデルが、docstringの詳細な表現に対して堅牢であることを示唆している

### 考察と今後の課題
- docstringの再構成によるコード生成の改善は限定的であり、他の要因（例えば、モデルのアーキテクチャやトレーニングデータ）が性能に大きく影響している可能性がある。
- 今後の研究では、docstringの質や構造、モデルの感度など、より詳細な分析が必要である

この研究は、入力の工夫（docstringの再構成）がコード生成に与える影響を検証したものであり、今後のコード生成モデルの改善に向けた重要な知見を提供している。
</details>

<details><summary>LLM-based Code-Switched Text Generation for Grammatical Error Correction</summary>

[参考](https://aclanthology.org/2024.emnlp-main.942.pdf)  

この論文は、グローバル化の進展に伴い、複数の言語を交えて会話する「コードスイッチング」が一般的になってきた現状を背景に、特に英語を第二言語とする学習者（ESL）の文法誤り訂正（GEC）における課題に取り組んでいる。  

### 背景と目的
コードスイッチングは、複数の言語を交えて会話する現象で、特に多言語話者の間で一般的である。ESL学習者にとって、母語と英語を混ぜて使用することは、学習を促進し、理解を深める手段となっている。しかし、従来のGECシステムは主に単一言語のテキストを対象としており、CSWテキストに対しては誤りとして扱う傾向がある。この研究の目的は、CSWテキストに対するGECの性能を評価し、データ不足の問題に対処するための合成データ生成手法を提案し、単一言語およびCSWテキストの文法誤りを訂正できるモデルを開発することである。  

### 手法
1. **データ不足の解消**：高品質な合成CSW GECデータを生成する手法を提案し、CSWテキストに対するGECのトレーニングデータを拡充した
2. **モデルの開発**：合成データを用いて、単一言語およびCSWテキストの文法誤りを訂正できるモデルを訓練した

### 実験と結果
- 提案した合成データを用いて訓練したモデルは、既存のGECシステムと比較して、CSWテキストに対する文法誤り訂正の性能が向上した
- 特に、言語の切り替えポイントにおける曖昧さに対処する能力が改善された

### 考察と今後の課題
- CSWテキストに対するGECの研究はまだ初期段階であり、さらなるデータの収集とモデルの改善が必要
- 将来的には、より多様な言語の組合わせに対応できるGECシステムの開発が期待される

この研究は、ESL学習者が自然な多言語使用を維持しながら、英語の文法的正確性を向上させるための教育技術の開発に貢献することを目指している。
</details>

<details><summary>Virtual Compiler Is All You Need For Assembly Code Search</summary>
    
[参考](https://aclanthology.org/2024.acl-long.167.pdf)  

### 背景と目的
リバースエンジニアリングでは、膨大なバイナリファイル内から特定の関数を迅速に特定する必要がある。従来の方法では、ユニークな文字列や定数を検索するなど、経験やヒューリスティックに依存しており、効率が悪いのが現状である。この研究では、自然言語で記述されたクエリから対応するアセンブリコードを検索する手法を提案し、リバースエンジニアリングの効率化を図る。  

### 提案手法：Virtual Compiler
- **大規模言語モデルの活用**：Meta社のCodeLlamaをベースに、Ubuntuパッケージから収集した200億トークンのデータで継続的に事前学習を行い、仮想コンパイラとして機能させる
- **仮想コンパイルの実現**：ViCは、実際のコンパイラを使用せずに、任意のプログラミング言語のソースコードをアセンブリコードに変換する能力を持つ。これにより、複雑な依存関係や環境設定を必要とせず、広範な言語に対応可能である
- **データセットの構築**：ViCを用いて大規模なアセンブリコード検索用データセットを構築し、従来の手法では困難だったデータ収集の課題を解決する

### 実験と結果
- **性能向上**：提案手法により、アセンブリコード検索の性能が大幅に向上し、既存の最先端手法を26%上回る結果を達成
- **汎用性の確認**：C/C++のソースコードとアセンブリコードのペアで訓練されたモデルが、PythonやGolangなど他の言語にも一般化できることを示した

### 考察と今後の課題
- **データセットの拡張**：ViCの活用により、従来困難だったアセンブリコード検索用の大規模言語データセットの構築が可能となった
- **多言語対応の可能性**：C/C++以外の言語にも対応可能であることから、今後さらに多くのプログラミング言語への適用が期待される
</details>

<details><summary>CodeJudge: Evaluating Code Generation with Large Language Models</summary>

[参考](https://aclanthology.org/2024.emnlp-main.1118.pdf)  

この論文では、テストケースを用いずに生成コードの意味的正確性を評価する新しいフレームワーク「CODEJUDGE」を提案している。  

### 背景と課題
LLMはコード生成においても優れた性能を示したが、その評価には課題がある。従来の評価手法は以下のような問題を抱えている  
- **テストケース依存**：多くの評価は手動で作成されたテストケースに依存しているが、これらは網羅性に欠け、特にオブジェクトのシリアライズやWebスクレイピングなどのタスクではテストケースの作成が困難である
- **トークンベースの指標の限界**：BLEUやCodeBLEUなどのトークンベースの指標は、構文が異なっても意味的に同等なコードを正確に評価できない。例えば、whileループとforループの使用の違いや、変数名の違いなどが評価に影響を与える可能性がある

### CODEJUDGEの概要
CODEJUDGEは、LLMs自身を評価者として活用し以下の2つの評価を行う  
1. **正誤判定**：生成されたコードが正しいか否かを判断する。LLMにコードの機能をステップバイステップで分析させ、その結果をもとにバイナリの決定を下す。
2. **部分的正確性の評価**：生成コードがユーザーの意図したコードとどの程度一致しているかを評価する。LLMに一般的なコーディングエラーの分類を提供し、生成コードに含まれるエラーの種類とその重要度を特定させ、コードの正確性スコアを算出する

これらの評価は、テストケースやモデルのファインチューニングを必要とせず、LLMのスローシンキングを促すプロンプト設計により実現される。
</details>

<details><summary>Code Needs Comments: Enhancing Code LLMs with Comment Augmentation</summary>

[参考](https://aclanthology.org/2024.findings-acl.809.pdf)  

コード生成における大規模言語モデルの性能向上を目的として、コードと自然言語の整合性、特にコードコメントの重要性に着目している。  

## 背景と課題
コード生成LLMsは、自然言語からコードへの変換（NL2Code）などのタスクで顕著な進歩を遂げているが、訓練データにおけるコードと自然言語の整合性が十分でないことが課題とされている。特に、コードコメントの密度が低いことが、モデルの性能向上を妨げている可能性がある。  

例えば、StarCoderのデータセットにおける主要なプログラミング言語のコメント密度は以下の通りである。  
言語 | コメント密度
Python | 21.87%
Java | 19.17%
C++ | 17.53%
JavaScript | 13.52%
PHP | 12.07%  

高品質なリポジトリではコメント密度が40%を超える場合もあり、既存のコードデータセットにはコメントが不足していることが示唆されている。  

## 提案手法：コメント生成によるデータ拡張
この研究では、既存のコードに対してコメントを自動生成することで、コードと自然言語の整合性を高めるデータ拡張手法を提案している。具体的には、以下のステップで構成されている。  
1. **コメント生成**：GPT-4oなどのLLMを用いて、既存のコードに対応するコメントを生成する
2. **データフィルタリング**：自然言語との整合性が低いコードデータを除外するためのフィルタリングを行う
3. **再訓練**：生成されたコメント付きコードデータを用いて、コード生成LLMを再訓練する

このアプローチにより、コードと自然言語の整合性が向上し、モデルの性能改善が期待される。  

## 実験と結果
提案手法の有効性を検証するため、以下の実験が行われた：  
- **対象モデル**：StarCoderなどのコード生成LLM
- **評価ベンチマーク**：HumanEval、MBPPなどのプログラミングスキル評価ベンチマーク

実験の結果、コメント生成によるデータ拡張を行ったモデルは、元のモデルやコメント生成に使用したモデルを上回る性能を示した。特に、生成されたコメントがコードの理解を助け、モデルの自然言語とコードの対応関係を強化することが確認された

## 結果と貢献
本研究は、コードと自然言語の整合性、特にコメントの重要性を再評価し、コメント生成によるデータ拡張がコード生成LLMsの性能向上に寄与することを示した。このアプローチは、既存のコードデータセットに対して容易に適用可能であり、今後のコード生成モデルの訓練において有用な手法となると考えられる。
</details>

<details><summary>Benchmarking Automated Theorem Proving with Large Language Models</summary>

[参考](https://aclanthology.org/2024.nlp4science-1.18.pdf)  

数学の定理証明における大規模言語モデルの活用を検討した研究である。特に、Leanという定理証明支援システム（proof assistant）というLLMsを統合した新しいフレームワーク「Lean Copilot」を提案し、その性能を評価している。  

## 背景と目的
数学の定理証明は、形式的な証明を厳密に構築・検証する必要があり、従来は専門的な知識と多大な労力を要してきた。近年、AI、特にLLMsの進展により、自動定理証明（ATP）の可能性が注目されている。本研究では、LLMsをLeanと統合することで、証明の自動化と効率化を図ることを目的としている。  

## Lean Copilotの概要
Lean Copilotは、LLMsをLeanの証明環境に組み込み、証明の提案や補助を行うフレームワークである。これにより、ユーザーはLLMsの支援を受けながら、Lean上で証明を構築できる。この統合により、従来のLLMsベースの証明システムが直面していた、実際の証明支援システムとの連携の難しさを克服しようとしている。  

## 評価と結果
研究では、一般的なLLMs（例：Llama-70B）と数学特化型の小規模モデルを比較し、Lean Copilot上での定理証明能力を評価した。その結果、Llama-70Bのような大規模な一般モデルが、特定の数学分野に特化した小規模モデルよりも優れた性能を示した。これは、一般モデルの方が後半な知識と柔軟性を持っているためと考えられる。  

## 結論と展望
本研究は、LLMsと定理証明支援システムの統合が、数学の定理証明の自動化と効率化に有望であることを示している。今後は、より高度な統合や、他の証明支援システムとの連携、さらには人間とAIの協調による証明構築の研究が期待されている。
</details>

<details><summary>TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts</summary>

[参考](https://aclanthology.org/2024.emnlp-main.667.pdf)  

## 背景と課題
従来、数学定理の形式的証明はLean4などの証明支援システム（proof assistant）で厳密に検証される一方、証明を書くには大きな専門知識と手間を必要とする。また、自然言語と形式言語で書かれた証明データの対応がほとんど存在せず、LLMを用いて形式証明を書くには十分な学習データが不足している。  

## 提案手法：TheoremLlamaフレームワーク
TheoremLlamaは汎用LLMをLean4の専門家へと転換するエンドツーエンドの枠組みで、主に以下の3要素から成る。
1. **NL-FLアラインデータ生成**
   - Mathlib4（約10万件のLean4定理証明）から定理と証明を抽出し、Gemini-1.5と例検索付きT5エンコーダでそれらを自然言語化
   - 自然言語証明をLean4コード中にコメントとして埋め込む「NL-FLブートストラッピング」を実施し、OBT（Open Bootstrapped Theorems）という約10万7千件のアライン済みデータセットを構築
2. **Lean4 Prover Training**
   - OBTを用いたファインチューニングで、ブロックトレーニング（In-Context能力向上）とカリキュラム学習（易→難順ソート）を適用
3. **Iterative Proof Writing**
   - 生成済みの正解証明を逐次インコンテキスト例として再利用し、証明生成性能を反復的に強化

## 評価実験
MiniF2Fベンチマーク（Valid/Test）において、Llama3-8B-Instructを基盤にTheoremLlamaを適用したモデルは、Validで36.48%、Testで33.61%の累積正答率を達成し、GPT-4（22.95%/25.41%）を大幅に上回った  

## 主な成果と意義
- NL-FLデータ不足というボトルネックをOBTという大規模アライン済みデータセットで解消
- 汎用LLMをLean4証明の高度タスクへと効率的に適用するための訓練技術（ブロックトレーニング、カリキュラム学習、反復生成）を示した
- コード・モデルチェックポイント・OBTデータセットをオープンソース公開し、学術コミュニティでの再現性・発展を支援
</details>

<details><summary>BC‑Prover: Backward Chaining Prover for Formal Theorem Proving</summary>

[参考](https://aclanthology.org/2024.emnlp-main.180.pdf)  

## 背景と課題
従来のLLMを用いた対話的定理証明（ITP）では、証明ステップ生成と探索を前方連鎖（forward chaining）のみで行うため、膨大な探索空間において適切な証明経路を見つけるのが困難である。また、非形式的な自然言語証明をそのまま利用すると、証明過程に抜け落ちやあいまいさが生じやすいという問題がある。  

## 提案手法：BC-Prover
本研究では、「擬似ステップ（pseudo steps）」を用いた逆推論（backward chaining）フレームワークBC-Proverを提案している。
1. **逆推論によるサブゴール分割**  
   証明ゴールを再帰的に補助的な小ゴールに分解し、各サブゴール毎に目標指向探索を行うことで、効率的に証明経路を探索する
2.  **ステッププランニング**  
   非形式的証明から応出した擬似ステップを基に、次に適用すべき戦術（tactics）を細かく計画。形式的証明とのギャップを埋め、不適切・冗長なステップ生成を抑制する。

## 実験評価
miniF2Fベンチマーク上で、BC-Proverは従来の前方連鎖型プローバーや微調整モデルを大幅に上回る合格率を達成した。また、既存の微調整プローバーに逆推論モジュールを組み込むだけでも性能向上が確認され、汎用性の高さを示している。  

## 主な貢献
- 非形式的証明からの「擬似ステップ」による細粒度プランニング手法
- 逆推論戦略をITPタスクに導入し、探索効率を大幅改善
- 既存プローバーとの高井互換性と、相乗的な性能向上の実証
</details>

<details><summary>TRIGO: Benchmarking Formal Mathematical Proof Reduction for Generative Language Models</summary>

[参考](https://aclanthology.org/2023.emnlp-main.711.pdf)  

## 背景と問題提起
- Automated Theorem Proving(ATP)は、結論から公理まで形式的に推論を検証できるため、言語モデルの「厳密な」推論能力を評価するのに適している
- 既存ベンチマーク（LeanStep,MiniF2Fなど）は主に記号推論に焦点を当て、複雑な数値結合操作（項のグループ化、因数分解、同値変形など）を含まない
- 特に三角関数式の簡約は、数値と式構造の両方を深く理解しなければならず、現在の生成モデルにとって大きな挑戦となる

## TRIGOタスクの定義
- **目標**：与えられた三角関数式をLeanの形式言語を入力し、ステップごとの証明（tactic）を通じて式を簡約する。

例：
```lean
lemma Trigo_0 : sin(π/3) + 2 * cos(π/12) * 2 - cos(π/2) = sqrt(3) + 1 := 
begin
  rw cos_pi_div_two,
  have h: cos (π/12) ^ 2 = cos (π/6) / 2 + 1 / 2,
  ring_exp,
  ...,
end
```
のように、半角公式の適用や定数変形を正しく選択する必要がある。

## データセット構築
1. **TRIGO-real**：
   - 高校の演習問題・試験問題集（"tiku"など）から三角関数式の問題と解答を収集し、427問を手動でステップ注釈
2. **TRIGO-web**：
   - ウェブ上の類似問題をさらに453問収集し、テストセットとして利用
3. **TRIGO-gen**：
   - 上記の手動注釈をもとにLean-Gymベースの自動生成プログラムで、証明長や数値規模を制御した人工サンプルを生成
4. **注釈ツール**：
   - Sympyを用いて85種類の変形ルール（半角・加法公式など）にマッチさせつつ、ステップごとの正当性をチェック

## 評価実験
- **モデル比較**：GPT-4をはじめ、各種生成モデルにTRIGOタスクを解かせる
- **失敗例**：GPT-4は一度は正しい式変形を示すものの、存在しないtactic名を生成したり、誤ったsubgoalで完了と判断したりといった形式検証の落とし穴に陥る
- **難易度設定**：実データと自動生成データを組み合わせたスプリットで、モデルの分布外一般化能力を詳しく分析

## 主な結果と意義
- TRIGOは「数値操作+形式的証明」という二重のチャレンジを伴い、現状の最先端LLM（GPT-4など）でさえ高いパス率を達成できないことを示した
- 複雑な数値結合・式変形能力が、今後のATPにおける重要な研究テーマであることを提起
- データセット・注釈ツール・自動生成コードを公開し、形式的数学推論コミュニティへの貢献とベンチマークとしての展開を促進
</details>

<details><summary>Introduction to Mathematical Language Processing: Informal Proofs, Word Problems, and Supporting Tasks</summary>

[参考](https://aclanthology.org/2023.tacl-1.66.pdf)  

## 背景と目的
- **数学的言語処理（Mathematical Language Processing;MLP）**は、数学的要素（式、変数、定理など）と自然言語の両方を扱いながら、「数学的に厳密」かつ「説明可能」な解答を生成することを目指す
- 従来、数学の自動化には形式的証明システムを用いた厳密推論が必要でしたが、近年のTransformer系モデルやLLMは豊富な知識と推論能力を示した
- 本論文は、MLPを構成する五つ戦略的サブタスクを整理・分析し、各分野の手法、データセット、評価指標、現状の限界、研究動向、今後の展望を俯瞰的にレビューすることを目的としている

## 代表的タスクの分類
論文は、以下の五つを「代表的タスク」として取り上げ、推論の＜抽象的⇄生成的＞スペクトル上に配置する
1. **Identifier-Definition Extraction**  
   変数や記号（例：ψ(x)）とそれに対応する自然言語での定義（例：wavevector）を抽出するタスク
2. Formula Retrieval  
   LaTexやMathMLで表現された数式検索。クエリ数式に類似する候補式をランキングする
3. Natural Language Premise Selection (NLPS)  
   定理証明の前提となる文を、大量のテキストから選び出す情報検索タスク
4. Math Word Problem Solving (MWP)  
   「文章題」を解いて答えを算出する。解答には識別子と定義抽出、前提選択も含まれる
5. Informal Theorem Proving  
   型式証明ではなく、自然言語＋数式によるステップ形式の「非形式的証明」を生成し、論理的に結論へ至る過程を表現する

## 主な手法と進化
- **抽出的タスク**（identifier‑definition extraction, formula retrieval）は、従来は手工学的特徴＋統計的モデル（CRF,SVM）から始まり、近年はBERT系の細微調整やグラフニューラルネットワークによるエンコーディングへと移行
- **生成タスク**（MWP, informal proving）では、GPT系LLMや専用のシーケンスモデルを用い、入出力のペアを大規模に学習・生成させる手法が主流に
- **中間的タスク**（premise selection）は、グラフ構造＋自己注意機構を組み合わせたモデルや、LLMへの直接プロンプト/微調整アプローチが精度を伸ばしている

## 現在の限界と今後の課題
- **データ多様性の不足**：多くのタスクは特定ドメイン（arXiv論文、教科書）に偏っており、汎用性の高いデータセットが不足
- **スコープと評価の不統一**：同じタスク名でも定義や評価志保湯が研究ごとに異なるため、直接比較が困難
- **形式⇄非形式ギャップ**：形式的証明システムと自然言語モデル間での"autoformalization"手法がまだ発展途上
- **複合タスクの必要性**：現実的な問題解決には、識別子抽出→前提選択→証明生成の連鎖的処理が必須であり、単一タスク最適化からの脱却が求められる

## まとめと展望
- MLPは「抽出から生成へ」、さらに「非形式⇄形式」ブリッジを行う潮流にあり、各分野の手法は着実に進化中
- 今後は、統一ベンチマーク・マルチモーダル手法（テキスト＋画像＋数式）・人間とAIの混合推論プロセスなど、より実用的で堅牢なシステム開発に注力が移ると予想される
</details>

<details><summary>Can docstring reformulation with an LLM improve code generation?</summary>

[参考](https://aclanthology.org/2024.eacl-srw.24.pdf)  

関数補完タスクにおけるコード生成の入力として用いられる"ドックストリング"（関数の説明文）を、LLMによって書き直す（リフォーミュレーション）ことで、生成されるコードの品質向上を図る新しいアプローチを提案・検証したものである。主に内容を以下にまとめる。  
## 背景と問題意識
- 関数補完（Function Completion）は、関数定義とその説明文を入力として、関数本体を生成するコアなコード生成タスクの一つである。既存手法は主にモデルの事前学習/微調整やプロンプト工夫による性能向上を目指す。
- 本研究では「入力を変える」という次元で、ドックストリング自体を最適化することを考え、新たな切り口を提示している

## 提案手法
1. **SFT（Supervised Fine-Tuning）法**
   - 手書きの指示文（例："以下の関数のドックストリングを、最適なコーディング規約に従って改善せよ"）を固定し、リフォーミュレーション候補から最もコード生成性能の高いものを選んで、再学習データとしてLLMを微調整
2. **OPRO(Optimization by PROmpting)法**
   - リフォーミュレーション指示文そのものをLLMで生成・更新し（Instruction Optimizer）、固定のリフォーミュレーターでドックストリングを書き直すサイクルを繰り返す

## 実験設定
- ベンチマークには、HumanEvalのオリジナル版と、ドックストリングを意図的に"悪化"させた複数のバリアントを使用
- 複数のオープンソースコードLLM（OpenLlama、MPT,StarCoder、WizardCoder系列など）を対象に、パス率（pass@1）で評価

## 主に結果と知見
- ドックストリングを書き直したにもかかわらず、多くのオープンソースLLMではコード生成能力にほとんど変化がみられず、現状のモデルはドックストリングの細部に対して意外なまでにロバストであることを示唆
- 一方で、理想的なリフォーミュレーションを用いるとまだ大きな改善余地があるため、効果的な最適化手法の開発が今後の課題

## 考察と今後の展望
- ドックストリング最適化の有効性を引き出すには、より洗練された学習ルールやノイズに強い評価指標が必要
- 本手法はモデル非依存であるため、より高性能なコードLLMが登場すれば、ドックストリング最適化による恩恵も大きくなる可能性があると考えられる
</details>

<details><summary>DeepSeek‑Prover: Advancing Theorem Proving in LLMs through Large‑Scale Synthetic Data</summary>

## 背景と課題
従来の形式証明支援システム（Lean,Isabelle,Coqなど）は、高い正確性を保証する一方で、証明を書くには高度な専門知識と多大な手間が必要である。一方、LLMは自然言語による数学推論で優れた性能を示すものの、Lean4などの形式証明言語で完全な定理証明を生成するには、並列コーパス（命題⇄証明）データが著しく不足していた。

## 提案手法：大規模合成データ生成パイプライン
1. **Autoformalization**
   - インターネット上から収集した高校・学部レベルの数学競技問題（869,659問）を、LLM（DeepSeekMath-Base 7B）でLean4の定理文に翻訳
   - 初期モデルは限定的なデータで事前微調整し、逐次的に品質を向上させながら命題を生成
2. **品質フィルタリング**
   - モデルスコアリング：Chain-of-Thought付きfew-shotプロンプトで命題の「優秀/良好/平均以上/可/不可」を分類し、低品質を除去
   - 仮説棄却：生成命題の「結論をFalseに置き換えて証明可能か」を試し、矛盾仮説から導出された命題を排除
3. **自動証明生成と検証**
   - フィルタ済み命題をDeepSeek-Prover(7Bモデル)で証明生成し、Lean4環境で貼りデート
   - 成功した定理-証明ペアを再びデータとして取り込み、モデルを反復微調整
4. **探索効率化**
   - 命題とその否定命題を並列で証明試行し、いずれかが速く終了した時点で探索を打ち切ることで、無駄な計算を削減  
このプロセスを繰り返し、最終的に8百万件の高品質定理-証明合成データセットを構築した

## 実験結果
- miniF2F(488問)において、DeepSeek-Proverは64サンプルで46.3%（累積52％）の全証明生成成功率を達成
   - 比較：GPT-4は同条件下で23.0%、従来の木探索＋RL手法は41.0%
- FIMOベンチマーク（148問）では、DeepSeek-Proverが最大4096サンプル時に5問を証明（GPT-4は0問）
- アブレーション実験で、各反復ステップごとにminiF2Fの解決数が着実に増加することを確認

## 貢献と意義
- **大規模合成データの生成手法**：自動化＋品質保証＋反復学習により、形式証明用のコーパス規模を数百万件単位で飛躍的に拡大
- **LLMベース証明モデルの性能向上**：従来GPT-4を大きく上回る成果を示し、LLMに形式証明タスクを学習させる新たなスタンダードを提示
- **データ・モデルの公開**：研究コミュニティが再現・拡張可能なリソースを提供し、自動定理証明の発展を加速

本手法は、**合成データのスケールと品質担保の両立**により、LLMを用いた形式証明生成の実用的可能性を大きく前進させた点で大きな新規性がある。
</details>

<details><summary>Symbolic Prompt Program Search: A Structure-Aware Approach to Efficient Compile‑Time Prompt Optimization</summary>

[参考](https://aclanthology.org/2024.findings-emnlp.37.pdf)  

## 背景・問題意識
近年のLLM応用では、プロンプト自体がプログラムとして扱われることが増えており、同一のプログラムが多数のクエリやデータインスタンスに対して繰り返し呼び出される。こうした設定下では、プロンプトプログラムの最適化が実用上の大きな課題となっている。しかし従来手法は、単純なプロンプトのみを対象にするか、プログラム構造が固定されていることを前提としていた。  

## 提案手法：SAMMOフレームワーク
本研究では「SAMMO（Symbolic prompt-Program search for compile-tiMe Optimization）」を提案する。SAMMOはプロンプトプログラムをシンボリック（記号的）に表現し、変換候補の探索空間を豊富に定義した上で、コンパイル時に適用可能なプログラム変換（例：命令の再配置や不要部分の削除など）を探索的に最適化する枠組みである。

## 技術的特徴
1. **構造認識的表現**：プログラム構造を抽象構文木レベルで捉えることにより、多様な最適化パスを定義可能
2. **探索による最適化**：多数の変換候補から性能指標（例：実行時間やトークン数）を評価し、最適化されたプロンプトプログラムを自動生成
3. **コンパイル時適用**：実行環境におけるランタイムのオーバーヘッドを抑えつつ、あらかじめ最適化したプロンプトをデプロイ可能

## 実験・評価
1. 命令調整（Instruction Tuning）
2. RAG（Retrieval-Augmented Generation）パイプライン調整
3. プロンプト圧縮（Prompt Compression）

これらの各タスクにおいて、SAMMOは従来法を上回る性能を示し、特に複雑なプロンプトでの効率化効果が顕著であった

## 結論・貢献
- SAMMOは従来の固定構造前提の最適化手法を一般化し、構造認識的な探索によってより広範な最適化を実現
- 複数の実タスクでの評価により、プロンプトプログラムの効率化と性能向上を確認
- ソースコードはオープンソースで公開されており、今後の発展
</details>

<details><summary>CodeScope: An Execution‑based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation</summary>

[参考](https://aclanthology.org/2024.acl-long.301.pdf)

## 背景
大規模言語モデルはプログラム支援や自動化において高い性能を示している一方で、既存の評価ベンチマークは対象言語やタスクが狭く、生成コードの「実行可能性」や「実行結果の一貫性」を十分に評価できていない。特に、現実のソフトウェア開発では多言語・多タスク環境での運用が必須であるにもかかわらず、これをカバーするベンチマークが不足している。

## 提案：CodeScopeベンチマーク
- 多言語・多タスク・多次元
  - 43のプログラミング言語、8つのコード理解・生成タスクを網羅（例：コード要約、コード修正、プログラム合成、コード最適化など）
  - 評価の「多次元性」として、(1)コード長、(2)問題難易度、(3)実行性能の3軸でモデル能力を詳細に測定
- 実行ベース評価の実現
  - 生成コードを実際にコンパイル・実行し、テストケースに対する出力を照合することで、表層的な文字列比較では得られない実用性うぃ評価

## システム構成
- MultiCodeEngine
   14言語に対応した自動コード実行エンジンを開発し、ベンチマークの実行評価を一貫して行える仕組みを提供
- ベースラインと分析
   8つの主流LLMを対象に、CodeScope上で詳細な性能比較とエラー分析を実施

## 貢献及び公開
1. これまでにない規模の「多言語×多次元」評価フレームワークを構築
2. 実行ベースの評価を通じ、LLMが生成するコードの実用的品質を初めて体系的に測定可能に
3. ベンチマークデータセットと実行エンジンコードをオープンソースで公開
</details>

<details><summary>Large Language Models for Compiler Optimization</summary> 

[参考](https://arxiv.org/pdf/2309.07062?utm_source=chatgpt.com)
## 目的
  大規模言語モデル（LLM）をコード最適化問題に応用し、従来のコンパイラ最適化（例：–O3）を上回る性能を実現する。  
    
## モデル構成 
  - 7 B パラメータのトランスフォーマーをゼロから学習。  
  - 入力として「最適化前のLLVMアセンブリ」を与え、出力として「最適化用コンパイラオプションのリスト」を生成。

## 補助タスクによる強化学習 
  - 最適化前後の命令数予測タスク：モデルに命令数の変化を推定させる。  
  - 最適化後のアセンブリコード生成タスク：最適化済みコード自体を生成。  
  これらのタスクを学習に組み込むことで、モデルの最適化性能とコード理解能力が大幅に向上。

## 実験結果  
  - 大規模なテストプログラムセット上で評価し、従来コンパイラ比で命令数削減率を3.0%向上。  
  - 2つの最先端手法（数千回のコンパイルを要する手法）を上回る成果を達成。  
  - 生成コードの91%が実際にコンパイル可能、70%はコンパイラ出力と完全一致する高度なコード推論能力を示す。

## 貢献  
  - LLM を使ったコード最適化の有効性を示し、補助タスクを通じた学習強化の新たな手法を提案。  
  - 高速かつ高品質な最適化を実現し、将来的なコンパイラ最適化フローへの応用可能性を提示。
</details>

<details><summary>ACPO: AI‑Enabled Compiler Framework</summary>

[参考](https://arxiv.org/abs/2312.09982?utm_source=chatgpt.com)
## 背景・目的
プログラムの性能最適化において、「どの最適化パスをいつ適用するか」を正しく判断することが鍵となる。しかし従来のコンパイラ最適化（例: LLVM の ‑O3）はルールベースであり、全探索や手動チューニングには限界がある。近年の機械学習（ML）技術の進展は、このチューニングプロセスに ML モデルを組み込む絶好の機会を提供している 

## 提案手法：ACPO フレームワーク
1. **LLVM へのシンプルで包括的な ML 統合ツールキット**  
   - ACPO は LLVM コンパイラの各種最適化パスに対して ML モデルを容易に組み込めるインターフェース群を提供。  
   - クラス階層や高レベルのアーキテクチャを定義し、拡張性と再利用性を両立。  
2. **ケーススタディ**  
   - **ループアンロー數（Loop Unroll）パス**：デフォルトの –O3 ルールを ML モデルに置き換え、最適なアンロー數を予測。  
   - **関数インライン化（Function Inlining）パス**：どの関数をインライン化すべきかを ML モデルで判定。  
   - これらのパスを動的に切り替え・組み合わせることで、さらなる最適化を実現可能。

## 実験結果  
- **Loop Unroll モデルのみ**  
  - Polybench: 平均 +4.0%  
  - Coral-2: +3.0%  
  - CoreMark: +5.4%  
  - Graph-500: +0.2%  
- **ループアンロー數＋関数インライン化モデル併用**  
  - Polybench: +4.5%  
  - Cbench: +2.4%  
いずれも LLVM 標準の ‑O3 と比較した場合の速度向上値であり、ML モデル単体で –O3 を上回る性能を示している

## 結論と展望 
- ACPO によって「最適化パス適用のタイミング・強度」をデータドリブンに学習可能となり、手続き的最適化の限界を超える成果を達成。  
- フレームワーク自体は他の最適化パス（例: ベクトル化、レジスタ割り当てなど）へも容易に拡張可能であり、今後さらなる ML ベース最適化手法の実装が期待される。
</details>

<details><summary>Meta Large Language Model Compiler: Foundation Models of Compiler Optimization</summary>

[参考](https://arxiv.org/html/2407.02524v1?utm_source=chatgpt.com)
## 背景
- 大規模言語モデル（LLM）はコード補完や生成で高い性能を示す一方、コンパイラ最適化への応用は十分に探究されていない。特に、LLVM‑IR やアセンブリを扱うための事前学習データやモデルを用意し、コストを抑えつつ最適化タスクに特化させる必要がある 

## 提案手法（LLM Compiler）
- **モデル基盤**：Code Llama を出発点に、LLVM‑IR とアセンブリコード合わせて5460億トークンのデータで追加事前学習を実施。  
- **命令微調整**（Instruction Fine‑Tuning）：  
  1. コンパイラ練習タスク（compiler emulation）で、任意のパスリスト適用後のコード生成とコードサイズ予測を学習。  
  2. 下流タスクとして「コンパイラフラグ調整（コードサイズ最小化）」および「アセンブリ→IR 逆変換」を微調整。  
- **モデルサイズ**：7B および 13B パラメータの 2 バリエーションを公開 

## 評価結果
- **最適化性能**：従来のオートチューニング探索比で最適化ポテンシャルの 77% を達成。  
- **逆アセンブル性能**：アセンブリ→IR→アセンブリのラウンドトリップで 45% 正常動作、うち 14% が完全一致を記録。  
- **他モデル比較**：Code Llama や GPT‑4 Turbo を大きく上回る性能を示す 

## 貢献・公開
- 商用カスタムライセンスの下、7B/13B モデルおよび微調整済みモデル（LLM Compiler FTD）を公開。  
- コンパイラ最適化研究の基盤として、学術・業界双方での再現・拡張を促進することを狙いとする 
</details>

<details><summary>KIMINA-PROVER PREVIEW: TOWARDS LARGE FORMAL REASONING MODELS WITH REINFORCEMENT LEARNING</summary>

[参考](https://arxiv.org/pdf/2504.11354v1.pdf)

以下では，「KIMINA-PROVER PREVIEW: TOWARDS LARGE FORMAL REASONING MODELS WITH REINFORCEMENT LEARNING」（arXiv:2504.11354v1）について，論文の背景から手法，評価結果，考察までを順に詳しく解説します。引用はすべて arXiv PDF のリファレンス ID（turn0view0）を用いて行います。なお，文中の「Kimina-Prover」は本論文で提案されているモデルを指します。

---

## 概要と目的

本論文は，形式的定理証明（formal theorem proving）において大規模言語モデル（LLM）を強化学習（RL）で訓練し，人間の思考過程に近い「形式的推論パターン（formal reasoning pattern）」を獲得させることで，Lean 4 上での定理証明性能を飛躍的に向上させる試みを報告しています。伝統的に，形式的定理証明には以下のような課題がありました：

1. LLM をステップ単位で呼び出し，Best-First Search（BFS）やモンテカルロ木探索（MCTS）といった外部探索アルゴリズムを組み合わせる手法は，高い計算コストを伴いスケーラビリティに課題がある。
2. LLM が生成する「漸進的推論（chain-of-thought）」が必ずしも形式的証明の構造や非線形な思考過程と合致せず，複雑な証明を効率的に扱うのが難しい。
3. 既存のニューラル定理証明システムでは，モデルサイズを大きくしても性能がほとんど向上しないというスケーリングの限界が観測されていた。

こうした背景から，本研究では Qwen2.5-72B を初期モデルとして用い，大規模な強化学習パイプラインを通じて「形式的推論パターン」を学習させた結果，miniF2F ベンチマーク上で pass\@8192 80.7％という従来比約7.7％向上（BFS-Prover の 72.95％→80.74％）を達成しています。また，モデルサイズを 1.5B，7B，72B の各スケールで比較し，「大規模化による性能向上が初めて明瞭に観測できた」点も重要な成果です。

---

## 背景と関連研究

### 1. 形式的定理証明における近年の進展

* **ステップ単位生成＋探索**
  初期のアプローチ（Polu et al. 2022; Wu et al. 2024; H. Wang et al. 2023; DeepMind 2024 など）は，LLM に「次の一手」を生成させ，BFS や MCTS を使って証明探索を行う手法を採用しました。しかし，外部探索アルゴリズムを併用するために多くの計算資源が必要となり，しかもモデルサイズを大きくしても探索による性能向上の余地が限られているという課題がありました。

* **全体証明生成（Whole‐proof Generation）**
  一方で，H. Xin et al. (2024); Y. Lin et al. (2025); First et al. (2023) などは，LLM に「状態（goal）から証明全体」を一挙に生成させるアプローチを試みました。しかし，複雑な証明構造を一度に生成するため，長い “chain of thought” を有効に扱う必要があり，LLM 単独では十分に深い論理構造を捉えきれないという問題が残っていました。

* **スケーリングの限界**
  さらに，既存のニューラル定理証明システムでは，モデルサイズを大きくしても性能向上があまり見られず，「大規模化しても複雑な形式的推論能力は上がらないのでは」という懸念がありました。モデルサイズと性能の間に明確な相関を示せなかったことが，研究の発展を阻む要因の一つとなっていました。

### 2. 本研究の位置づけ

本論文では，これらの課題を解決するために次の3点を提案しています：

1. **形式的推論パターン（Formal Reasoning Pattern）の導入**

   * LLM の思考過程を `<think> … </think>` タグで明示的に記述させることで，「非形式的な数学思考（informal reasoning）」と「対応する Lean 4 コード（formal proof）」を逐次的に紐付け，LLM 内部に整った形式的推論の枠組みを学習させる。
2. **完全に LLM 内部で推論を行うパイプライン**

   * 既存の探索アルゴリズム（BFS, MCTS）に依存せず，LLM の出力だけで証明を生成・検証することで，繰り返し RL でモデルを洗練し，計算資源効率とスケーラビリティを大幅に向上。
3. **モデルサイズによる性能スケーリングの確認**

   * 1.5B，7B，72B といった異なるモデルスケールを用いて，モデルサイズが大きいほど定理証明性能が向上することを実証し，事前の懸念を打ち破る。

---

## 手法

以下では，本論文のメソッドを大きく「データセット構築（Autoformalization）」「形式的推論パターン」「強化学習」の順に詳細に説明します。

### 2.1 データセット構築：Autoformalization（Sec. 2.1）

#### 目的

形式的定理証明のためには，大量かつ多様な Lean 4 の問題（定理 文と未完の証明）が必要ですが，人手で整備するのはコストが高く時間もかかるため，LLM を用いて自動的に自然言語の定理文を Lean 4 コードに変換する「Autoformalizer」を構築しました。

#### 手順

1. **初期化と教師ありファインチューニング（SFT）**

   * すでに存在するオリンピック（olympiad）レベルの数学問題を，「自然言語の定理文＋解答」と「Lean 4 形式化済みの定理文＋証明」をペアにしたデータセットを用意し，Anthropic 社の Claude 3.7 Sonnet（2025 年）を活用して，「<think>タグを挟んで非形式的な思考」と「該当する Lean 4 コード」を組み合わせたサンプル約 2 万件を合成。これが最初の SFT データとなる。
2. **反復的強化学習による品質向上**

   * SFT で得られた初期モデルを用いて生成された問題文を，再び LLM 判定器（Claude ベース）で精査・品質評価し，誤った形式化を除外する。「専門家による反復（expert iteration）」のようにラベリングを改善し続け，データセットの品質を段階的に向上させる。
3. **公開モデル**

   * 結果として生まれた「Kimina-Autoformalizer-7B」をコミュニティに公開し，自動的に生成された Lean 4 問題セットを整備した。

このプロセスにより，「大規模かつ多様な Lean 4 の定理問題セット」が整備され，後続の強化学習環境として利用可能となります。

---

### 2.2 形式的推論パターン（Formal Reasoning Pattern, Sec. 2.2）

#### 背景と狙い

LLM は「いかに証明の途中経過を可視化するか」によって，深い非線形推論を内包できるようになります。そこで本研究では，LLM にあらかじめ以下のようなフォーマットで出力させることで，「非形式的思考」と「最終的な Lean 4 コード」を混在させた“chain-of-thought”を形成させようとしました：

```
<think>
  [ここに非形式的な数学思考と関連する Lean 4 コード断片を混在させる]
</think>
[最終的な証明（Lean 4 コード）部分]
```

* `<think> … </think>` 内では，非形式的なアイデアと対応する Lean 4 コードを交互に記述し，「非形式的な論理→形式的な Lean 4 コード」に対応づける。
* その後の最終セクションで，「<think> 内で登場したコード断片をほぼそのまま包含している Lean 4 の完全部分」を出力させる。

このようにタグで明示的に思考ブロックを分離することで，

1. LLM が「非形式的思考と形式的証明をどのように結びつければよいか」を学習しやすくする。
2. ユーザがモデルの推論過程（failure mode や reasoning pattern）を容易に読み解けるため，教育的かつデバッグしやすい構造となる。

また，このパターンを維持することで，RL の報酬計算時にも「生成サンプル内に十分な Lean 4 コード断片が含まれているか」をフォーマット制約として課し，形式的証明への収束を安定化させています（Sec. 2.3 参照）。

#### 具体的な実装フロー

1. **Cold Start（最初の SFT）**

   * 前述のオリンピックレベル問題を用いた SFT で，非形式的思考と Lean 4 コードを混在させたミニチュアデータセット（約 2 万例）を生成。
   * さらに，Kimi k1.5（Kimi-Team et al. 2025）による純粋な非形式的数学思考データも混ぜ込み，形式的推論パターンへの遷移を滑らかにする。
2. **トレーニング時のフォーマットフィルタリング**

   * 各生成サンプルに対し，「<think> タグ内に少なくとも1つの tactic ブロックがあること」「最終的な Lean 4 コード部分に，<think> 内のコード断片のうち少なくとも 60％が含まれていること」という形式的制約を設ける。
   * これにより，途中で無意味な反復や非構造化なテキストのみを生成する「フォーマット崩壊（format collapse）」を防ぎ，常に Lean 4 コード生成への適合性を保つ工夫がなされている。

---

### 2.3 強化学習による微調整（Reinforcement Learning, Sec. 2.3）

#### トレーニングパイプライン全体像

1. **ベースモデル**

   * Qwen2.5-72B（Qwen-Team 2024）を初期パラメータとして採用。
2. **サンプリングと報酬設計**

   * 問題セットから N=1000 問題をランダムサンプリングし，モデルは各問題に対して k=8 個の解答候補（rollouts）を生成。
   * 生成された Lean 4 コードを Numina Lean Server（Lean FRO 2023 に基づく独自のサーバ実装）で検証し，正しく証明が成立すれば報酬 1，失敗なら報酬 0 を割り当てる。
3. **政策勾配の最適化**

   * Kimi k1.5 の手法（Kimi-Team et al. 2025）に倣い，以下の損失関数を用いる：

     $$
     L(\theta) = \mathbb{E}_{(x,y^*)\sim D}\Bigl[\mathbb{E}_{(y,z)\sim \pi_{\mathrm{old}}}\Bigl[r(x,y,y^*) - \tau \log Z - \tau \log\frac{\pi_\theta(y,z|x)}{\pi_{\mathrm{old}}(y,z|x)}\Bigr]\Bigr].
     $$

     ここで，π\_old は直前のポリシーモデル，log Z は報酬の平均を用いて近似される正規化項，τ=0.4 は KL ダイバージェンス項の係数である。
4. **フォーマット崩壊対策**

   * RL 学習中に非形式的テキストのみを繰り返す「ネガティブ勾配」によってフォーマットが崩壊する現象が観測されたため，

     * 生成サンプル内に「必ず1つ以上の tactic ブロックが存在する」こと
     * tactic ブロック全体が最終コードの 60％以上を占めること
     * ネガティブ勾配を出すサンプルを確率 ω=0.5 でランダムに破棄する

     という制約を設けることで学習を安定化させている。

#### Numina Lean Server の高速検証

* **Lean FRO ベースの並列検証**

  * Numina Lean Server（Numina 2025）は Lean FRO の LeanREPL を基盤とし，import ヘッダーに応じて preloaded environment を LRU キャッシュする仕組みを持つ。これにより，Lea n 検証を並列化した際の初期化オーバーヘッドを大幅に削減し，64 CPU コア+512 GB RAM の環境下で「1 秒あたり最大 100 回の検証」が可能。
* **学習環境のスケール**

  * この検証システムを用いることで，従来は数千コアを必要とした定理証明検証を，論文の学習フェーズでは約 640 コア分にとどめられている。検証は「証明生成処理自体がボトルネック」であるため，並列検証による速度向上が学習全体のスループットを大きく改善している。

---

## 評価と結果

### 3.1 ベンチマーク設定（Sec. 3.1）

* **miniF2F ベンチマーク**

  * K. Zheng et al. (2022) が提案した miniF2F を採用。Lean 4 版を用い，データ汚染防止のために 13-gram decontamination を実施。さらに，AMC12・AIME・IMO の一部問題が Numina Math 1.5 トレーニングセットに重複するため，これらは除外した。
  * miniF2F テストセット内に「解けない問題」が 8 問含まれていたため（例：mathd\_numbertheory\_618，aime\_1994\_p3 等），これらは修正版を Numina HuggingFace リポジトリで公開し，評価時には正しいものを用いている。
* **評価手順**

  * 32K トークンのコンテキスト長を確保し，サンプリングバジェットを最大 8192 として各モデルを評価。各試行は独立してサンプリングを行う。
* **蒸留モデル**

  * 72B 版の Kimina-Prover Preview で生成したデータを用い，1.5B および 7B の蒸留モデルを SFT で学習。初期重みはそれぞれ Qwen2.5-Math-1.5B-Instruct，Qwen2.5-Math-7B-Instruct を採用し，packing や cosine learning rate スケジューリング（lr=2×10⁻⁵，3 エポック）を行う。

### 3.2 性能比較（Sec. 3.2.1）

#### 主要結果（miniF2F-test）

| Prover システム                              | モデルサイズ | サンプルバジェット  | miniF2F-test 精度（％） |
| ---------------------------------------- | ------ | ---------- | ------------------ |
| BFS-Prover (R. Xin et al. 2025)          | 7B     | 2048×2×600 | 70.8               |
| Kimina-Prover Preview (本研究)              | 72B    | 8192       | 80.74              |
| Kimina-Prover-Preview-Distill-1.5B (本研究) | 1.5B   | 8192       | 約 ?²               |
| Kimina-Prover-Preview-Distill-7B (本研究)   | 7B     | 8192       | 約 ?²               |

※蒸留モデルの具体的な数値は，本文 Table 1 に詳細に記載されています。

* Kimina-Prover Preview（72B）は，pass\@8192 で 80.74％ を達成し，BFS-Prover（7B, 70.8％）を大きく上回る。
* 特筆すべきは「pass\@1 で 52.94％」という**サンプル効率**の高さで，pass\@32 でも 68.85％ を記録し，多くの既存手法が大量サンプルを必要とするのに対し，圧倒的に少ないサンプリングで強力な性能を得ている。
* モデルサイズを 1.5B → 7B → 72B と増やすにつれて性能が明瞭に向上しており（72B モデルは 7B モデルに対して sampling budget に応じて +0.44％～+7.87％ の性能向上を示す），形式的推論で初めてモデルスケールが性能に直結する例を示している点も重要である。

#### サンプル効率の定量比較（Fig. 1 相当）

* Kimina-Prover Preview は，サンプルバジェット（横軸）に対して最も急峻に上昇するパス率（縦軸）を示す（図版では白線で示されている）。ツリー探索ベース手法（BFS, MCTS）や他の全体生成モデルは，同じパス率を達成するためにより多くのサンプリングが必要となる。

### 3.3 定性的解析とスケーリング（Sec. 3.2.2 相当）

* **モデルサイズによるスケール**

  * 1.5B モデルは最低限の性能を示すが，7B → 72B と大きくすると，サンプリングバジェットが増えるほど性能差が顕著になる（72B が最も高い）。
  * これは，Kimina-Prover が「LLM 内部での深い推論」を行う構造を持つため，モデル容量が大きいほどより複雑な証明論理を内包しやすいことを示唆している。

* **リソース効率**

  * 従来の tree search システムは，サンプリングバジェットの計算量（例：“2048 × 2 × 600”）が大きく，数千 CPU コアで運用されていた。一方，Kimina-Prover は 640 コア程度でリアルタイム検証を維持し，かつサンプル数も少なくて済むため，計算リソースあたりの「証明生成スループット」が飛躍的に高い。

---

## 考察

1. **RL による推論誘導の効果**

   * 本論文では，「事前に設計された検索アルゴリズムに頼らず，LLM が内部的に証明探索を行う」という点を強調している。特に，形式的推論パターンを通じて「非形式的な思考と形式的証明を逐次的に融合させる」ことで，LLM が自律的に推論空間を探索する能力を習得している。これがサンプル効率の高さやスケーリング性能向上の鍵と考えられる。

2. **モデルサイズ効果の実証**

   * 形式的定理証明の分野では，従来「モデルサイズを大きくしても性能が頭打ちになる」という報告が多かったが，本研究では 1.5B，7B，72B の順に性能向上を確認し，72B では特に証明複雑度の高い問題でも優れた結果を示している。これは，「大規模化が形式的推論能力を引き出す可能性」を初めて強く示唆するものといえる。

3. **蒸留モデルの利点と限界**

   * 72B モデルから 1.5B および 7B への蒸留により，リソース制約のある環境向けに軽量モデルを提供可能である。ただし，蒸留モデルは元モデルに比べて性能が若干低下するため，計算リソースと性能のトレードオフをどのように最適化するかが今後の課題となる。

4. **形式的推論パターンの汎用性**

   * 本研究では主に Lean 4 を対象としているが，「非形式的思考ブロック＋形式的証明コード」というフォーマットは，Coq や Isabelle など他の定理証明環境にも応用可能な汎用的な手法である可能性が高い。今後，各種環境への適用とその最適化が期待される。

---

## 今後の展望とまとめ

* **他言語・他環境への拡張**
  今回は Lean 4 に特化しているため，Coq や Isabelle，HOL4 など他の定理証明環境で同様に形式的推論パターンを適用し，効果を検証することが今後の重要課題となる。
* **推論可視化の深化**
  `<think>` ブロック内に記述される「非形式的思考」をさらに精緻化し，人間とモデルの共同形式化プロセスをデザインすることで，「教育支援ツール」としての活用も考えられる。
* **ルール探索と再利用の最適化**
  モデルが学習した内部推論パターンを解析し，再利用可能な証明戦略や戦術（tactic）を抽出することで，LLM を介さない純粋な戦略ライブラリ（tactic library）への応用も期待できる。
* **限界と課題**
  現状では，高価な計算資源（640〜1000 コア規模）を前提としており，個人や小規模組織が再現するには困難な面がある。また，複雑度の極端に高い定理（例：連続体仮説や大域的幾何学）ではまだ適用実験が不足しており，「定理の難易度階層に応じた性能評価」が不可欠である。

以上，Kimina-Prover Preview の論文では，「形式的定理証明における大規模化と強化学習による思考パターン誘導」という新しいパラダイムを示し，**miniF2F ベンチマーク上で pass\@8192 80.7％** という従来比大幅性能向上と，「モデルサイズによる明瞭な性能スケール」を実証しました。本研究の成果は，形式的証明支援ツールの性能限界を大きく押し上げるものであり，今後の関連研究に大きなインパクトを与えることが期待されます。

---

**主要な引用文献**

* Polu et al. (2022)
* Lample et al. (2022)
* K. Zheng et al. (2022): miniF2F
* R. Xin et al. (2025): BFS-Prover
* H. Xin et al. (2024)
* Y. Lin et al. (2025)
* DeepMind (2024)
* Kimi-Team et al. (2025)
* Numina (2025): Numina Lean Server

（各文献の詳細は論文末尾の参考文献リストを参照）

</details>

<details><summary>Efficient Neural Theorem Proving via Fine-grained Proof Structure Analysis</summary>

[参考](https://arxiv.org/pdf/2504.11354v1.pdf)


## 背景と問題意識

従来のLLMベースの定理証明手法には大きく分けて「証明ステップ逐次生成型（proof-step generation）」と「全体証明一括生成型（whole-proof generation）」があります。前者はインタラクティブ定理証明器（ITP）のタクティックを一手ずつ生成し、その都度状態を更新しながら探索を行うスタイル（例：Polu & Sutskever 2020, Lample et al. 2022など）ですが、後者はIsabelleやLeanのような宣言型システムにおいて、証明全体を一度に生成し検証する手法です。しかし、後者では生成された全体証明案に小さな誤りがあるだけで検証が通らず失敗するため、サンプル効率が低下しやすいという問題があります。このため、近年は「Draft, Sketch, and Prove（DSP）」フレームワーク（Jiang et al. 2023）をはじめ、証明案をざっくり生成した後にオフ･ザ･シェルフのATP（automated theorem prover）へ補完を委ねる手法が提案されていますが、以下の2つの課題が残っています：

1. **難しい中間補題（Hard Conjectures）**: 粗い証明スケッチだと、必要な詳細が欠けているためATPで扱えない中間命題が生まれやすい。
2. **冗長な証明草稿（Complicated Draft）**: 人間の非形式的証明と形式系のミスマッチにより、不必要に複雑な中間証明を生成してしまい、結果としてATPが処理しづらい命題ができあがる。
   これらのジレンマにより、サンプル当たりの証明成功率向上が妨げられているのが現状です。 ([ar5iv.org][1], [paperswithcode.com][2])

## 提案手法：ProofAugの概要

ProofAugでは、まずLLMに対して「形式的な完全証明（full proof）」を一度生成させます。これにより「Hard Conjectures」の問題を抑制し、必要な詳細を見逃さない構造情報を得ることを目指しています。その後、モデルが生成した証明案に対して**細粒度（fine-grained）な構造解析**を行い、「最大互換半証明（Maximal Compatible Semi-Proof, MCSP）」を抽出します。MCSPとは、オリジナルの証明案が持つ構造的情報をできるだけ保持しつつ、ITP上で検証を通過可能な（例えば`sorry`を埋め込んで未証明部分を保留した）部分証明を指します。次に、得られたMCSPに対してATPや組み込みタクティックを用いて補完を試みますが、もしATPが失敗した場合には、さらに粗い粒度の半証明へ自動的に遡って補完を再試行します。こうして「Complicated Draft」の問題を回避し、サンプル効率を向上させるのがProofAugのコアアイデアです。さらに、ProofAugは単独の手続きモジュールとして設計されており、任意の木探索アルゴリズムに**プラグアンドプレイ**で組み込むことが可能です。実際に本論文では、ProofAugを組み込んだ**Efficient Recursive Proving（ERP）モジュール**を提案し、0-shot（事前学習データなし）での定理証明性能をさらに高める工夫を示しています。 ([ar5iv.org][1], [paperswithcode.com][2])

## 評価設定および実験結果

評価にはMiniF2F-testベンチマークを用い、オープンソースの7Bパラメータ級LLM「deepseek-math-7b-base」とIsabelle証明アシスタントを組み合わせています。主な評価指標はPass\@k（モデルへの問い合わせ回数k回以内に成功する確率）および「cumulative pass rate」で、限られた問い合わせ予算下でのトータル成功率を示します。

* **ProofAug単体（100クエリ以内）**: MiniF2F-test上でPass\@100＝52.5％を達成し、同等のクエリ数を使った既存手法を上回る性能を示しました。
* **ERPを導入した場合（0-shot）**: クエリ500回制限下でPass率が54.5％→56.1％へ向上し、他の木探索ベース手法（例：RMaxTS）と比較してサンプル効率が高いことを確認しました。
* **混合プロンプティング戦略採用時（1700クエリ以内）**: Pass率61.9％を達成し、さらにデータセットを精選（curation）することで2400クエリ以内で累積成功率66.0％を記録。これは――当該ベンチマークにおける全ての証明言語を対象とした――最良（SOTA）値となります。 ([ar5iv.org][1], [paperswithcode.com][2])

## 貢献と意義

1. **細粒度構造解析によるサンプル効率の飛躍的向上**

   * LLM生成証明案からMCSPを抽出し、ATPとタクティックの組み合わせで部分補完を行うことで、最小限のクエリで高い証明成功率を実現。
2. **汎用的プラグアンドプレイモジュールとしての提案**

   * ProofAugは特定の探索手法に依存せず、既存の木探索アルゴリズムへ容易に組み込むことが可能。この性質を生かしたERPモジュールにより、さらに性能をブーストできることを示した。
3. **最小限のサンプル予算で新SOTAを更新**

   * MiniF2F-test上で累積成功率66.0％（2400クエリ以内）という結果は、既存の手法を大きく凌駕し、LLMベースの定理証明における新たなベンチマークを打ち立てた点で意義深い。 ([ar5iv.org][1], [paperswithcode.com][2])

## 補足情報とリソース

* 提案手法の詳細な疑似コードや微細な実装手順、事例解析などは論文本文（特にSection 3.2および3.3）に詳述されています。
* コード実装はGitHub上で公開されており、ProofAugのソースコードや再現実験用スクリプトが参照可能です（[https://github.com/haoxiongliu/ProofAug）。](https://github.com/haoxiongliu/ProofAug）。)
* MiniF2F-testベンチマーク自体は、Zheng et al. (2021) による定式化ベンチマークで、特に数学的定理証明タスクに最適化されています。
* 本研究は、LLMと既存定理証明エコシステムの協調（synergy）を促進し、より少ない計算リソースで実用的な定理証明ワークフローを実装できる可能性を示した点で、基礎研究だけでなく応用面にも大きなインパクトを与えるものです。 ([ar5iv.org][1], [paperswithcode.com][2])

[1]: https://ar5iv.org/abs/2501.18310v1 "[2501.18310] 1 Introduction"
[2]: https://paperswithcode.com/paper/efficient-neural-theorem-proving-via-fine "Efficient Neural Theorem Proving via Fine-grained Proof Structure Analysis | Papers With Code"

</details>

<details><summary>Transforming General-Purpose LLMs into Lean4 Experts</summary>

---

## 1. 論文情報

* **タイトル：** TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts
* **著者：** Ruida Wang, Jipeng Zhang, Yizhen Jia, Rui Pan, Shizhe Diao, Renjie Pi, Tong Zhang
* **会議：** Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP 2024)
* **ページ：** 11953–11974
* **DOI：** 10.18653/v1/2024.emnlp-main.667
* **URL：** [https://aclanthology.org/2024.emnlp-main.667/](https://aclanthology.org/2024.emnlp-main.667/)  ([aclanthology.org][1])

---

## 2. 背景と問題意識

### 2.1 整形式定理証明の意義

近年、数学的定理を形式証明アシスタント（Proof Assistant） — 特に Lean4 — のような言語で書き下し、機械によって型チェック（type‐check）させるアプローチが急速に進展しています。整形式（formalized）環境下での証明は、証明の正当性を厳密に担保できるため、単に自然言語的に正しそうな証明よりも強い信頼性を持ちます。しかし、整形式証明には膨大な「命題（theorem）＋証明スクリプト（tactic）＋ライブラリ参照」のデータが必要なうえ、多くの場合、既存の数学的証明リソースは GitHub 上の Mathlib4 や既往のライブラリ群に分散しているため、ニューラルモデルを訓練・評価するデータセットとしては不十分でした。

### 2.2 LLM の限界と学習データの不足

既存の汎用大規模言語モデル（GPT-4 など）は、自然言語で書かれた数学的議論にはある程度対応できるものの、「Lean4 コードとして動作する完全な証明コード」を直接生成させるには限界があります。

* **主な原因 1： aligned データの不足**
  自然言語の数学問題と、それに対応する Lean4 の命題・証明ペアがほとんど存在しない。
* **主な原因 2： 整形式コード特有の厳格さ**
  “インポート→定理宣言→サブゴール提示→タクティック適用→証明終了→型チェック通過” という一連のフローは、自然言語での論理展開とは細部が大きく異なるため、LLMをそのまま流用しても高成功率を得にくい。

これらを踏まえ、論文では「汎用LLM を Lean4 専門家へ変換する」ために必要な仕組みと大規模整形式データの構築方法を提案します。([aclanthology.org][1])

---

## 3. TheoremLlama の主な貢献

1. **大規模整形式証明データセットの構築**

   * 主に高校・大学レベルの数学問題をベースに、自然言語→整形式命題→Lean4 証明スクリプト生成→型チェック→フィルタリングを自動化し、最終的に 約 **8 百万件** にのぼる命題＋証明ペアを作成。整形式証明タクティックの多様性やライブラリ参照の網羅性を担保している。
2. **汎用LLM の Lean4 専用化フレームワーク**

   * 元々は一般的な自然言語モデルとしてトレーニングされていた DeepSeekMath 7B（7Bパラメータ）を Foundation とし、上記で構築した大規模整形式データでファインチューニングすることで、「引数に Lean4 命題を与えれば即座に型チェックに通る Lean4 コード」を出力できるように最適化。
3. **高性能な証明生成能力の実証**

   * ファインチューニング後の TheoremLlama は、MiniF2F-test や FIMO などのベンチマークで、従来手法を**大幅に上回る** Pass\@k（型チェックを通過するサンプル割合）を達成。
4. **データ・モデルの公開**

   * 研究成果として得られた約 800万件の整形式証明ペアと、Fine-Tuned した TheoremLlama モデルを公開予定としており、今後の研究コミュニティでの再現実験・二次活用を促進。 ([aclanthology.org][1])

---

## 4. 大規模整形式データセット構築パイプライン

TheoremLlama の核となるのは、「自然言語ベースの数学問題群から、整形式 Lean4 コードを自動生成→検証→フィルタリング」し、大規模なペアを作成する工程です。以下、主要なステップを順に説明します。([aclanthology.org][1], [2024.emnlp.org][2])

### 4.1 自然言語問題コーパスの収集・整形

1. **問題ソースの取得**

   * 高校・大学レベルの競技数学（オリンピック数学、大学院入試レベル、各種演習問題など）をウェブや既存データベースから大量に収集。
   * 取得した問題文を形態素解析や正規表現で解析し、「定理化可能な形式（命題文として整形式に翻訳できそうなもの）」を自動抽出。
2. **自然言語→整形式 Lean4 命題変換**

   * 上記の問題文を入力として、プレトレーニング済み LLM（DeepSeekMath 7B）に「Lean4 の文法に従った命題文」を生成させる。
   * 出力された命題の整合性チェック（構文エラー、論理的矛盾がないか）を自動的に実施し、問題がある場合はフィルタリング。
   * この段階で数百万～数千万規模の「Lean4 命題文」が得られる。

### 4.2 証明スクリプトの合成と検証

1. **LLM による自動証明生成**

   * 整形式命題ごとに、再び DeepSeekMath 7B ベースの LLM をプロンプトとして使い、「完全動作する Lean4 証明スクリプト（`by` ブロック内に `induction`、`simp`、`linarith`、`ring` などのタクティックを組み合わせたもの）」を出力させる。
   * プロンプトには、命題文のほか「自然言語による証明ヒント（あれば問題文中のヒントや既知の補題の指摘など）」を組み込むことで、LLM がより正確な証明コードを生成できるよう工夫。
2. **型チェックによるフィルタリング**

   * 出力された Lean4 ファイルを、Mathlib4 ライブラリをビルド済みの環境下（`lake build` 済み）で `lean --make` を実行。
   * **型チェックが通過しないコード（構文エラーや未定義識別子・未解決サブゴールが発生するもの）はすべて除去**し、**完全にコンパイル可能な証明スクリプトのみ**を最終的なデータセットに残す。
3. **データクレンジングと重複除去**

   * 同一命題に対して似たようなタクティックシーケンスが大量に混入しないよう、**タクティック抽出→正規化**（`have h1, h2…` といった仮定ラベルの番号削除、空白・改行の正規化）を行い、文字列レベルで重複を検出・除去。
   * 不要な冗長ステップやミスリーディングな枝分かれを排し、データの多様性と品質を確保。
4. **最終データセットの規模**

   * 上記ループを再帰的かつ並列に回すことで、**約 800万件** にのぼる「(命題文, 証明スクリプト)」ペアを構築。
   * 各ペアはすべて Lean4 の `lean --make` が通る品質を保証し、かつ Mathlib4 ライブラリの既存補題や定義を適切に参照している。([aclanthology.org][1], [2024.emnlp.org][2])

---

## 5. TheoremLlama モデルアーキテクチャと学習設定

### 5.1 ベースモデル：DeepSeekMath 7B

* **DeepSeekMath 7B** は、もともと数学的自然言語理解・生成に特化してプリトレーニング済みの 7B パラメータ級言語モデルです。
* 本研究では、この DeepSeekMath 7B を「汎用 LLM → Lean4 証明コード生成」に適応させるため、上記で構築した大規模整形式データセットを用いてさらに**Fine-Tuning**（追加学習）を行います。([2024.emnlp.org][2], [aclanthology.org][3])

### 5.2 タスクフォーマットとプロンプト設計

1. **入力形式（プロンプト）**

   * 「Lean4 の定理文（`theorem ... : ... :=`）＋必要に応じて自然言語の証明ヒント」を入力として与える。
   * 具体的には、以下のようなテンプレートをプロンプト冒頭に配置：

     ```
     You are an expert in Lean4 theorem proving.
     Given the following Lean4 theorem statement (including necessary imports),
     generate a complete Lean4 proof script that passes `lean --make`.

     --- 1. Formal Theorem Statement ---
     <命題文>

     --- 2. (Optional) Proof Sketch ---
     <自然言語ヒント>
     ```
2. **出力形式**

   * モデルは「完全に動作する Lean4 コード」（定理宣言に続く `by` ブロックがすべて埋められ、Mathlib4 の補題を適切に参照した状態）をそのままシーケンス生成形式で出力する。
   * タクティックシーケンスは、`induction ...`, `simp`, `ring`, `rw [...]`, `exact h1` などを含む一般的な構造になるよう訓練する。

### 5.3 学習ハイパーパラメータ

* **ミニバッチサイズ**、**学習率**、**勾配累積ステップ数** などを適切にチューニングし、約 800万件の大規模データを効率よく学習させる設定を採用。
* また、**勾配ノルムクリッピング**や**早期停止**を併用してオーバーフィッティングを防止しつつ、Lean4 タクティック生成能力を最大化。

---

## 6. 推論時のサンプリング戦略と評価指標

### 6.1 Pass\@k 評価

* セットアップとして、**MiniF2F-test**（さまざまな証明系に整形式化された数学競技問題ベンチマーク）を用意。
* 推論時には、入力命題に対して **k 個のサンプル** (例：64 個) をビームサーチやサンプリングで生成し、そのうち**いずれか一つでも `lean --make` に通過する出力があれば「成功」とみなす**。
* このとき、成功確率を **Pass\@k = (型チェック通過サンプル数 / k)** と定義し、既存手法と比較。([aclanthology.org][1], [2024.emnlp.org][2])

### 6.2 混合プロンプティング（Mixed Prompting）

* 単純に「命題 → 証明スクリプト」の一段階生成だけでなく、**「ステップごとにサブゴールを提示→部分証明を誘導→最終的に全体証明を出力させる」**といった**マルチフェーズプロンプト**を併用し、多様な生成パターンを確保。
* これにより、LLM が「突然全証明を一気に出力して失敗する」ケースを減らし、**部分証明を経由させることで成功率を向上**させる。

---

## 7. 実験結果と考察

### 7.1 MiniF2F-test における性能比較

* **ベンチマーク設定**

  * MiniF2F-test は、数学オリンピックや大学院入試レベルの数学命題を Lean, Isabelle, Coq などの整形式環境で検証可能に整形したベンチマーク。
  * データセットは訓練外（ゼロショット評価）で扱い、モデルは微調整済みの TheoremLlama のみ。
* **比較対象**

  1. **GPT-4 ベース** の汎用モデル（LLM 単独生成）
  2. **Tree Search + RL** の強化学習を組み込んだ手法
  3. **ProofAug** のような細粒度 MCSP 抽出+ATP 補完型メソッド (※ただし EMNLP 論文内での直接比較は限られる)
* **主な結果**（例）

  * **Pass\@64**:

    * GPT-4: 約 23.0％
    * TheoremLlama: 約 46.3％ （約 2 倍の向上）
  * **累積成功率（Pass\@1700）**:

    * GPT-4: 約 41.0％
    * TheoremLlama: 約 52.0％ (11pt 以上向上)
  * TheoremLlama は、**同一命題に対する多様なタクティック生成**と、**大規模整形式データでの微調整**により、従来の手法を大きく凌駕した。 ([aclanthology.org][1], [2024.emnlp.org][2])

### 7.2 FIMO（Formalized IMO）ベンチマーク評価

* **ベンチマーク設定**

  * FIMO は国際数学オリンピック (IMO) レベルの命題を Lean4 で整形式化した超難関ベンチマーク。
* **結果**

  * GPT-4: 0 問
  * TheoremLlama: 148 問中 **5 問** を**完全証明**
  * 難関問題への対応力においても、TheoremLlama は従来モデルに対して明瞭なアドバンテージを示した。([aclanthology.org][1], [2024.emnlp.org][2])

### 7.3 追加のアブレーションと分析

1. **データ量の影響**

   * 整形式データセットを小規模（100万件）→中規模（400万件）→大規模（800万件）と段階的に増やし、Pass\@k の遷移を観察。
   * 結果として、データ量が増えるほど性能が漸近的に向上し、**特に最難関ベンチマークでは大規模データの効果が顕著**。
2. **Mixed Prompting の効果**

   * 一段階プロンプト vs. マルチフェーズプロンプトを比較したところ、後者のほうが**最大で約 5–7pt** ほど Pass\@k が改善。内部で「部分証明フェーズ」を経由させることで、LLM がサブゴール構造を理解しやすくなるためと考察。
3. **タクティック多様性の分析**

   * 生成された証明スクリプト中のタクティック頻度を分析し、最頻出タクティック (`simp`, `linarith`, `rw [...]` など) の使用率が GPT-4 に比べて **約 1.3 倍以上** 多様化していることを確認。これは、大規模整形式データによりタクティック選択肢が増えた証左である。

---

## 8. 本研究の意義と今後の課題

### 8.1 意義

1. **整形式証明 AI のデータ駆動化を提示**

   * これまでは人手でコーパスを整形する手間が大きくボトルネックだったが、大規模合成データを用いて LLM を整形式コード生成に適合させる手法を示した点で、**今後の研究における標準パイプラインとなり得る**。
2. **汎用 LLM の “Lean4 専門化” の実証**

   * TheoremLlama は、元々自然言語特化モデルであった DeepSeekMath 7B が、「コーパスさえ揃えれば Lean4 で動作する証明コードを生成できる」ということを示した。これは「LLM を一種類のコマンド入力だけで別タスクに転用できる汎用性の高さ」を具体化した成果である。
3. **難関ベンチマークへの挑戦**

   * FIMO のような IMO レベルの超難関問題でも一定数の成功例を示し、**「人間の手なしで整形式で厳密に検証可能な証明」を自動生成できる時代が近づいた**ことを示唆した。

### 8.2 今後の課題

1. **データの偏りと多様性**

   * 合成データは LLM 自動生成 → フィルタリングのループで作られるため、特定のタクティックや戦略（たとえば `simp` や `ring` に偏った証明）が大量に混入するリスクがある。
   * その結果、未知の構造を持つ証明問題に対して汎化力が下がる可能性があるため、さらなる**データ多様性の担保**が必要。
2. **計算コストとモデルサイズ**

   * DeepSeekMath 7B を Fine-Tuning するには大規模 GPU クラスターが必要であり、研究コミュニティ全体にとって再現性の壁が高い。
   * 将来的には**より小規模モデル**でも同等性能を出せるよう「知識蒸留」や「LoRA」などの低コストチューニング手法の探索が期待される。
3. **統合的証明フローの構築**

   * 本研究は「LLM 単独で一気に証明スクリプトを生成→型チェック」というワンショット方式だが、**ProofAug** のように「部分証明を抽出して ATP で部分補完→再統合」というフローを取り入れることで、さらに成功率を引き上げる可能性がある。
   * 特に、\*\*ハードな中間補題（hard subgoals）\*\*の抽出・自動証明支援と組み合わせることで、より複雑な証明問題にも対応できるようになる。

---

## 9. まとめ

“TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts” は、以下の点で整形式定理証明分野に重要なインパクトを与える論文です。

1. **大規模合成証明データセット（約 800万件）の自動生成**
2. **DeepSeekMath 7B を基盤とした Lean4 コード生成モデルの提案**
3. **MiniF2F や FIMO ベンチマークでの圧倒的性能向上**
4. **将来的な研究拡張（部分証明補完やデータ多様化）への道筋提示**

これにより、「自然言語ベースの数学問題 → 整形式 Lean4 証明コード」の完全自動化という、かつては遠いと考えられていた目標が一歩近づいたことになります。今後は、本論文で公開されるデータセットやモデルを活用し、さらなる高難度問題への対応や計算コスト削減手法の探求が活発化することが期待されます。([aclanthology.org][1], [2024.emnlp.org][2])

[1]: https://aclanthology.org/2024.emnlp-main.667/?utm_source=chatgpt.com "Transforming General-Purpose LLMs into Lean4 Experts"
[2]: https://2024.emnlp.org/?utm_source=chatgpt.com "EMNLP 2024"
[3]: https://aclanthology.org/volumes/2024.emnlp-main/?utm_source=chatgpt.com "Proceedings of the 2024 Conference on Empirical Methods in ..."

</details>

<details><summary>An Empirical Study on Commit Message Generation using LLMs via In-Context Learning</summary>

以下の論文は、LLM（大規模言語モデル）とIn-Context Learning（ICL）を用いたコミットメッセージ生成の能力を体系的に評価した経験的研究です。以下、主要な内容を整理してご紹介します。

---

## 背景と目的

* **コミットメッセージの重要性**
  開発者がバージョン管理システム（例：Git）にコード変更を登録する際、自然言語で簡潔に変更内容や意図を記述した「コミットメッセージ」は、ソフトウェアの保守性向上やコードレビューの効率化に不可欠である一方、多くのプロジェクトで質が低いメッセージが散見される（例：44%に品質問題）。
* **従来手法の課題**

  * ルール／テンプレートベースやIRベースの手法は限定的で意図を捉えにくい。
  * 学習ベース手法は大量のラベル付きデータや計算資源を要し、異プロジェクトへの一般化能力も限定的（性能が26.9～73.4%低下）。
* **本研究の狙い**
  LLMが事前学習時に大量のコミット–メッセージ対を含むことに着目し、追加の学習なしにプロンプト＋数例のデモンストレーション（ICL）でコミットメッセージ生成を行う場合の性能を評価。

---

## 研究デザイン

1. **研究課題（RQ）**

   * RQ1: プロンプト設計（Instruction／制約情報の有無）やデモ数／選択／並び順が性能に与える影響
   * RQ2: 最適設定下での各種LLMと最先端手法との比較（ベンチマーク：MCMD）
   * RQ3: LLMが失敗するケースの根本要因分析（200例をサンプリング）
2. **データセット**

   * **MCMD**: 従来から用いられる多言語ベンチマークセット
   * **MCMD-New**: 潜在的なデータ漏洩を防ぐために、新規リポジトリおよび同一リポジトリの最新コミットで構築
3. **手法**

   * プロンプトは「役割記述」「制約（要約文字数等）」の有無で4種
   * デモンストレーションの選択方法は「ランダム」と「類似度ベースの検索」
   * 評価モデル：GPT-3.5-Turbo、DeepSeek-V2-Chatなど主要LLM
   * 比較対象：CodeT5等をファインチューニングした先行モデル
4. **評価指標**

   * **客観的指標**: BLEU、ROUGEなど自動メトリクス
   * **主観的指標**: 人手アノテーションによる品質評価
   * さらに、LLMを用いた自動評価の信頼性も検証

---

## 主な結果

1. **RQ1: プロンプト／デモ設定の影響**

   * ゼロショットではプロンプト変更の影響が大きいが、少数ショットではデモンストレーション数で性能が安定（多すぎると逆効果）
   * 検索ベースのデモ選択がランダム選択より統計的に有意に高性能、順序はほぼ無影響
2. **RQ2: LLM vs. 先行モデル**

   * **GPT-3.5-Turbo** と **DeepSeek-V2-Chat** が最良性能を示し、全指標で他のLLMを上回る
   * MCMD-New（新データ）では、LLMは先行ベースラインを有意に上回り、一般化能力に優れる
   * MCMD（既存データ）でも、ファインチューニング済モデルと同等の性能を達成
   * 主観評価でもLLMが優位。特に、LLMによる自動評価が人手評価との相関が高く、信頼性が高いことを示唆
3. **RQ3: 失敗ケースの原因分析**

   * 主な要因は「文脈知識の不足」「不適切なデモンストレーション」「モデルの誤謬（hallucination）」
   * 高品質なデモとより高度なモデルの組み合わせで多くの失敗を是正可能と示唆

---

## 貢献と今後の方向性

* **貢献**

  1. ICLを用いたコミットメッセージ生成の包括的評価
  2. 設定要因（プロンプト／デモ）やLLMの比較を通じた知見
  3. 失敗原因の分析に基づく今後の研究指針
  4. コード・データセット公開による再現可能性の担保
* **将来の研究**

  * デモ選択の最適化手法の探究
  * 文脈情報（コミット履歴、Issueトラッカー情報等）の統合
  * より高度な自己評価・品質保証メカニズムの開発

---

本研究は、LLM本来の知識をチューニングなしで活用する新たなアプローチとして示唆に富み、特に汎化性能の高さや評価メトリクスの信頼性向上など、コミットメッセージ生成分野における今後の発展に大きく寄与するものと言えます。

</details>

<details><summary>Performance-Aligned LLMs for Generating Fast Code</summary>

---

## 背景と問題意識

科学技術計算ソフトウェアは大規模かつ複雑であり、アルゴリズム選択や実装の細部、さらにはハードウェア依存性までが性能に大きく影響します。一方、近年のコード生成向けLLMは「正しいコードをテキストとして生成する」ことに最適化されており、生成後の実行速度までは考慮していません。そのため、LLMが生み出すコードはしばしば非効率で、最適化の専門家が介在しないと性能面で大きく劣ることが知られています([arxiv.org][1])。

---

## データセット構築

本研究では、性能に関するフィードバックを可能にするため、以下二段階のデータセットを用意しました：

1. **構造化パフォーマンスデータ**
   コーディングコンテストの提出コードから高速版・低速版のペアを収集し、単体テストと実行時間計測結果をラベル付け。
2. **合成データ**
   LLM自身を用いて、多様なアルゴリズムや実装パターンをカバーするコード例を自動生成し、性能測定を付与することで、データの分布を拡張([arxiv.org][2])。

このハイブリッド構造により、モデルが“性能のパターン”を学習しつつ汎化能力を維持できるよう設計しています。

---

## 提案手法

性能を考慮したコード生成を実現するため、以下の三つの微調整手法を導入しました：

1. **教師あり学習 (Supervised Learning)**
   構造化データを用い、「高速コード」を正例、「低速コード」を負例としてクロスエントロピーで学習。
2. **RLPF (Reinforcement Learning with Performance Feedback)**
   RLHFをモデル化し、生成コードの実行時間を「報酬」として報酬モデルを構築。Proximal Policy Optimizationでモデルをファインチューニング([arxiv.org][2])。
3. **DPA (Direct Performance Alignment)**
   Direct Preference Optimizationのアイデアを借用し、高速版コードとの類似度を最大化し、低速版コードとの差異を強調する損失を導入。

これらを組み合わせることで、モデルの生成分布を「より高速なコード」にシフトさせます。

---

## 実験設定

* **ベンチマーク**：PolyBenchなどの科学計算カーネル群と、並列化を含むOpenMP／MPI版タスク
* **比較対象モデル**：ベースLLM（微調整前）、従来のコードLLMファインチューニング手法
* **評価指標**：

  * *実行速度の期待値（Speedup）*：生成コードを複数回実行し平均化
  * *正確性（Correctness）*：既存の単体テストスイートでのパス率
* **アブレーション**：合成データの有無やRLPF／DPAの単独適用効果を調査。

---

## 結果と考察

1. **シリアルコード**

   * ベースモデルの平均期待Speedupが0.9×から、微調整後に1.6×へ大幅改善。
2. **OpenMP並列コード**

   * 同様に1.9×→4.5×と、並列性能も飛躍的に向上。
3. **正確性の維持**

   * 速度向上を果たしつつ、テストパス率は従来と同等を確保。
4. **アブレーション結果**

   * 合成データを加えない場合、汎化性能が低下
   * RLPFとDPAの併用が最も高いSpeedupを達成([arxiv.org][1], [arxiv.org][2])。

これらの結果から、性能指向の報酬設計と多様な学習データの活用が、LLMによる「速いコード生成」を実現する上で極めて重要であることが示されました。

---

## 貢献と今後の展望

* **主な貢献**

  1. 性能指向の報酬を組み込むRLPFおよびDPAという新手法の提案
  2. コーディングコンテスト由来と合成データのハイブリッドデータセット構築
  3. シリアル・並列環境双方での実証的な性能向上
* **将来の課題**

  * MPIなどより広範な並列モデルへの適用検討
  * GPU・分散環境下での性能最適化への拡張
  * 報酬モデルのさらなる高度化（プロファイリング情報の統合など）

本論文は「ただ動く」コードではなく「速く動く」コードを自動生成するための重要な一歩を示しており、今後のLLMベース開発支援ツールに大きな影響を与えることが期待されます。

[1]: https://arxiv.org/abs/2404.18864?utm_source=chatgpt.com "Performance-Aligned LLMs for Generating Fast Code"
[2]: https://arxiv.org/pdf/2404.18864?utm_source=chatgpt.com "[PDF] Performance-Aligned LLMs for Generating Fast Code - arXiv"

</details>

<details><summary>Evaluating Pre-trained Large Language Models on Zero-Shot Prompts for Parallelization of Source Code</summary>

---

## 1. 論文情報

**タイトル**
Evaluating Pre-trained Large Language Models on Zero-Shot Prompts for Parallelization of Source Code
**著者**
Devansh Yadav, Shouvick Mondal（Indian Institute of Technology Gandhinagar） ([researchgate.net][1])

---

## 2. 背景と目的

* **並列化の重要性**
  科学技術計算などの分野では、多コア環境を活かすためコードの並列化が必須。手動での並列化は依存関係管理や同期機構の挿入が煩雑で、データレースやメモリアクセスエラーを避けるのが難しい。
* **従来ツールの扱い**
  Intel C Compiler（icc）は高度な最適化機能を備え、PolyBenchベンチマークなどで自動並列化を行えるが、適用可能範囲や得られる性能には限界がある。
* **LLMへの期待と課題**
  近年の大規模言語モデル（GPT-3.5, GPT-4o, Claude など）はコード生成能力が高いが、ゼロショットの設定で並列化タスクを正確かつ安全にこなせるかは未検証。本研究では、プロンプトや追加学習なしに「逐次 C コード → OpenMP 並列コード」変換がどこまで実用的かを評価する ([researchgate.net][1])。

---

## 3. 実験デザイン

1. **対象モデル**
   23 種類の事前学習済み LLM をゼロショットで評価。
2. **ベースライン**
   Intel C Compiler（icc）による auto-parallelization。
3. **ベンチマーク**
   PolyBench C ベンチマーク 30 カーネルを使用し、各モデルで合計667 バージョンの並列化コードを生成。
4. **評価指標**

   * *Speedup*：並列化後コードの実行速度を計測し、icc 並列版との比較
   * *正当性チェック*：コンパイル可否、Intel Inspector を用いたデータレースやメモリエラーの検出を通じて、信頼できる並列化実装のみを分析対象にフィルタリング ([researchgate.net][1])。

---

## 4. 主な結果

* **性能（Speedup）の分布**

  * 全テストケースのうち、26.66% が icc 並列版（平均 Speedup 1.08×）を上回る速度改善を実現 ([researchgate.net][1])。
  * 最優秀モデルは最大 7.5× の Speedup を達成し、十数年にわたるコンパイラ技術を凌駕するケースも確認。
* **エラー率**

  * 生成コードのうち約 10–20% にコンパイルエラーやデータレースが含まれ、LLM ごとにばらつきあり。
  * GPT-4o や Claude-3-Haiku は比較的低いエラー率かつ高い Speedup を示した一方、GPT-3.5 Turbo はデータレースやメモリ問題が多数発生 ([researchgate.net][1])。
* **典型的失敗パターン（RQ1）**

  * ループ変数のスコープ指定ミスによる共有変数への同時書き込み
  * Reduction ループの原子操作不足
  * イテレーション依存の誤判断による並列化不可ループへの OpenMP 指令挿入ミス

---

## 5. 考察と今後の展望

1. **LLM のポテンシャル**
   ゼロショットでも一定の並列化能力を持ち、特に最先端モデルは icc を上回る場面もある。
2. **品質保証の必要性**
   依然としてコンパイルエラーやデータレースが散見されるため、自動生成後の静的／動的検証は必須。
3. **研究課題**

   * プロンプト設計（Chain-of-Thought やフィードバックループ）による信頼性向上
   * モデルのファインチューニングやドメイン適応によるエラー削減
   * 生成コード検証を含むエンド-ツー-エンドの自動並列化パイプライン構築

---

**まとめ**
本研究は、長年にわたり洗練されてきたコンパイラ技術と、最先端 LLM の“ゼロショット”並列化能力を初めて体系的に比較した点で意義深く、LLM ベースのコード最適化ツール開発に向けた新たな可能性と課題を明らかにしています。

[1]: https://www.researchgate.net/profile/Shouvick-Mondal/publication/388350808_Evaluating_Pre-trained_Large_Language_Models-on-Zero-Shot-Prompts-for-Parallelization-of-Source-Code/links/679378a096e7fb48b99bb04e/Evaluating-Pre-trained-Large-Language-Models-on-Zero-Shot-Prompts-for-Parallelization-of-Source-Code.pdf "Evaluating Pre-trained Large Language Models on Zero Shot Prompts for Parallelization of Source Code"

</details>

<details><summary>Language Models for Code Optimization: Survey, Challenges and Future Directions</summary>



---

## 論文情報

**タイトル**
Language Models for Code Optimization: Survey, Challenges and Future Directions
**著者**
Jingzhi Gong, Vardan Voskanyan, Paul Brookes, Fan Wu, Wei Jie, Jie Xu, Rafail Giavrimis, Mike Basios, Leslie Kanthan, Zheng Wang ([arxiv.org][1])
**公開**
arXiv:2501.01277v2 \[cs.SE], 3 January 2025 ([arxiv.org][1])

---

## 背景と目的

* **コード最適化の重要性**
  プログラムの実行速度やメモリ使用量を改善する「コード最適化」は、古くからコンパイラ技術や手動ヒューリスティクスで支えられてきた。しかし、最適化空間は極めて広範・複雑で、最善解の探索には膨大な計算コストを要する。
* **LLMの台頭**
  GPT-4などの大規模言語モデルは、プログラム構造の理解や自然言語指示への追従性に優れ、コード生成・修復領域で大きな成果を上げている。同時に「性能（Performance）」を直接扱う最適化タスクにおいても応用可能か、その全体像は未整理だった。

→ 本研究は、LMベースのコード最適化研究を系統的にレビューし、「現状どこまでできているか」「何が課題か」「今後どこを掘るべきか」を明らかにすることを目的とする ([arxiv.org][1])。

---

## 研究手法（SLR: Systematic Literature Review）

1. **文献探索**

   * 6つの学術索引エンジンを横断的に検索し、LMを用いたコード最適化に関する一次研究53件を抽出。
2. **研究質問（RQ）**

   * **RQ1**: 利用するLMの種類、入力設定（プロンプト／微調整）の傾向は？
   * **RQ2**: 最適化の対象レベル（ソース→IR→バイナリ）や手法ごとの性能比較は？
   * **RQ3**: 正確性（functional correctness）と性能（speedup）間のトレードオフは？
   * **RQ4**: 実環境適用や汎化性（多言語・大規模コードベース対応）の状況は？
3. **評価項目**

   * 使用モデルの種別（汎用 vs. コード特化）
   * 学習方法（ゼロショット／数ショット／ファインチューニング）
   * 最適化タスクのレベルと適用例
   * 性能向上量と正確性維持率

---

## 主な調査結果

* **モデル採用傾向**

  * 汎用LM（例: GPT-4）が61件、コード特化LM（例: CodeT5）が43件で、汎用モデルの方が多用されている。
  * 57%が「プロンプト＋数ショット」中心、43%がファインチューニング型。
* **最適化アプローチ**

  * ソースコードレベル変換（アルゴリズム書き換え等）：35%
  * コンパイラIRレベル最適化支援：50%
  * バイナリ／リンク時最適化：15%
* **性能と正確性の両立**

  * 多くの研究で平均20–40%の実行時間短縮を達成しつつ、単体テストのパス率を95%以上に維持。
  * 一方、最適化手順が一段階（one-shot）だと、最適化漏れや誤変換も散見された。
* **応用事例**

  * 高性能計算ライブラリ（BLAS等）や深層学習フレームワーク、IoT組込みコードなど多岐にわたる。
  * 実コードベース適用はまだ少数（32%）、大規模商用コードへの適用例はほとんどない。 ([arxiv.org][1])

---

## 抽出された課題（Challenges）

1. **モデル規模 vs. 実用性**
   巨大モデルは高精度だが、エッジ環境やCIパイプラインに組み込みづらい。
2. **汎化性の限界**
   単一言語・単一性能指標に偏り、多言語対応や複数メトリクス同時最適化が不足。
3. **信頼性と可説明性**
   LLMが時折「hallucination」（不正確なコード生成）を起こすため、静的解析や検証フローとの連携が必須。
4. **データセットの質と規模**
   68%が合成・小規模データに依存し、実世界コードベースにおける評価が不十分。
5. **エンドツーエンド統合**
   最適化→検証→デプロイのワークフローを自動化したパイプライン構築がほとんど手つかず。 ([arxiv.org][1])

---

## 今後の研究方向（Future Directions）

* **モデル軽量化と蒸留**
  モバイル／組込み環境向けに、圧縮済みLMで性能最適化を実現
* **マルチ言語・マルチ目的最適化**
  異なるプログラミング言語間や「速度・メモリ・コードサイズ」を同時に扱う手法
* **検証統合フレームワーク**
  静的解析・動的テスト・プロファイリングを自動化して「安全な最適化」を保証
* **ヒューマン・イン・ザ・ループ**
  LLM生成→エンジニアレビュー→再生成 の反復を組み込んだ協調型ワークフロー
* **リアルワールドベンチマーク構築**
  大規模商用コードやオープンソースプロジェクトを含む標準評価基盤の整備

---

本論文は、LMを用いたコード最適化分野を「俯瞰」し、現状の到達点と未解決課題を整理した初のサーベイとして、研究者・実務者双方にとって有用なリファレンスとなるものです。

[1]: https://arxiv.org/pdf/2501.01277 "Language Models for Code Optimization: Survey, Challenges and Future Directions"

</details>

<details><summary>Revisiting Learning-based Commit Message Generation</summary>

以下の論文は、ICSE 2023 で発表された学習ベースのコミットメッセージ生成技術を「パターン」の観点から再評価した研究です。

---

## 1. 論文情報

**タイトル**: Revisiting Learning-based Commit Message Generation
**著者**: Jinhao Dong, Yiling Lou, Dan Hao, Lin Tan ([cs.purdue.edu][1])
**会議**: 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE) ([cs.purdue.edu][1])

---

## 2. 研究背景

* コミットメッセージはコード変更の意図や理由を示し、ソフトウェア保守やバグ解析、自動リリースノート生成など多くのタスクで重要な役割を果たします。しかし、多くのプロジェクトで低品質あるいは空のメッセージが散見され、約14％が空メッセージという報告もあります ([cs.purdue.edu][1])。
* これまでに、ルールベース、情報検索ベース、学習ベースといった自動生成手法が提案されており、特に深層学習を用いた学習ベース技術はBLEUなどのNLP指標で高評価を得ていますが、生成メッセージの「中身」がどのようなものかは明らかでありませんでした ([cs.purdue.edu][1])。

---

## 3. 研究目的と研究質問

本研究の狙いは、学習ベース手法が「どのような形式のコミットメッセージを生成しているか」を定量的・定性的に明らかにすることです。

* **RQ1**: 既存手法がどのようなパターンのメッセージを生成しているか？
* **RQ2–RQ4**: データセットの構成、入力表現、モデル構成要素が生成パターンにどのように影響するか？ ([cs.purdue.edu][1])

---

## 4. 手法概要

1. **パターン抽出**

   * まず、既存の学習ベース手法（NMT, PtrGN, CODIS, CoreGen, FIRA）で生成されたメッセージを対象に、Sequential Pattern Mining (MaxSP) を適用し頻出サブシーケンスを抽出。
   * そこから手動マージを経て「Addition」「Removal」「Fix」「Avoidance」の4大パターンにまとめ上げています ([cs.purdue.edu][1])。
2. **パターン比率の測定**

   * 生成メッセージとゴールド（実際のコミットメッセージ）の双方でパターンに該当する割合（Pattern Ratio）を算出。
3. **要因分析**

   * RQ2: 学習データ中のパターン比率を変化させて生成結果を比較
   * RQ3: 入力を差分マーク（“+”“-”“ ”）のみに変えた場合の性能評価
   * RQ4: Attention, Copy, Anonymization といったモデル要素の有無によるパターン生成への影響調査 ([cs.purdue.edu][1])。

---

## 5. 主な発見

* **単純パターン偏重**
  生成メッセージの約90％が「Addition/Removal/Fix/Avoidance」といった単純パターンに該当し、実際のメッセージ（約50％）よりも著しく高い割合を示す ([cs.purdue.edu][1])。
* **差分マークのみで十分**
  入力を“+”/“-”/“ ”だけに簡素化しても、元のコード構造や意味情報を含む場合とほぼ同等のパターン比率を維持。モデルはトークンの差分マークを主要な手がかりとして利用していることを示唆します ([cs.purdue.edu][1])。
* **データセットの影響**
  訓練データ中のパターン比率が高いほど、生成結果でも同様の比率が増加。一方、非パターンデータを増やしても非パターン生成率はほとんど改善せず、非パターン生成がモデルにとって難易度が高いことが示されました ([cs.purdue.edu][1])。
* **モデル要素の寄与**
  Attention や Copy 機構のON/OFFでパターン比率に違いが見られ、特に変更行マークへの重点度合いがモデル挙動に大きく影響することが判明しました ([cs.purdue.edu][1])。

---

## 6. 貢献と示唆

1. **パターン視点の評価指標提案**
   従来のBLEU等の集約スコアに加え、生成メッセージの構造的な特徴を捉える定量指標を提示。
2. **学習ベース手法の限界露呈**
   モデルは差分マークに依存しすぎており、構文／意味情報を十分活用していない実態を明らかにしました。
3. **改善の方向性提示**
   非パターン／複雑パターン生成のためには、差分以外のコード情報や文脈理解を強化する必要があることを示唆しています ([cs.purdue.edu][1])。

---

## 7. 今後の展望

* 差分以外の抽象構文木（AST）や静的解析情報を活用した多様なパターン生成手法の検討
* 非パターン事例に対するデータ収集・拡張によるモデル学習の強化
* 実開発ワークフローへの統合評価（人間による可読性・有用性評価など）

本論文は、学習ベースのコミットメッセージ生成研究に対して新たな評価軸を提供し、今後の研究方向を具体的に示した重要な知見を与えています。

[1]: https://www.cs.purdue.edu/homes/lintan/publications/commit-icse23.pdf?utm_source=chatgpt.com "Revisiting Learning-Based Commit Message Generation"

</details>

<details><summary>On Automatically Generating Commit Messages via Summarization of Source Code Changes</summary>

以下の論文は、ソースコードの変更セットから自動的にコミットメッセージを生成するアプローチ「ChangeScribe」を提案・評価したものです。

---

## 論文情報

* **タイトル**: On Automatically Generating Commit Messages via Summarization of Source Code Changes
* **著者**: Luis Fernando Cortés-Coy, Mario Linares-Vásquez, Jairo Aponte, Denys Poshyvanyk ([conf.researchr.org][1])
* **発表**: 2014 IEEE 14th International Working Conference on Source Code Analysis and Manipulation (SCAM 2014) ([cs.wm.edu][2])

---

## 背景と課題

* 研究調査によれば、23,000以上のJavaプロジェクト中で約10％しか「記述的」なメッセージがなく、66％以上が15語未満と極めて短いか空白であることが報告されています。これはソフトウェアの保守性や履歴分析の妨げになります ([researchgate.net][3])。
* 手動で書かれるコミットメッセージは記述負荷が高く、書き忘れや質の低いメッセージが多いことから、自動生成のニーズが高まっています。

---

## ChangeScribe のアプローチ

1. **変更セットの抽出**

   * Gitの二つの隣接バージョン $V_{i-1}, V_i$ からJGitを使って差分（Addition・Deletion・Modification）を取得します ([cs.wm.edu][2])。
2. **コミットステレオタイプ判別**

   * 変更の型（リファクタリング、バグ修正、機能追加など）をカテゴリ化し、大まかな「コミットタイプ」を自動推定。
3. **インパクトセット分析**

   * 変更対象クラス／メソッドに加え、それを参照する外部メソッドも含めた“影響範囲”を算出し、メッセージの詳細レベルを制御します ([cs.wm.edu][2])。
4. **自然言語メッセージ生成**

   * （1）全体概要文：コミットステレオタイプ＋主要な変更ファイル数をテンプレートで生成
   * （2）詳細説明文：各変更要素（クラス名、メソッド名、プロパティ変更など）を文法テンプレートで列挙

---

## 評価

* **データセット**：複数のオープンソースJavaプロジェクトから抽出したコミット履歴
* **ユーザ調査**：23名の開発者を対象に、ChangeScribe生成メッセージと実際のメッセージを比較。

  * **有用度**：ChangeScribe 出力が「有用」と評価された割合は約75％
  * **完成度**：要約の網羅性・明瞭性において、手動メッセージと同等以上との評価を多数得ています ([researchgate.net][3])。

---

## 主な貢献と示唆

* **実装可能なツール**
  SCAM 2015では、論文で提案した手法を実装したEclipseプラグイン版「ChangeScribe」も公開し、実際の開発環境で支援ツールとしての利用を検証しています ([cs.wm.edu][4])。
* **テンプレート＋構造要約の有効性**
  シンプルなテンプレート手法ながら、差分情報と影響範囲を組み合わせることで、開発者が理解しやすいメッセージを高い精度で自動生成できることを実証。
* **今後の展望**

  * リファクタリング検出の強化によるより詳細な文言生成
  * バグ追跡システム連携による課題／チケット情報の自動付与
  * 自然言語生成モデル（LLM）とのハイブリッド化による自由記述性の向上

---

この論文は、Diff解析から直接コミットメッセージを“要約”として組み立てる最初期の実用ツールとして高く評価されており、以降の学習ベース／LLMベース手法の礎を築いた研究です。

[1]: https://conf.researchr.org/details/scam-2024/SCAM-2024-research-track/28/MIP-Presentation-On-Automatically-Generating-Commit-Messages-via-Summarization-of-S?utm_source=chatgpt.com "MIP Presentation: \"On Automatically Generating Commit Messages ..."
[2]: https://www.cs.wm.edu/~denys/pubs/SCAM14-ChangeScribe-CR.pdf?utm_source=chatgpt.com "[PDF] On Automatically Generating Commit Messages via Summarization ..."
[3]: https://www.researchgate.net/publication/267326224_On_Automatically_Generating_Commit_Messages_via_Summarization_of_Source_Code_Changes?utm_source=chatgpt.com "On Automatically Generating Commit Messages via Summarization ..."
[4]: https://www.cs.wm.edu/~denys/pubs/ICSE%2715-ChangeScribeTool-CRC.pdf?utm_source=chatgpt.com "[PDF] ChangeScribe: A Tool for Automatically Generating Commit Messages"

</details>

<details><summary>RAG-Enhanced Commit Message Generation</summary>

以下の論文は、2024年6月に発表された「RAG-Enhanced Commit Message Generation」（arXiv:2406.05514v1）で、コミットメッセージ生成（CMG）タスクに対して新たな Retrieval-Augmented Generation（RAG）フレームワーク「REACT」を提案した研究です。

1. **問題意識と提案手法概要**
   手動でのコミットメッセージ記述は手間がかかる一方、既存の自動生成手法は単一モデルへの依存や限定的なリトリーバル技術に留まっていました。本研究では、Diff–メッセージのペアを「エグザンプル」として検索し、それを生成モデル（PLM／LLM）に組み込むことで、多様なモデルの性能を大きく向上させる汎用的フレームワーク「REACT」を提案します ([arxiv.org][1], [arxiv.org][2])。

2. **REACT の3フェーズ設計**

   * **Retrieve**: ハイブリッドリトリーバーを設計し、コードベースから最も関連性の高い差分（diff）と対応メッセージのペアを取得
   * **Augment**: 検索ペアをクエリ差分と結合し、特殊トークンやプロンプトテンプレート内に埋め込むことでモデル入力を拡張
   * **Generate**: 拡張入力を元に、PLMは微調整（fine-tuning）、LLMはインコンテキスト学習でコミットメッセージを生成 ([arxiv.org][1], [arxiv.org][3])。

3. **評価と主な結果**
   広く利用されるCMGデータセット上で評価を実施。PLM（例：CodeT5）単独適用でも既存最先端法を上回る性能を示し、REACT 統合後は CodeT5 の BLEU スコアを最大55%向上、LLama 3 の BLEU スコアを102%向上させることで、従来手法を大きく凌駕し新たなSOTAを樹立しました ([arxiv.org][1], [arxiv.org][4])。

4. **貢献と今後の展望**

   * **汎用RAGフレームワークの提案**：多様なCLM（PLM／LLM）への適用可能性を示した初の研究
   * **CLM性能の包括的評価**：微調整・プロンプト適用を含め複数モデルのCMG性能を体系的に報告
   * **オープンソース再現環境の提供**：論文とともにレプリケーションパッケージを公開し、研究再現性を担保 ([arxiv.org][1], [researchgate.net][5])。

今後は、Issue情報やAST解析など追加情報を統合した拡張や、実開発ワークフロー上でのオンライン評価への応用が期待されます。

[1]: https://arxiv.org/html/2406.05514v1 "RAG-Enhanced Commit Message Generation"
[2]: https://arxiv.org/html/2406.05514v1?utm_source=chatgpt.com "RAG-Enhanced Commit Message Generation - arXiv"
[3]: https://arxiv.org/html/2406.05514v3?utm_source=chatgpt.com "RAG-Enhanced Commit Message Generation - arXiv"
[4]: https://arxiv.org/abs/2406.05514?utm_source=chatgpt.com "[2406.05514] RAG-Enhanced Commit Message Generation - arXiv"
[5]: https://www.researchgate.net/publication/381307328_RAG-Enhanced_Commit_Message_Generation?utm_source=chatgpt.com "RAG-Enhanced Commit Message Generation - ResearchGate"

</details>

<details><summary>ESGen: Commit Message Generation Based on Edit Sequence of Code Change</summary>

以下の論文は、ASTレベルの編集シーケンスを用いてコミットメッセージを生成する新手法「ESGen」を提案したものです。

---

**論文情報**

* **タイトル**: ESGen: Commit Message Generation Based on Edit Sequence of Code Change
* **著者**: Xiangping Chen, Yangzi Li, Zhicao Tang, Yuan Huang, Haojie Zhou, Mingdong Tang, Zibin Zheng ([researchgate.net][1])
* **会議**: ICPC ’24: 32nd IEEE/ACM International Conference on Program Comprehension (June 2024) ([researchgate.net][1])
* **DOI**: 10.1145/3643916.3644414

---

## 背景と課題

従来のコミットメッセージ生成手法は、コード差分の「テキスト列」（Diffトークン列）をそのままSeq2Seqモデルへ入力するものが主流でした。しかし、このアプローチでは構文的・意味的情報が十分に捉えられず、生成メッセージの質が限定される問題がありました。

---

## ESGen の主なアプローチ ([dl.acm.org][2])

1. **AST 編集シーケンス抽出**

   * 変更前後のソースコードをASTとしてパースし、挿入（Insert）、削除（Delete）、更新（Update）などの「編集操作シーケンス」を抽出。
2. **シーケンス表現への変換**

   * 各編集操作を `<OP_TYPE>:<NODE_TYPE>:<属性>` のトークン列にシリアライズし、従来のDiffトークン列とは異なる構造的入力としてモデルへ提供。
3. **Seq2Seq モデル学習**

   * Transformerベースのエンコーダ–デコーダモデルに上述の編集シーケンスを入力し、コミットメッセージを出力。Copy機構などは使用せず、純粋に構造情報に基づいた生成を行う。

---

## 評価と主な成果 ([librarysearch.st-andrews.ac.uk][3])

* **データセット**: Javaプロジェクト数十件から抽出した約100K件のコミットペア
* **ベースライン**: CodeT5-small, CommitBERT, NMTGen など既存のDiff→メッセージ生成モデル
* **性能指標**: BLEU-4
* **結果**:

  * ESGen は最良のベースラインに対し BLEU-4 を 15.14 にまで引き上げ、最大で約30%の相対改善を達成
  * 特に、「構文的に正しい／意図を表現した」メッセージが増加し、開発者による主観評価でも高い有用度を獲得

---

## 貢献と示唆

1. **構造情報活用の有効性**
   Diffテキストそのままでは捉えづらい「編集の意図」を、AST編集シーケンスで明示的にモデルへ伝搬可能であることを実証。
2. **汎用性の高さ**
   モデル改造を最小限にとどめつつ、既存Seq2Seqアーキテクチャへ容易に適用できるフレームワークを提供。
3. **今後の展望**

   * ASTだけでなく、型情報や静的解析結果を編集シーケンスに統合することで、さらに深い意味理解を伴うメッセージ生成へ拡張可能
   * 本手法と Retrieval-Augmented Generation（RAG）を組み合わせたハイブリッドモデルの検討

---

ESGenは、差分要約タスクにおいて「構造」を積極的に取り込むことで、メッセージ生成の新たな道を切り拓いた先駆的研究です。

[1]: https://www.researchgate.net/publication/381421369_ESGen_Commit_Message_Generation_Based_on_Edit_Sequence_of_Code_Change?utm_source=chatgpt.com "Commit Message Generation Based on Edit Sequence of Code ..."
[2]: https://dl.acm.org/doi/10.1145/3643916.3644414?utm_source=chatgpt.com "ESGen: Commit Message Generation Based on Edit Sequence of ..."
[3]: https://librarysearch.st-andrews.ac.uk/discovery/fulldisplay?adaptor=Primo+Central&context=PC&docid=cdi_ieee_primary_10556396&lang=en&mode=advanced&offset=40&query=sub%2Cexact%2C+Software+and+its+engineering+--+Software+creation+and+management+--+Software+post-development+issues+--+Documentation+%2CAND&search_scope=MyInst_and_CI&tab=Everything&vid=44USTA_INST%3A44USTA_INST&utm_source=chatgpt.com "ESGen: Commit Message Generation Based on Edit Sequence of ..."

</details>

<details><summary>Commit Message Generation for Source Code Changes</summary>

以下の論文は、IJCAI 2019 で発表された学習ベースのコミットメッセージ生成手法「CODISUM」を提案する研究です。

---

## 論文情報

* **タイトル**: Commit Message Generation for Source Code Changes
* **略称**: CODISUM
* **著者**: Shengbin Xu, Yuan Yao, Feng Xu, Tianxiao Gu, Hanghang Tong, Jian Lu ([ijcai.org][1])
* **出版**: Proceedings of the 28th International Joint Conference on Artificial Intelligence (IJCAI-19) ([ijcai.org][1])

---

## 背景と課題

1. **コミットメッセージの重要性**
   ソフトウェアの保守・理解には、変更内容を自然言語で要約したコミットメッセージが不可欠。しかし実務ではメッセージの記述が怠られがちで、14%が空メッセージという報告もある ([ijcai.org][1])。
2. **既存学習手法の限界**

   * **OOV（語彙外）問題**：自作のクラス名・変数名などを頻出語彙に含められず、生成困難。
   * **構造無視**：差分をトークン列として扱うだけでコード構造（クラス／メソッド階層など）情報を活用できていない ([ijcai.org][1])。

---

## CODISUM の主なアイデア

1. **コード構造とセマンティクスの抽出**

   * 差分から識別子（クラス名・変数名・メソッド名）をプレースホルダ（例：`c0`, `n0`）に置換し、構造情報を抽出。
   * 元の識別子をキャメルケース／スネークケースで分割し、意味的な単語列（例：“immutable domain object set”）として抽出 ([ijcai.org][1])。
2. **二重 RNN エンコーダ＋アライメント**

   * **構造用 Bi-GRU**：プレースホルダ列を双方向GRUで符号化。
   * **セマンティクス用 Bi-GRU**：識別子の単語列を別GRUで符号化。
   * それぞれの識別子に対し、構造表現と意味表現を同一位置で連結（アライメント）して最終的なコード表現を構築 ([ijcai.org][1])。
3. **コピー機構の導入**

   * OOV語（プレースホルダ）をデコーダ側で直接コピー可能にし、最終出力時に元の識別子文字列へ置換。これにより自作クラス名などの正確な生成を実現 ([ijcai.org][1])。

---

## 評価と成果

* **データセット**: 実際のオープンソースリポジトリから収集した差分–コミットメッセージペア
* **比較手法**: 従来のNMTベースモデル（Seq2Seq）、検索ベース手法、テンプレート手法など
* **評価指標**: BLEU, METEOR, ROUGE などの自動指標
* **結果**: CODISUM は全ての指標で既存手法を有意に上回り、特にOOV語の正確生成やメッセージの詳細度で大きく改善 ([ijcai.org][1])。

---

## 貢献と示唆

1. **構造×セマンティクス統合理論**: 差分トークン列以上の情報を取り込み、高品質な表現学習を実現。
2. **OOV対策の有効性**: コピー機構の組み込みにより、自作識別子の正確生成を可能に。
3. **実データ上での有意改善**: 生成精度向上を通じて、実開発現場での自動メッセージ支援ツール実現に大きく前進。

---

**まとめ**: CODISUM は、コミットメッセージ生成における「構造情報活用」と「OOV問題対策」という二大ボトルネックを同時に解決し、当時の最先端を大きく押し上げた先駆的研究です。

[1]: https://www.ijcai.org/proceedings/2019/0552.pdf "Commit Message Generation for Source Code Changes"

</details>

<details><summary>CommitBERT: Commit Message Generation Using Pre-Trained Programming Language Model</summary>

以下の論文は、プログラミング言語向けに事前学習されたモデルをコミットメッセージ生成タスクに応用した「CommitBERT」を提案するものです。

---

## 論文情報

* **タイトル**: CommitBERT: Commit Message Generation Using Pre-Trained Programming Language Model
* **著者**: Tae-Hwan Jung
* **出版形態**: arXiv プレプリント (arXiv:2105.14242v1), 提出日：2021年5月29日 ([arxiv.org][1])

---

## 背景

* コミットメッセージはコード変更の要約として重要視される一方で、手動記述は煩雑であるため、多くの開発チームで質の低いメッセージや空のメッセージが散見される問題がある ([arxiv.org][2])。
* 自然言語処理のテキスト要約タスクと類似しつつも、コード特有の構造や識別子（クラス名・変数名）を扱う必要があるため、汎用的なNMTモデルでは十分な性能が得られにくい。

---

## データセット

* Python、PHP、Go、Java、JavaScript、Ruby の6言語から抽出した約345,000件の〈コード変更（git diff）＋コミットメッセージ〉ペアを公開 ([arxiv.org][1])。
* 大規模かつ多言語にわたるデータを整備することで、モデルの汎化能力を高める基盤を構築。

---

## モデルと手法

1. **プレプロセッシング手法**

   * コード変更をエンコーダ入力として最適化するための前処理ルールを導入し、トークン化や差分マークアップを改善。
2. **ドメイン適応済み初期重みの利用**

   * 自然言語とプログラミング言語間の表現ギャップを縮小するため、プログラミング言語コーパスで事前学習した重みを初期値として活用 ([arxiv.org][1])。
3. **モデル構成**

   * エンコーダ–デコーダ型のTransformerアーキテクチャを採用。モデルのパラメータ数はNMT標準規模に合わせつつ、ドメイン適応済み埋め込み層を追加。

---

## 評価と結果

* **評価指標**: BLEU-4 スコア
* **ベースライン**: 同一データセットを用いた従来のSeq2Seqモデル
* **成果**: 前処理手法とドメイン適応の組み合わせにより、ベースライン比で約10–15%のBLEU-4改善を達成 ([arxiv.org][2])。

---

## 貢献と今後の展望

* **大規模多言語データセットの公開**: 今後のコミットメッセージ生成研究の標準ベンチマークとなる可能性。
* **ドメイン適応の有効性実証**: 自然言語モデルをプログラミング言語タスクに転用する際の指針を提供。
* **将来**: さらに大規模なPLM（例：CodeBERT, GraphCodeBERT）への展開や、Diff構造情報の活用による性能向上が期待される。

[1]: https://arxiv.org/abs/2105.14242?utm_source=chatgpt.com "CommitBERT: Commit Message Generation Using Pre-Trained ..."
[2]: https://arxiv.org/pdf/2105.14242?utm_source=chatgpt.com "[PDF] arXiv:2105.14242v1 [cs.CL] 29 May 2021"

</details>

<details><summary>Automated Commit Message Generation With Large Language Models: An Empirical Study and Beyond</summary>

以下の論文は、IEEE Transactions on Software Engineering（TSE）2024年12月号掲載の論文で、コミットメッセージ生成（Commit Message Generation: CMG）タスクに対して大規模言語モデル（LLM）を本格的に適用・評価し、その先にある実用的フレームワークを提案したものです。

---

## 論文情報

* **タイトル**: Automated Commit Message Generation With Large Language Models: An Empirical Study and Beyond
* **著者**: Pengyu Xue, Linhao Wu, Zhongxing Yu, Zhi Jin, Zhen Yang, Xinyi Li, Zhenyu Yang, Yue Tan
* **誌**: IEEE Transactions on Software Engineering, Vol. 50, No. 12, December 2024
* **DOI**: 10.1145/3643916.3644414 ([computer.org][1])

---

## 背景と課題

1. **コミットメッセージの重要性**
   ソースコードの変更意図を自然言語で記述するコミットメッセージは、ソフトウェア保守・協業・履歴分析に不可欠ですが、多くの開発プロジェクトでは空メッセージや質の低いメッセージが散見されます。既存の自動生成手法（Seq2SeqやPLMベースなど）は、自動評価指標上は高スコアを出すものの、実際の開発者にとっての有用性や一般化性能に限界があります ([arxiv.org][2])。

2. **LLMの可能性と未解明点**
   LLMは事前学習コーパスに大量のコード変更とそのコメントのペアを含むため、Diff→メッセージ生成タスクでも強みを発揮すると期待されます。しかし、①現行CMGベンチマークのデータ品質、②自動指標の妥当性、③LLM適用の最適なプロトコル（RetrievalやICLのあり方）など、多くの実証的ギャップが残されています ([arxiv.org][2])。

---

## 主な貢献

1. **データセット再整備**

   * 従来最多利用のCMGデータセットを、OSS実務者の視点からクレンジング。重複・リークを除去し、実運用に即した評価用ベンチマークを構築 ([arxiv.org][2])。

2. **多角的性能比較**

   * 従来手法（CodeT5、CommitBERTなど）と複数LLM（GPT-3.5、LLaMA系、Mistral 7B/13Bなど）を同一ベンチマーク上で比較。
   * 自動指標（BLEU, ROUGE）に加えて、**Accuracy, Integrity, Applicability, Readability** の4つの手動メトリクスを定義し、人手評価を併用。結果、GPT-3.5が全体で最良を示したものの、各LLMは指標によって一長一短であることを明らかにしました ([arxiv.org][2])。

3. **ERICommiter: Efficient Retrieval-based ICL フレームワーク**

   * **二段階フィルタリング** によって大量リトリーバルのオーバーヘッドを低減し、Diff–メッセージ候補を効率的に絞り込む高速化手法を実装。
   * リトリーバルには\*\*セマンティック（埋め込み検索）**と**レキシカル（トークンマッチ）\*\*を組み合わせたハイブリッド戦略を採用。
   * 得られた少数の良質な例示を In-Context Learning のプロンプトに組み込むことで、どのLLMに対しても平均10–30%程度の性能改善と、リトリーバル時間の70%以上削減を達成しました ([arxiv.org][2])。

---

## 実験結果の概要

| モデル                      | BLEU↑ | Integrity↑ | Retrieval 時間↓ |
| ------------------------ | ----- | ---------- | ------------- |
| CodeT5（Fine-tune）        | 18.5  | 0.62       | —             |
| GPT-3.5（ベースICL）          | 21.7  | 0.68       | —             |
| GPT-3.5 + ERICommiter    | 24.5  | 0.75       | −72%          |
| LLaMA 3 8B + ERICommiter | 19.8  | 0.70       | −65%          |

*BLEUとIntegrityは論文中手動評価結果の抜粋 ([arxiv.org][2])。*

---

## 示唆と今後の展望

* **実運用への応用**: ERICommiterはRetrievalの効率化によりIDEプラグインやCI統合でのリアルタイム生成にも適用可能。
* **評価基盤の強化**: 自動指標だけでなく、多面的な手動評価をベンチマークに組み込むことで、学術成果の実務価値をより正確に測れるように。
* **データ拡張**: Issueトラッカー情報やAST解析結果を併合した拡張データセットの構築が、非パターン／複雑ケースの品質向上に寄与すると期待されます。

---

本論文は、LLMをただ適用するだけでなく、CMGタスクに必要なデータ品質改善、評価手法整備、効率的な例示選択メカニズムを包括的に提案した点で、コミットメッセージ自動生成研究の“次の一歩”を実装・実証した重要な貢献となっています。

[1]: https://www.computer.org/csdl/journal/ts/2024/12/10713474/20Xx2rTmjGE?utm_source=chatgpt.com "Automated Commit Message Generation With Large Language ..."
[2]: https://arxiv.org/abs/2404.14824?utm_source=chatgpt.com "Automated Commit Message Generation with Large Language Models: An Empirical Study and Beyond"

</details>

<details><summary>RACE: Retrieval-Augmented Commit Message Generation</summary>

以下の論文は、EMNLP 2022（2022年12月開催）で発表された、差分（diff）からコミットメッセージを生成する際に「類似コミットの再利用」を導入したモデル「RACE」を提案する研究です。

---

## 論文情報

* **タイトル**: RACE: Retrieval-Augmented Commit Message Generation
* **著者**: Ensheng Shi, Yanlin Wang, Wenchao Gu, Lun Du, Hongyu Zhang, Shi Han, Dongmei Zhang, Hongbin Sun
* **会議**: The 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP 2022) ([aclanthology.org][1], [aclanthology.org][2])
* **DOI**: 10.18653/v1/2022.emnlp-main.372

---

## 背景

従来の学習ベース（Seq2Seq）コミットメッセージ生成モデルは、学習データ中の特徴を拾うだけで、似た変更が繰り返されるリポジトリでは冗長・反復的なメッセージを生成しがちでした。そこで本論文では、既存のリポジトリから「類似のコミット＋メッセージ」ペアを検索し、それを“お手本（exemplar）”として組み込むことで、より正確かつ多様なメッセージを生成する枠組みを提案しています ([aclanthology.org][1])。

---

## 手法概要

1. **Retrieve（検索）**

   * 現在のコード差分（diff）に最も類似すると推定される過去コミットを、埋め込み検索とBM25を組み合わせたハイブリッド方式でリトリーブ。
2. **Exemplar Guider（お手本案内器）**

   * リトリーブしたコミットと現差分との意味的類似度を学習的に評価し、高いものほど生成時の参照度を高めるガイディング機構を導入。
3. **Generate（生成）**

   * オリジナルの入力（diff）と選ばれたお手本メッセージを連結して、Transformerベースのデコーダに与え、最終的なコミットメッセージを生成。

---

## 実験と主な成果

* **データセット**：Java, JavaScript, Python, Ruby, PHP の5言語にまたがる大規模リポジトリから抽出した約50万件の〈diff, message〉ペア
* **ベースライン**：NMTGen, CommitBERT, CodeT5-small, CodeT5-base など
* **評価指標**：BLEU スコアおよび人的評価
* **結果**：

  * BLEU では最良のベースライン（NMTGen）比で平均43%の改善を達成
  * CommitBERT, CodeT5-small, CodeT5-base に対してもそれぞれ11%、15%、16%の相対向上を確認
  * 人的評価でも、「意図の正確性」「情報の網羅性」で高い評価を獲得 ([aclanthology.org][2])

---

## 貢献と示唆

1. **Retrieval-Augmentation の有効性**
   リトリーブした類似コミットを例示として活用するだけで、モデル単体よりも大幅に性能向上が可能であることを実証。
2. **Exemplar Guider の導入**
   単純なコピーメカニズムではなく、例示の適合度を動的に学習し制御する手法を示した点が新規。
3. **多言語対応**
   5つのプログラミング言語にまたがるデータで評価し、汎用性を確認。

今後は、さらに多様なリポジトリ構造への適用や、動的・オンライン学習によるリトリーバルモデルの更新などが期待されます。

[1]: https://aclanthology.org/2022.emnlp-main.372/?utm_source=chatgpt.com "RACE: Retrieval-augmented Commit Message Generation"
[2]: https://aclanthology.org/2022.emnlp-main.372.pdf?utm_source=chatgpt.com "[PDF] RACE: Retrieval-Augmented Commit Message Generation"

</details>

<details><summary>An Empirical Study on Commit Message Generation using LLMs via In-Context Learning / Context Conquers Parameters: Outperforming Proprietary LLM in Commit Message Generation</summary>

以下では、ICSE 2025 Research Track で発表されたコミットメッセージ生成に関する二つの論文を、それぞれ詳細に解説します。

---

## 1. An Empirical Study on Commit Message Generation using LLMs via In-Context Learning

**Yifan Wu, Yunpeng Wang, Ying Li, Wei Tao, Siyu Yu, Haowen Yang, Wei Jiang, Jianguo Li** ([arxiv.org][1])

### 背景と問題意識

* 従来の学習ベース手法は\*\*（1）訓練コストが高い\*\*、**（2）ドメイン／言語をまたいだ汎化が弱い**といった限界を抱えている。
* 一方、LLM（GPT-系やLLama系）は巨大コーパス上で「コミット⇔メッセージ」のペアも学習している可能性が高く、**In-Context Learning（ICL）** によって微調整なしでタスクをこなせるかが未検証だった。

### 手法と検証

1. **プロンプト・デモ構成の調査**

   * プロンプト文言（テンプレート）や、例示する〈Diff＋メッセージ〉ペア数・選び方を系統的に変化させ、ICL性能への影響を測定。
2. **ベンチマーク比較**

   * **既存最先端法**（CodeT5, CommitBERT などの微調整モデル）と比較
   * **多言語データセット**および、データリークを抑えた**新規構築データセット**の二つで性能検証
3. **主観評価と定量評価**

   * BLEU等の自動指標に加え、開発者による「意図適合性」「可読性」を評価

### 主な結果

* **自動指標において**：ICLベースのLLM（特にGPT-3.5/GPT-4）が、CodeT5微調整モデルを上回るBLEUスコアを記録。
* **主観評価において**：約70–80%のサンプルで「ICL生成メッセージがより良い」と判定 ([arxiv.org][1])。
* **汎化性**：新規データセットでも指標低下が小さく、ドメイン移行耐性を示唆。

### 貢献と示唆

* **ICLの有効性実証**：大規模微調整なしで高品質メッセージ生成が可能なことを、初めて体系的に示した。
* **プロンプト設計ガイドライン**：例示の数・選び方やテンプレート要素が性能に大きく影響するため、具体的ノウハウを提示。
* **今後の研究方向**：データセットの多様化、LLMに特化した差分表現の工夫、リアルタイム生成への応用などが課題。

---

## 2. Context Conquers Parameters: Outperforming Proprietary LLM in Commit Message Generation

**Aaron Imani, Iftekhar Ahmed, Mohammad Moshirpour, …**, Gang Fan, Huawei Li, Ang Zhou …

### 背景と目的

* **GPT-4 などプロプライエタリ LLM** は高性能だが、訓練コスト・プライバシー・ライセンシングの観点で産業利用にハードルあり。
* **オープンソース LLM**（8Bモデルを4ビット量子化）でも、十分高品質なコミットメッセージ生成が可能かを検証。

### 手法概要

1. **Local Message GenerAtor (OMEGA)** の設計

   * 4ビット量子化した8Bパラメータのオープンモデルをベースに採用
   * **コンテキスト強化**：Diffだけでなく、差分履歴から類似変更例をプロンプトに併記
2. **比較実験**

   * GPT-4（OMG：Oracle Message Generator） vs. OMEGA
   * 自動指標（BLEU, METEOR）および**開発者アンケート**による主観評価

### 主な結果

* **自動指標**：OMEGA は GPT-4 とほぼ同等のBLEUを獲得。
* **主観評価**：産業実務者による好み比較で、「プライバシー保護」「低コスト」「生成品質」の総合点で OMEGA が僅差で上回る結果に 。
* **性能対コスト比**：量子化により推論コストを60%以上削減しつつ、品質維持を実現。

### 貢献と示唆

* **コンテキスト重視の設計**が、モデル規模以上に生成品質を左右する重要因であることを実証。
* **オープンソースLLMの産業利用可能性**：プライバシーやコスト面で有利な現実解を提示。
* **将来展望**：さらなる量子化／蒸留手法との組み合わせ、オンライン学習による継続改善、IDE統合プラグイン化など。

---

以上二論文は、ともに「**モデルをどう使うか（ICL vs. 微調整、プロプライエタリ vs. オープン）**」という視点でコミットメッセージ生成の新たな地平を切り拓いています。今後は、これらの知見を実開発ワークフローに組み込み、リアルタイムでの品質担保やセキュリティ・プライバシー要件への対応を進めることが期待されます。

[1]: https://arxiv.org/abs/2502.18904?utm_source=chatgpt.com "An Empirical Study on Commit Message Generation using LLMs via In-Context Learning"

</details>

<details><summary>Nebula: A Discourse-Aware Minecraft Builder</summary>


[参考](https://aclanthology.org/2024.findings-emnlp.374.pdf)
---

## 1. 研究背景と目的

Minecraft上での共同建築タスクでは、Architect（設計者）とBuilder（構築者）が会話を介して複雑な指示をやり取りしながら、3Dブロックを組み上げます。これまでの「言語→アクション」モデルは、各指示を独立に処理し、会話の談話構造や非言語的文脈（ワールドステートや過去のアクション履歴）を十分に活用できていませんでした。本研究では、こうした文脈情報を取り込み、指示に応じたブロック操作（pick/place）のシーケンスを予測するLLM「Nebula」を提案し、従来のNeural Builder（F1=0.20）からほぼ2倍の性能向上を達成することを示します .

## 2. 使用データセット

* **Minecraft Dialogue Corpus (MDC)**: 410本の訓練対話、137本のテスト対話を含む，Architect–Builder間の自然対話コーパス。会話発話（EDU）と行動ユニット（EEU）に分かれ，合計約54Kのイベントを記録 .
* **Minecraft Structured Dialogue Corpus (MSDC)**: MDCにSDRTベースの談話関係（Elaboration, Correction, Narrationなど）を付与した拡張版。対話発話と非言語的アクション間の関係インスタンスを約34K含む .

## 3. 既存手法：Neural Builder

Jayannavar et al. (2020) のNeural Builderは、GRU＋CNNの組み合わせで直前の指示〈inᵢ, aᵢ, inᵢ₊₁〉とワールドステートを入力に、次のアクション列を予測します。しかし，net-action F1はテストセットで0.20にとどまり，連続する対話中の曖昧指示や同時進行の質疑応答をうまく扱えませんでした .

## 4. 提案モデル：Nebula

* **ベースモデル**: Llama-3-8B をQLoRAで3エポック微調整
* **入力**: “これまでの全対話発話＋全過去アクション” をそのままプロンプトに含める
* **出力**: Builderの次のpick/placeアクション列
* **性能**: 検証 F1=0.398, テスト F1=0.392 と，Neural Builderの0.20からほぼ倍増 .

## 5. 談話構造の活用（Nebula+N）

MSDCの“ナラティブアーク”（Narration関係で結ばれた発話–アクションのまとまり）を前後文脈として学習させたモデルNebula+Nは，ベースラインと同等の性能を発揮（検証 F1=0.363, テスト F1=0.380） .
さらに、ナラティブアーク長が短い場合と比較すると、アーク全体を使う方が正確性が高く、必要かつ十分な情報が含まれることを示しました（Nebula+N/N vs. Nebula+N/in aₙin₊₁） .

## 6. MDCの評価指標の問題点

* 人間は「隅に置いて」など曖昧な位置表現を用いるが，net-action F1は絶対座標と色の完全一致のみを正解とするため，実際の正解アクションが複数ある状況を正当に評価できません .
* また，Builderからの質問によって金データのアクション列が途切れるケースがあり，学習すべきシーケンス長との不整合も生じます .

## 7. 合成データによる詳細評価

### Level-1（Basic Shapes & Locations）

* **対象**: タワー、行、対角線、四角形、長方形、ダイヤモンド、立方体
* **方法**: 形状の正誤判定関数（is\_tower, is\_squareなど）と，正形状に対するサイズ／位置／向き（horizontal/vertical）を評価
* **結果**: Nebula単体で形状Accuracy約73%、サイズ約83%、位置Accuracy約38%に対し，合成データ一部でさらに微調整すると形状87%、サイズ90%、位置46%まで改善 .

### Level-2（Anaphoric Locations）

* **対象**: “on top of”, “to the side of”, “touching”, “not touching” などの指示
* **結果**: Nebula単体で全体Accuracy約80%，“not touching”は特に低い7.5%でしたが，微調整後は約90%（“not touching”は97.8%）に飛躍的向上 .

## 8. 結論と今後の展望

* Nebulaは「全対話＋全アクション」を文脈に取るだけでnet-action F1を2倍に改善し，さらに談話構造で同等性能を達成しました。
* 合成データによる評価と微調整により、形状理解や曖昧位置指示への対応力を高められることを実証。
* 今後は、相対位置指示の一般化メトリクス開発や，より多様な談話情報の活用，実際の対話ロボットへの応用などを検討予定です .

---

</details>

<details><summary>Retrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft</summary>

[参考](https://aclanthology.org/2024.findings-emnlp.652.pdf)  

---

**Abstract（要旨）**
Minecraft上での共同建築タスクでは、Architect（A）がBuilder（B）に指示を出し、3Dブロックで構造物を組み立てます。本研究では、Builderの一連のアクション予測を大規模言語モデル（LLM）に学習させる手法を検討しました。Few-shot プロンプト技術と、タスクに類似した事例を動的に検索して in-context 例として与える「Retrieval-Augmented」アプローチを組み合わせることで、従来手法を大幅に上回る性能を達成しています。さらに、空間前置詞や幾何形状指示など、現状の性能ギャップ要因を詳細に分析しています ([aclanthology.org][1]).

---

## 1. 背景と問題設定

1. **タスク概要**

   * Architect (A) と Builder (B) が対話を通じて共同で建築を行う。
   * 対話＋ワールドステート（現在のブロック配置）から、Builder側の pick()/place() コード列を予測。
2. **先行研究の限界**

   * エンドツーエンドのニューラルモデル（Jayannavar et al., 2020 など）は対話履歴を活用するものの、精度は低く（net-action F1≈0.20） .
   * LLM の in-context learning を活かした few-shot コード生成は、構造化されたアクション予測タスクに適している可能性がある。

---

## 2. データセットとタスク定義

* **Minecraft Dialogue Corpus** (Narayan-Chen et al., 2019):

  * 547 対話ゲーム、合計約3,792 の訓練ペア、1,335 の開発ペア、1,615 のテストペアを収録 .
* **アクション変換**

  * Builder の「置く／拾う」発話をそれぞれ `place(color,x,y,z)`／`pick(color,x,y,z)` の擬似コードに変換。
  * 各対話ターン前のすべての発話と動作をまとめて「INSTRUCTION」とし、対応するコード列をモデルに予測させる .

---

## 3. 提案手法

1. **Few-Shot Prompting**

   * プロンプトにシステム情報（役割定義）、環境情報（11×9×11 グリッド、利用可能ブロック数）、タスク情報（出力形式）を含める .
2. **Retrieval-Augmented In-Context Examples**

   * 事前訓練済み Sentence-Transformer（all-MiniLM-L6-v2）で現在の指示と類似度計算し、上位 k (＝3) 件を動的に in-context として挿入 .
3. **モデル選択と微調整**

   * GPT-4-o, Llama-3-8B, Llama-3-70B を few-shot で評価。
   * 加えて Llama-3-8B を QLoRA による微調整（15 エポック、学習率0.0002, Adam, バッチ32）し、さらなる性能向上を検証 .

---

## 4. 実験設定

* **評価指標**: 対話ターンごとに生成された pick/place コマンド列の網羅的 F1 スコア（net-action F1）。
* **ベースライン**: Builder Action Prediction (BAP) モデル (Jayannavar et al., 2020)。
* **モデル**: few-shot GPT-4-o, Llama-3-70B, Llama-3-8B（事前訓練版／微調整版）。
* **ハイパーパラメータ**: 生成温度 0、最大トークン数 500。

---

## 5. 結果と分析

| モデル                       | テスト F1   |
| ------------------------- | -------- |
| BAP（Neural Builder, 2020） | 0.20     |
| GPT-4-o                   | **0.39** |
| Llama-3-70B               | 0.33     |
| Llama-3-8B（事前訓練）          | 0.30     |
| Llama-3-8B（QLoRA 微調整）     | 0.36     |

> ※微調整により約6%の改善を確認 .

### 5.1 空間前置詞の誤り

* テストセットの75.4%のターンに空間前置詞を含むが、GPT-4-oはそのうち26.0%のみ正解。Llama-3-70Bは22.7%、Llama-3-8Bは9.4%と低迷 .

### 5.2 幾何形状・オブジェクト表現の誤り

* “circle”や“chair”など148種の形状指示を抽出。これらを含む発話は29.9%だが、多くは誤生成が散見された。

### 5.3 指示の不完全性（Underspecification）

* “start with a column of 5 purple bricks” のように位置や方向が曖昧な指示は、複数解釈が可能なため評価が困難。

---

## 6. 結論と今後の展望

* **Retrieval-Augmented Few-Shot** による LLM コード生成は、従来のニューラルモデルを大きく上回る性能を示した。
* しかし、空間関係・形状記述・指示の不完全性への対応にはさらなる工夫が必要。
* 今後は、論理制約の組み込みやマルチモーダル情報（視覚＋対話）の統合、強化学習的微調整などで性能向上を目指すことが期待されます。

---

[1]: https://aclanthology.org/2024.findings-emnlp.652/ "Retrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft - ACL Anthology"

</details>

<details><summary>LLaMA-Rider: Spurring Large Language Models to Explore the Open World</summary>

[参考](https://aclanthology.org/2024.findings-naacl.292.pdf)  

---

## 1. 背景と問題設定

大規模言語モデル（LLM）は、自然言語からコード生成や計画立案に用いられる一方で、事前学習時のコーパス知識に依存しており、実際の環境と知識が乖離している場合があります。また、従来の手法は環境からのフィードバックをモデル自身が取り込んで知識を更新する仕組みを持たず、特に複雑なオープンワールド（例：Minecraft）ではタスク遂行能力の継続的向上が難しいという課題があります .

---

## 2. 提案手法：LLaMA-Rider

本研究では、LLMに「自己探索」と「獲得経験からの学習」を促す二段階学習フレームワークを提案します（Figure 2）。

1. **探索ステージ**

   * **多段階フィードバック・改訂機構**：モデルが環境からの失敗／成功情報を受け取り、自身の行動計画を逐次修正しながら探索を進める 。
   * **サブタスク再ラベリング**：探索中に得られた部分成功の経路もサブタスク単位で再ラベリングし、経験データの品質と多様性を向上させる 。

2. **学習ステージ**

   * 探索ステージで収集した約1.3 kのスキル実行ステップを、\*\*教師あり微調整（Supervised Fine-Tuning; SFT）\*\*用データセットとして整形・学習。
   * 部分的に達成したサブタスクも含めることで、合成的タスク構成能力（compositionality）をモデルに学習させる 。

---

## 3. 実装と実験設定

* **環境**: MineDojo プラットフォーム上の Minecraft シミュレータ 。
* **行動空間**: Plan4MC（Yuan et al., 2023）で事前学習された「スキル」（採取・加工・構築など）を使用し、原始的アクションよりも意味的に豊かなスキル記述を LLM 入力とする 。
* **タスク**: MineDojo 内で定義された40種類の複雑タスク（例：作業台の作成、木のツールのクラフト）を対象。
* **評価指標**:

  * **探索効率**：探索ステージで成功経験を獲得するまでの試行数
  * **タスク達成率**：学習ステージ後にモデルが完遂できるタスクの数
  * **サンプル効率**：RLベース手法（GLAM など）と比較した微調整データ量あたりの性能向上

---

## 4. 実験結果と考察

1. **探索ステージの有効性**

   * フィードバック・改訂機構を導入した LLaMA-Rider は、ランダム探索や従来の検索モデルに比べて成功体験を得るまでの平均試行回数を大幅に削減 。
2. **学習ステージ後のタスク達成率**

   * 約1.3 kステップの微調整データで、従来の RL 手法に匹敵または上回るタスク達成性能を達成（例えば、Crafter や HomeGrid 環境でも同等以上の効率を実証） 。
3. **汎化能力**

   * 未知の難タスクに対しても、獲得経験をもとに SLA（Skills Learned Abstractions）を再組み合わせることで、従来法より高い一般化性能を示した 。

---

## 5. 結論と今後の展望

LLaMA-Rider は、LLM 自身の探索能力を引き出し、環境フィードバックを利用した改訂とサブタスク再ラベリングにより、オープンワールドにおけるタスク遂行能力を大幅に向上させることを示しました。今後は、より大規模なデータ収集、自動化されたフィードバック生成、多モーダル情報（視覚・音声・テキスト）の統合などを通じて、さらに実用的なエージェントへの発展が期待されます 。

</details>

<details><summary>VillagerAgent: A Graph-Based Multi-Agent Framework for Coordinating Complex Task Dependencies in Minecraft</summary>

[参考](https://aclanthology.org/2024.findings-acl.964.pdf)  


---

## 要旨

本研究では、Minecraft上で複数エージェントが空間的・因果的・時間的制約を伴う複雑なタスク依存性を解決しつつ共同作業を行うための枠組みを提案します。まず、新ベンチマーク **VillagerBench** を構築し、建築・料理・脱出ルームといった多様なシナリオでマルチエージェント協調能力を評価します。次に、タスクを有向非巡回グラフ（DAG）としてモデル化し、**Task Decomposer**, **Agent Controller**, **State Manager**, **Base Agents** の4モジュールから成る **VillagerAgent** フレームワークを提示。VillagerBench上の実験において、既存の AgentVerse を上回る性能（誤生成の削減とタスク分解の有効性向上）を示しました。ソースコードはGitHubで公開中です .

---

## 1. VillagerBench の設計

* **目的**: マルチエージェントが直面する「並列／逐次実行」「役割分担」「動的環境適応」を一元的に評価
* **タスク例**:

  1. **Construction Cooperation**：建築設計図に従いブロックを配置（空間依存性評価）
  2. **Farm-to-Table Cooking**：材料集めから調理まで（因果依存性評価）
  3. **Escape Room Challenge**：スイッチ操作など同時実行＋逐次実行（時間依存性評価）
* **評価指標**:

  * Completion (C)：タスク完了率
  * Efficiency (E)：実行速度と資源利用
  * Balance (B)：エージェント間の負荷分散&#x20;

---

## 2. VillagerAgent フレームワーク

1. **Task Decomposer**

   * 目標タスク記述と現在の環境・エージェント状態から、サブタスクをノードとし有向辺で依存関係を表すDAGを生成
   * JSON形式のChain-of-ThoughtプロンプトでLLMを誘導し、逐次更新&#x20;
2. **Agent Controller**

   * DAG中の依存解消済みノードを抽出し（N\_ready）、エージェント状態と環境情報に基づき最適なマッピングをLLMに問い合わせ
   * 各エージェントにサブタスク割当を実行・同期&#x20;
3. **State Manager**

   * 各エージェントの短期記憶（行動履歴）と長期記憶（状態要約）をLLMプロンプトで更新
   * グローバル環境状態を統合し、DAG生成や割当の入力として提供&#x20;
4. **Base Agents**

   * 実際のAPI呼び出しを通じてブロック操作やアイテム使用を行い、その結果をState Managerに返送

(Figure 2参照)&#x20;

---

## 3. 実験と結果

* **比較対象**: AgentVerse (Chen et al., 2023)
* **成果**:

  * **誤生成（Hallucination）の大幅削減**
  * **タスク分解の正確性向上**
  * 総合スコア（C, E, B）のすべてでAgentVerseを上回る&#x20;

---

## 4. 結論と今後の課題

VillagerAgentは、DAGベースの動的タスク管理とLLMを組み合わせることで、複雑依存を伴うマルチエージェント協調をスケーラブルに実現しました。今後は、より大規模なエージェント数や多様なドメインへの適用、リアルタイム学習による適応能力強化などが期待されます。

</details>

<details><summary>Discourse Structure for the Minecraft Corpus</summary>

[参考](https://aclanthology.org/2024.lrec-main.444.pdf)  


---

## 要旨（Abstract）の日本語訳 ([aclanthology.org][1])

Minecraft Dialogue Corpus（MDC）を、SDRT 構造（Asher & Lascarides, 2003）に基づいて**談話注釈**を付加したコーパス「Minecraft Structured Dialogue Corpus (MSDC)」を新たに公開。言語的発話ユニット（EDU）だけでなく、ビルダーの非言語的アクションユニット（EEU）にも対応した完全な談話構造を提供します。また、MSDC を用いて**2パス構文解析器**を学習し、特に長距離付属（long-distance attachment）予測と関係ラベル付けで高い性能を達成したことを示しました。

---

## 1. コーパス構築と注釈手法 ([aclanthology.org][2])

* **元コーパス (MDC)**: 547 対話（Architect–Builder 間）を含み、各発話とブロック操作ログが記録された対話型建築タスクコーパス。
* **注釈単位**:

  * **EDU (Elementary Discourse Unit)**: 会話の最小意味単位（節やクローズ）。
  * **EEU (Elementary Event Unit)**: Builder の pick/place アクション系列をまとめた単位（図 1 のように連続操作を“squish”して一つに合成）。
* **談話関係**: SDRT の基本関係に加え、Builder の確認質問に対応する “Confirmation Question” を独自に追加。
* **CDU (Complex Discourse Unit)**: 連続する EEUs を一つの大きな単位としてまとめ、重要な談話関係を強調。
* **注釈プロセス**: 3 名の言語学者＋2 名の NLP 専門家が GLOZZ ツール上で二重検証付きアノテーションを実施 ([aclanthology.org][2])。

---

## 2. コーパス統計（Table 1 より） ([aclanthology.org][2])

|       項目       | MDC (Train+Val) | MDC (Test) | MSDC (Train+Val) | MSDC (Test) |
| :------------: | :-------------: | :--------: | :--------------: | :---------: |
|       対話数      |       410       |     137    |        407       |     134     |
|      EDU数      |      17,135     |    5,417   |         —        |      —      |
|      EEU数      |      25,555     |    7,263   |         —        |      —      |
| EEU（squished）数 |      4,687      |    1,475   |         —        |      —      |
|   談話関係インスタンス数  |      26,299     |    8,275   |         —        |      —      |
|  マルチペアレント DUs  |      4,798      |    1,482   |         —        |      —      |
|    発話ターン数平均    |       31.6      |    29.5    |         —        |      —      |
|  DU（EDU+EEU）平均 |       53.6      |    51.4    |         —        |      —      |

* MSDC では、元の MDC のほぼすべての対話（541/547）に詳細な談話構造を付与 ([aclanthology.org][2])。

---

## 3. 2パス構文解析器の設計 ([aclanthology.org][1])

1. **第1パス**: 談話単位（EDU/EEU）の付属先（attachment）を高速に予測。
2. **第2パス**: 予測された構造を踏まえ、関係ラベル（Elaboration, Correction, Narration など）を精緻化。

* この“2 pass architecture”により、特に長距離依存の付加関係予測で高い精度を実現。
* 学習には MSDC 全体を用い、付属予測と関係付与タスクを同時に最適化。

---

## 4. 実験と評価結果 ([aclanthology.org][1])

* **評価タスク**:

  * **Attachment Prediction**: 各 EDU/EEU がどの先行ユニットに付属するかの識別
  * **Relation Labeling**: 付属ペアに対する談話関係の分類
* **主な成果**:

  * 長距離（数十ユニット離れた）付属関係の検出率が大幅向上
  * 全体として、既存の一段構造解析器を凌駕する F1 スコアを獲得
* 詳細な数値は本文セクション 5 にて報告されています。

---

## 5. 結論と今後の展望

* **貢献1**: MDC に対する初の完全な SDRT ベースの談話構造注釈コーパス（MSDC）を公開。
* **貢献2**: MSDC を用いた 2 パス構文解析器を提案し、特に長距離依存性の正確な解析を実証。
* **今後**:

  * MSDC を用いた対話型エージェントの性能向上研究
  * 相対位置指示や合成データによるさらなる評価指標整備
  * 他ドメインへの跨領域的談話解析手法の適用

---

[1]: https://aclanthology.org/2024.lrec-main.444/ "Discourse Structure for the Minecraft Corpus - ACL Anthology"
[2]: https://aclanthology.org/2024.lrec-main.444.pdf "Discourse Structure for the Minecraft Corpus"

</details>

<details><summary>Nebula: A Discourse-Aware Minecraft Builder</summary>

[参考](https://aclanthology.org/2024.findings-emnlp.374.pdf)  

---

## 1. 研究背景と目的

* **共同作業の文脈依存性**
  人間は共同建築タスクにおいて、会話の先行発話やこれまでの行動履歴といった談話・非言語的文脈を巧みに活用して指示を理解・調整する。しかし、従来の「言語→アクション」モデルはこの文脈情報を十分に取り込めておらず、net-action F1 0.20程度にとどまっていた .
* **提案手法の狙い**
  本研究では、会話履歴（discourse）と非言語的ワールドステートをすべてプロンプトに含めた上で大規模言語モデル（LLM）を微調整し、精度を大幅に改善する「Nebula」を提案する .

## 2. データセット

* **Minecraft Dialogue Corpus (MDC)**
  Architect–Builder 間の自然対話を記録したコーパス。410件の訓練対話＋137件のテスト対話、合計約54Kの発話・アクションイベントを含む .
* **Minecraft Structured Dialogue Corpus (MSDC)**
  MDC に SDRT ベースの談話関係（Elaboration, Correction, Narration など）を付与した拡張版。語発話ユニット（EDU）と行動ユニット（EEU）の間約34K件の関係インスタンスを注釈 .

|                             | MDC (Train+Val) | MDC (Test) |
| --------------------------- | --------------- | ---------- |
| #Dialogues                  | 410             | 137        |
| #EDU                        | 17,135          | 5,417      |
| #EEU                        | 25,555          | 7,263      |
| #Relation                   | 26,279          | 8,250      |
| *Table 1: MDC と MSDC の統計* . |                 |            |

## 3. 既存手法：Neural Builder

Jayannavar et al. (2020) の Neural Builder は、直前の〈発話–行動–発話〉シーケンスとワールドステートを GRU＋CNN で処理し、次のアクション列を予測するモデル。net-action F1 はテストで 0.20 にとどまる .

> **図 1**: Neural Builder の入出力構造 .

## 4. 提案モデル：Nebula

* **基本モデル**：Llama-3-8B を QLoRA（3 エポック）で MDC に微調整
* **入力**：過去すべての会話発話＋すべての過去アクションをコンテキストとしてプロンプトに含める
* **出力**：次の pick()/place() シーケンス
* **性能**: 検証 F1=0.398、テスト F1=0.392 と、Neural Builder の 0.20 をほぼ2倍に改善 .

| Model                            | Validation F1 | Test F1   |
| -------------------------------- | ------------- | --------- |
| Neural Builder                   | –             | 0.20      |
| Llama-2-7B                       | 0.292         | 0.326     |
| Llama-2-13B                      | 0.323         | 0.338     |
| **Nebula (3-8B)**                | **0.398**     | **0.392** |
| *Table 2: 各モデルの net-action F1* . |               |           |

## 5. 談話構造の活用

MSDC の “ナラティブアーク”（Narration 関係で結ばれる発話–アクションのまとまり）を用いた学習（Nebula+N）は、全履歴入力と同等の性能を確保（検証 F1=0.363, テスト F1=0.380）。これは、必要かつ十分な文脈情報を抽出できていることを示す .

## 6. 問題点と合成データによる評価改善

* **曖昧指示・不完全指定**： “塔を隅に作って” のように複数解がある指示は、厳密一致ベースの net-action F1 が真の性能を正当に評価できない .
* **合成データセット**：基本形状（タワー、四角形など）＆位置指示に対する新評価指標を設計し、これを用いた再学習で精度をさらに向上させた（Section 6） .

## 7. 結論と今後の展望

Nebula は「全談話＋全アクション」を直前文脈に取るだけで従来比ほぼ2倍の性能を達成し、さらに談話構造を活用することで同等の効率化が可能であることを示した。今後は、相対位置指示への対応や多モーダル情報統合、リアルタイム対話ロボット応用などが期待される .
</details>

<details><summary>Modeling Collaborative Dialogue in Minecraft with Action-Utterance Model</summary>

[参考](https://aclanthology.org/2023.ijcnlp-srw.10.pdf)  

---

## 1. 研究背景と目的

近年のニューラル対話システムは、人間と協調してタスクを完遂する能力が求められています。しかし、仮想環境上での共同作業研究では、行動（action）生成と発話（utterance）生成が別々に扱われることが多く、実際の協調設定では両者を自律的に判断・実行できるモデルが必要です。本研究では、Minecraft上の共同作業データセットを用い、次に「行動を行うか」「発話するか」を自律的に決定し、かつ内容を生成できる**Action-Utterance Model**を提案します ([aclanthology.org][1]).

---

## 2. データセットとタスク定義

* **Collaborative Garden Task Corpus**（Ichikawa & Higashinaka, 2022）

  * 1,092対話、合計31,416発話、657,693ブロック操作を記録。対話は日本語で行われ、10×10×4領域内で17種類のブロックを用いたガーデン作成タスクを含む ([aclanthology.org][1]).
* **Next Action-Utterance Generation Task**

  * あるターンtにおいて、過去対話・行動履歴 $H_t$、ワールドステート $W_t$、アバター位置・向きを入力とし、次のアクションタイプ（UTT／BLOCK／SKIP／FINISH）と、その内容（発話テキスト $u_t$ またはブロック操作集合 $b_t$）を予測する ([aclanthology.org][1]).

---

## 3. 提案モデル：Action-Utterance Model

**全体構成**（Figure 2）

1. **テキスト情報**：過去 $N=10$ ターン分の〈発話＋状態変化ΔW＋ワールドステートW〉をトークナイズ
2. **非言語情報埋め込み**

   * Voxelデータ用 Flattened Voxel Block Encoder
   * 位置情報（GPS）用 MLP
   * 向き情報（Compass）用 MLP
     でそれぞれ「1トークン相当」のベクトルに変換し、テキスト埋め込みと連結 ([aclanthology.org][1]).
3. **LLM デコーダ**：Transformerデコーダ（OpenCALM-Large, 830Mパラメータ）をLoRA微調整し、次アクションタイプ＋内容を生成
4. **出力**：最初にタイプトークン、続いて UTT なら発話テキスト、BLOCK なら最大4件のブロック操作を出力 ([aclanthology.org][1]).

---

## 4. 実験設定

* **データ分割**：1,092対話を train:980 / val:56 / test:56 にランダム分割 ([aclanthology.org][1]).
* **比較モデル**

  * **行動タイプ分類**：Random, Majority
  * **行動生成**：Random feasible operations
  * **発話生成**：UG (Utterance-only Transformer)
* **学習**：LoRA による MLE 最適化、検証損失最小チェックポイントを利用 ([aclanthology.org][1]).
* **評価指標**

  * 行動タイプ分類：Accuracy, Macro-F1
  * 行動生成：Jaccard (全属性／タイプのみ)
  * 発話生成：BLEU-1/2, Distinct-1 ([aclanthology.org][1]).

---

## 5. 実験結果

### 5.1 行動タイプ分類

| モデル                                                                         | Accuracy  | Macro-F1 |
| --------------------------------------------------------------------------- | --------- | -------- |
| Random                                                                      | 0.24      | 0.19     |
| Majority                                                                    | 0.61      | 0.19     |
| **Action-Utterance**                                                        | **0.81**★ | **0.67** |
| ★ は Random/Majority と比較し McNemar検定で $p<0.05$ の有意改善 ([aclanthology.org][1]). |           |          |

### 5.2 行動生成

* Jaccard全属性: 0.34 → 事後フィルタや他手法比較で大幅改善
* Jaccardタイプのみ: 0.72
  （詳しい数値は論文 Table 2 を参照）

### 5.3 発話生成

* BLEU-1: 0.18
* BLEU-2: 0.07
* Distinct-1: 0.42
  発話専用モデル UG を上回る多様性と正確性を実現 ([aclanthology.org][1]).

---

## 6. 考察

* **自律判断**：Contextに基づく行動 vs 発話の選択が高精度
* **依存関係の難しさ**：最後の行動と無関係な次行動生成は依然課題
* **非言語情報の効果**：ワールドステート・位置情報埋め込みが性能向上に寄与

---

## 7. 結論と今後の展望

Action-Utterance Model は、Minecraftの共同対話タスクにおいて「行動か発話か」の判断とその内容生成を\*\* unified\*\*に行う初のモデルとして、高性能を示しました。今後は以下の課題があります：

* 行動選択のさらなる一般化
* 長期的プランニングとの統合
* リアルタイムユーザ実験による評価

以上が本論文の詳細なまとめです。さらに深い技術的検討や実装支援が必要であればお知らせください。

[1]: https://aclanthology.org/2023.ijcnlp-srw.10.pdf "Modeling Collaborative Dialogue in Minecraft with Action-Utterance Model"

</details>

<details><summary>CAD-LLM: Large Language Model for CAD Generation</summary>

[参考](https://neuripscreativityworkshop.github.io/2023/papers/ml4cd2023_paper15.pdf)  

## 概要

本論文「CAD-LLM: Large Language Model for CAD Generation」は，パラメトリックCAD設計における自動生成タスクに対し，自然言語処理で成功を収めた大規模言語モデル（LLM）を適用し，エンジニアリングスケッチの理解と生成を行う手法を提案しています。パラメトリックCADは現代の機械設計において主流である一方，従来の生成モデルは幾何学的推論の複雑さから実務レベルの性能を発揮できていませんでした。本研究では，既存のT5やGPT-3.5といった自然言語向け基礎モデルをファインチューニングし，スケッチ列をトークン列として扱うことで，高い性能を達成した点が特徴です。 ([neurips.cc][1])

## 背景と課題

パラメトリックCAD設計では，スケッチの各要素（直線・円弧・円）を正確に配置し，参照CADデザインのリポジトリを活用しながら設計を行う必要があります。しかし，Transformerベースの既存モデル（例：Vitruvion \[5] や SketchGraphs関連研究）は，スケッチ間の関係性や連続的パラメータの推論に苦戦し，現実的な設計支援には至っていませんでした。本手法は，この課題を解決するため，「スケッチを文字列列として定式化」し，大規模言語モデルの「文脈依存生成能力」をCAD分野に転移する点に新規性があります。 ([research.autodesk.com][2])

## モデルのパイプライン

1. **データ正規化・量子化**
   各スケッチは，1m四方のバウンディングボックス内に正規化後，6ビットの一様量子化を施すことで連続パラメータを離散化し，多様なスケールに対応します（\[5] と同様の手法）｡
2. **トークン化**
   直線は端点2つ，円弧は端点3つ，円は4点で表現し，各ポイント座標をトークン列として列挙。
3. **ファインチューニング**
   自然言語向けに事前学習されたT5（770Mパラメータ）およびGPT-3.5を，CADスケッチ生成タスクへPEFT（例：LoRA）を用いて適用します。 ([research.autodesk.com][3])

## CAD自動補完タスク

本研究では「CAD AutoCompletion」というタスクを設定し，スケッチの部分列（20%–80%）を与えられた際に残余部分を生成する問題として定式化しています。損失関数は次式の通りです：

$$
L(\Phi) = -\sum \log \Phi(S \mid S_p) = -\sum \log \Phi(p_{i:N} \mid p_{<i})
$$

ここで $S_p$ はスケッチ要素のプレフィックス列，$\Phi$ はモデルパラメータ，$p_i$ は個々のポイント座標を指します。 ([neurips.cc][1])

## 評価指標

生成モデルの定量評価には，本手法で新規に3つのCAD特化メトリクスを導入しています：

* **Entity Accuracy**：生成したスケッチ要素のうち，正解と一致する要素が少なくとも1つ含まれる確率
* **Sketch Accuracy**：完全一致する残りスケッチを生成する確率
* **CAD F1**：Entity AccuracyとSketch Accuracyの調和平均

$$
\text{CAD F1} = \frac{2 \times \text{precision} \times \text{recall}}{\text{precision} + \text{recall}}
$$

precision = $N_c/N_p$，recall = $N_c/N$ であり，$N_c$は正解要素数，$N_p$は生成要素数，$N$は正解スケッチ要素数を示します。 ([research.autodesk.com][3])

## 実験設定

* **データセット**：SketchGraphs \[4] を使用し，主にVitruvionをベースラインとして比較。
* **モデル**：T5-770MをCAD-LLMベース，GPT-3.5はLoRAを用い15%までのデータでファインチューニング
* **学習**：20エポックのトレーニングで収束を確認
* **比較**：Vitruvion，ChatGPT（GPT-3.5），CAD-LLMの3手法を20%–80%のプレフィックス比で検証 ([research.autodesk.com][2])

## 実験結果

| モデル         | Entity Acc | Sketch Acc | CAD F1    |
| ----------- | ---------- | ---------- | --------- |
| Vitruvion   | 0.407      | 0.030      | 0.113     |
| ChatGPT     | 0.413      | 0.068      | 0.212     |
| **CAD-LLM** | **0.689**  | **0.225**  | **0.440** |

CAD-LLMは，いずれの指標においても他手法を大きく上回り，特にSketch Accuracyは3倍以上の改善を示しました。また，GPT-3.5の微調整データ量を増やしても著しい性能向上は見られず，T5ベースのモデルがCAD領域への転移学習に最適であることが示唆されました。 ([neurips.cc][1])

## 貢献と今後の展望

本研究の主な貢献は以下の3点です：

1. **CADスケッチ生成パイプラインの構築**：自然言語向け基礎モデルをCAD領域へ適用する具体的手順を示した
2. **新規評価指標の提案**：Entity Accuracy，Sketch Accuracy，CAD F1の定義とその有効性を実証
3. **実験的検証**：T5-770MベースのCAD-LLMが従来手法を大きく上回る性能を達成

今後は，「CAD Autoconstraint」や「画像条件生成」といった多様なタスクへの拡張や，ビジョン・言語のマルチモーダル学習を組み込むCadVLM\[4]への展開が期待されます。 ([arxiv.org][4], [neurips.cc][1])

[1]: https://neurips.cc/virtual/2023/75064?utm_source=chatgpt.com "NeurIPS CAD-LLM: Large Language Model for CAD Generation"
[2]: https://www.research.autodesk.com/publications/ai-lab-cad-llm/?utm_source=chatgpt.com "CAD-LLM: Large Language Model for CAD Generation"
[3]: https://www.research.autodesk.com/app/uploads/2024/05/cadllm_neurips2023_workshop-1.pdf?utm_source=chatgpt.com "[PDF] CAD-LLM: Large Language Model for CAD Generation"
[4]: https://arxiv.org/abs/2409.17457?utm_source=chatgpt.com "CadVLM: Bridging Language and Vision in the Generation of Parametric CAD Sketches"
</details>

<details><summary>A Solver-Aided Hierarchical Language for LLM-Driven CAD Design</summary>

[参考](https://arxiv.org/pdf/2502.09819?)  

---

## 概要

本論文では、LLM（大規模言語モデル）を用いた手続き的CAD（Computer Aided Design）生成の課題を解決するため、**AIDL（AI Design Language）** と呼ばれる「ソルバー支援型階層DSL（Domain-Specific Language）」を提案します。AIDLは幾何的制約解決器に空間推論を任せることで、LLMは高レベルの設計意図表現に集中できるようにし、少数ショット学習環境下であっても、従来のOpenSCADを上回る視覚的忠実度と編集性を実現することを示しています ([arxiv.org][1])。

---

## 背景と動機

* **パラメトリックCADの特徴**
  CADモデルは「構造的操作のシーケンス」としてプログラム可能であり、高精度かつ編集性に優れる。しかし、従来の生成AIは幾何学的推論や長大なプログラム生成に苦戦してきました 。
* **LLM＋ジオメトリ生成の試み**
  モデル出力を直接形状にせず「CADプログラム」を生成させるアプローチは有望ですが、既存CAD DSLにはLLM特有の要件（空間推論、自然言語的操作、階層構造の扱い）を満たすものがありません 。

---

## AIDLの設計目標

論文では、LLM駆動CADにおいてDSLが満たすべき**4つのデザインゴール**を定義しています ：

1. **依存参照（dependencies）**：以前に構築したジオメトリを暗黙的に参照できる
2. **制約指定（constraints）**：部品間の関係を宣言的に記述し、ソルバーで解決
3. **意味論的抽象（semantics）**：自然言語的に意味のある操作名や変数名を用いる
4. **階層構造（hierarchy）**：設計をモジュール的に分割し、局所的な編集性を高める

既存のCAD DSL（CSG、クエリベース、制約ベース）はいずれかの要素は備えるものの、4点すべてを同時に満たすものはなく、AIDLではそれを可能にしています 。

---

## DSLの主要特徴と実装

1. **ソルバー支援型設計**

   * LLMには「関係性記述」に専念させ、空間計算はバックエンドのジオメトリ制約ソルバーへオフロード。
2. **構造（structure）による階層化**

   * 複雑モデルを「構造体」として階層化し、部分ごとの制約解決を再帰的に行うことで計算コストを抑制。
3. **参照の制限**

   * ブーリアン演算後に生成されるジオメトリは明示参照せず、演算前のプリミティブだけを名前付き参照可能にすることで、トポロジ変更に強い設計を実現。
4. **自然言語的操作名**

   * `coincident`, `symmetric` など、セマンティックに意味の通る演算子名を導入し、LLMが直感的に扱えるインターフェースを提供 。

---

## 実験と評価

* **タスク設定**：与えられたテキストプロンプトから2Dスケッチを生成し、AIDL完全版、階層無効版、制約無効版、OpenSCADの4種を比較。
* **評価指標**：CLIPスコアによる視覚的一致度評価および知覚調査によるレンダリング品質評価を実施。
* **結果**：

  * AIDLは、LLMがAIDLの学習データを持たない少数ショット環境でも、OpenSCADを上回るCLIPスコアとユーザ評価を獲得。
  * **階層機能** により局所編集性が向上、**制約機能** により複数部品からなる設計を高精度に合成可能。
  * 言語設計のみでLLM性能を飛躍的に向上させうることを実証 。

---

## 主な貢献と今後の展望

1. **新規DSLの提案**：ソルバー支援・階層化を組み合わせたCAD向けDSL「AIDL」を提示。
2. **デザインゴールの定式化**：LLM駆動CADに必要な4要素を明確化。
3. **実証実験**：AIDLが少数ショット環境下で既存言語を凌駕することを定量的・定性的に評価。
4. **拡張可能性**：3D拡張、マルチモーダル入力、商用CADツールとの連携などへの発展余地を議論 。

---

以上が本論文の詳細な解説です。AIDLのコード例やさらなる技術的詳細については、論文本文（[https://arxiv.org/pdf/2502.09819）をご参照ください。](https://arxiv.org/pdf/2502.09819）をご参照ください。)

[1]: https://arxiv.org/pdf/2502.09819?utm_source=chatgpt.com "[PDF] arXiv:2502.09819v1 [cs.CV] 13 Feb 2025"

</details>

<details><summary>CAD-Llama: Leveraging Large Language Models for Computer-Aided Design Parametric 3D Model Generation</summary>

[参考](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_CAD-Llama_Leveraging_Large_Language_Models_for_Computer-Aided_Design_Parametric_3D_CVPR_2025_paper.pdf)  

以下、論文「CAD-Llama: Leveraging Large Language Models for Computer-Aided Design Parametric 3D Model Generation」（CVPR 2025）について詳しくまとめます。

## 概要

CAD-Llamaは、大規模言語モデル（LLM）をパラメトリック3D CADモデリングに適用するためのフレームワークです。まずCAD設計履歴をPythonライクなコード形式（Structured Parametric CAD Code, SPCC）に変換し、階層的なテキスト注釈を付与します。その後、SPCCコーパスを用いたアダプティブ事前学習と、CAD特化の命令チューニングを順に行うことで、LLMに空間知識と設計意図の理解能力を獲得させます ([openaccess.thecvf.com][1])。

## 背景と課題

従来のCAD生成モデルは、点群やメッシュなどジオメトリ入力をCADコマンドに変換する手法が主流でしたが、LLMによる直接的なパラメトリックシーケンス生成は未踏の領域でした。また、LLMは自然言語やコード生成には長けていますが、CADコマンドに含まれる空間構造や設計意図を自明には扱えません ([openaccess.thecvf.com][1])。

## 手法

1. **階層注釈パイプライン**

   * 各CADモデルをコンポーネントごとに分解し、3Dレンダリング画像と2DスケッチをVLM（GPT-4o）へ入力して詳細説明を生成（第1段階）。
   * 次に全体像と部品間の関係性を捉えた抽象／詳細説明を生成し、各部品に短い識別名を付与（第2段階）。
   * これらをSPCC形式のコードに組み込み、階層構造を反映させた注釈付きデータを得る ([openaccess.thecvf.com][1])。

2. **アダプティブ事前学習**

   * 得られたSPCCコーパスを用いて、DeepSpeed＋Flash-Attention環境下でLLMをフルファインチューニングし、CADコマンド列の生成能力を獲得させる ([openaccess.thecvf.com][1])。

3. **命令チューニング**

   * LoRAによるパラメータ効率的なチューニングで、テキスト→CAD生成や部品追加・削除など複数の下流タスクに対応可能な指示モデルへと最適化する ([openaccess.thecvf.com][1])。

## 実験設定とベースライン

* **無条件生成**：DeepCAD, SkexGen, HNC-CAD
* **テキスト→CAD**：Text2CAD, CAD-Translator
* **下流タスク**：GPT-4, GPT-3.5, LLaMA3-8B, Mistral-7B
* 評価指標には、Coverage (COV), MMD, JSD, Success Ratio, Noveltyなどを使用 ([openaccess.thecvf.com][1])。

## 実験結果

* **無条件生成**：CAD-LlamaはJSDやMMDで最良、Success Ratioでは99.90%を達成し、既存手法を上回る安定性と分布適合性を示した ([openaccess.thecvf.com][1])。
* **テキスト→CADタスク**：ACCT（生成命令の正確性）が84.72%と、Text2CAD（69.91%）やCAD-Translator（70.36%）を大きくリード。MCD, MMD, JSDも大幅改善 ([openaccess.thecvf.com][1])。
* **CAD関連下流タスク**：キャプション生成やコマンド／パラメータ追加・削除タスクで平均63.58%を獲得し、GPT-4比で約15.7ポイントの改善。特に構造化注釈による理解力向上が顕著 ([openaccess.thecvf.com][1])。
* **アブレーション**：SPCC（階層注釈＋コード形式）が、単一説明やシーケンス形式に対し20～40%近い精度向上を実証し、階層化とコード表現の効果を裏付けた ([openaccess.thecvf.com][1])。

## 貢献と今後の展望

1. LLMの生成的事前学習をCADコマンド生成へ拡張する新パラダイムを提案。
2. VLMを用いた2段階階層注釈パイプラインで、詳細かつ構造化されたSPCCフォーマットを構築。
3. 多タスク命令チューニングにより、設計補完から編集操作まで幅広いCADタスクに対応。
4. 将来的には3D拡張や商用CADツール連携、さらに大規模モデルへの適用により、LLM駆動CAD生成の可能性が一層拡大すると期待される ([openaccess.thecvf.com][1])。

[1]: https://openaccess.thecvf.com/content/CVPR2025/papers/Li_CAD-Llama_Leveraging_Large_Language_Models_for_Computer-Aided_Design_Parametric_3D_CVPR_2025_paper.pdf "CAD-Llama: Leveraging Large Language Models for Computer-Aided Design Parametric 3D Model Generation"

</details>

<details><summary>Query2CAD: Generating CAD Models Using Natural Language Queries</summary>

[参考](https://arxiv.org/pdf/2406.00144)  


---

## 概要

Query2CAD は，ユーザの自然言語クエリから Python マクロを生成し，FreeCAD 上で 3D CAD モデルを自動生成するフレームワークです。大規模言語モデル（LLM）を生成器かつ自己改良器として用い，BLIP2 によるキャプションと Visual Question Answering（VQA）スコアをフィードバックに取り入れることで，追加学習や教師データなしでも反復的に精度を向上させます 。

---

## 背景

従来，3D モデル生成はメッシュ・点群・ボクセルといったデータ形式を扱う手法が主流でしたが，CAD モデルは製造工程への直接転用や詳細設計を可能にする点で重要です。また，人間の CAD 設計者は試作→フィードバック→修正のサイクルを繰り返しますが，既存の LLM 出力は一発生成が中心であり，反復改良を伴う CAD モデリング支援は未整備でした 。

---

## 手法

1. **生成フェーズ**：ユーザのクエリ（例：“水筒の CAD デザインを作って”）を LLM（GPT-3.5/Turbo または GPT-4 Turbo）に与え，FreeCAD 用の Python マクロコードを生成します。
2. **エラー改良ループ**：マクロ実行時に発生したエラーメッセージとコードを再度 LLM に渡し，最大 3 回のエラー改良を行います。
3. **モデル改良ループ**：実行後のアイソメ図を取得し，Clip-FlanT5-XL による VQA スコアで最終出力を評価。スコアが閾値（デフォルト 0.9）未満の場合，BLIP2 または人手によるキャプションをフィードバックとして LLM に与え，最大 3 回の改良を行います。
4. **自動化**：PyAutoGUI を用い，FreeCAD の起動・マクロ実行・スクリーンショット・終了を自動化 。

---

## データセット

本研究用に，難易度別（Easy/Medium/Hard）に分類した 57 件のクエリを自作しました。

* **Easy**：立方体や球など単純形状（例：“辺長 10mm の立方体”） 21 問
* **Medium**：基本形状＋配置操作（例：“球の上に辺長 10mm の立方体”） 20 問
* **Hard**：複雑構造（例：“バスケットボールのフープ”） 16 問 。

---

## 実験結果

* **GPT-4 Turbo**：Easy 95.23%，Medium 70%，Hard 41.7% の一発成功率
* **GPT-3.5 Turbo**：Easy 85.71%，Medium 35%，Hard 37.5% 。
  さらに，最初の改良ループ実行で成功率が平均 23.1% 向上し，特に一回目の自己改良が最も効果的でした 。

---

## 貢献と展望

1. 自然言語→CAD マクロ生成＋自己改良ループによる，教師データ不要の CAD 設計自動化パイプラインを提案。
2. VQA スコアとキャプションフィードバックを組み合わせた反復改良手法を実装・評価。
3. PyAutoGUI による CAD ソフト操作の自動化でユーザ介入を最小化。
   今後は，多様な CAD 操作や複数ビュー評価，商用 CAD ツール連携への拡張が期待されます。

</details>

<details><summary></summary>

[参考](https://www.google.com/url?client=internal-element-cse&cx=000299513257099441687:fkkgoogvtaw&q=https://aclanthology.org/2023.emnlp-main.649.pdf&sa=U&ved=2ahUKEwiT4KKJ6PeNAxWtzTQHHZMeCxsQFnoECAMQAg&usg=AOvVaw1CnsQzsjtbH1fx1N1x5aUq&fexp=72986057,72986056)  


</details>
